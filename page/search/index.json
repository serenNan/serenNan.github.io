[{"content":"我是直接把这些动画效果全放一个css文件了\n创建一个hover-animation.css文件(可自定义)，然后记得在assets/scss/style.scss下添加@import \u0026quot;hover-animation\u0026quot;; 然后在创建的css文件添加以下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 /* 主页博客卡片 */ .article-list article { transition: transform 0.6s ease; -webkit-font-smoothing: antialiased; will-change: transform; transform-origin: center; \u0026amp;:hover { transform: scale(1.02, 1.02); } } /* 左侧栏选项 */ #main-menu { overflow: visible; li { a { -webkit-font-smoothing: antialiased; will-change: transform; transition: transform 0.6s ease; \u0026amp;:hover { transform: scale(1.1, 1.1); will-change: transform; } } } } /* 归档和链接卡片 */ .article-list--compact { overflow: visible; } .article-list--compact article { transition: transform 0.6s ease; -webkit-font-smoothing: antialiased; will-change: transform; \u0026amp;:hover { transform: scale(1.05,1.05); z-index: 4; } } /* 分类页面 */ .article-list--tile article { transition: 0.6s ease; } .article-list--tile article:hover { transform: scale(1.05, 1.05); will-change: transform; } /* 右侧导航栏 */ // 搜索 .search-form.widget { transition: transform 0.6s ease; } .search-form.widget:hover { transform: scale(1.1, 1.1); will-change: transform; -webkit-font-smoothing: antialiased; } //归档 .widget.archives .widget-archive--list { transition: transform .3s ease; will-change: transform; } .widget.archives .widget-archive--list:hover { transform: scale(1.05, 1.05); } // 标签 .tagCloud .tagCloud-tags a { border-radius: 10px; font-size: 1.4rem; transition: transform .3s ease; } .tagCloud .tagCloud-tags a:hover { transform: scale(1.1, 1.1); will-change: transform; -webkit-font-smoothing: antialiased; } 参数简单介绍:\n1 2 3 4 5 6 7 8 9 10 11 12 // 动画时间 transition: 0.6s ease; // 放大 transform: scale(1.1, 1.1); // 允许超出边框 overflow: visible; // 这个是为了放大别出现字体抖动（但好像没什么效果） will-change: transform; -webkit-font-smoothing: antialiased; ","date":"2025-01-05T00:00:00Z","image":"https://example.com/post/hugo-animation/word.jpg","permalink":"https://example.com/post/hugo-animation/","title":"Hugo动画"},{"content":"","date":"2025-01-05T00:00:00Z","permalink":"https://example.com/post/hugo-clock/","title":"Hugo时钟"},{"content":"字体 字体文件放在assets/fonts下，然后在layouts/partials/footer/costom.html(没有就创建)中引入,格式如下\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;style\u0026gt; @font-face { font-family: \u0026#39;MapleMono2\u0026#39;; src: url(\u0026#39;{{ (resources.Get \u0026#34;font/MapleMono2.ttf\u0026#34;).Permalink }}\u0026#39;) format(\u0026#39;truetype\u0026#39;); } :root { --base-font-family: \u0026#39;MapleMono2\u0026#39;; --code-font-family: \u0026#39;MapleMono2\u0026#39;; } \u0026lt;/style\u0026gt; 注意: 字体文件路径src要有后缀\n自定义分类页面样式 我不喜欢原本默认的归档页面，想把归档和分类分成两个页面，具体操作写在了我的Hugo配置博客Hugo配置(stack主题)\n后续想添加对应的页面样式，就在layouts添加对应的html文件，比如layouts/page/category.html，然后在contents/page/category.md中添加layout: \u0026quot;category\u0026quot;，这样就会使用layouts/page/category.html的样式了\n评论功能 这里使用的giscus配置\n先在github page上打开discussion功能 点击setting，向下滑找到discussion，勾选discussion 2. 下载giscus\ngiscus app\n选择仓库地址 3. 配置hugo\n进入giscus官网 giscus\n按照步骤配置，最后复制代码 五个重要参数：\ndata-repo data-repo-id data-category data-category-id data-mapping 添加到配置文件中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 comments: enabled: true provider: giscus giscus: repo: serenNan/serenNan.github.io repoID: category: Announcements categoryID: mapping: pathname lightTheme: light darkTheme: dark reactionsEnabled: 1 emitMetadata: 0 inputPosition: bottom lang: zh-CN 博客背景 我这里用的是particles动态粒子背景\n配置：\\\n进入网站自定义配置：particles 唯一需要注意的是有个选项改成window 配置好后下载文件 将particles.min.js 和 particlesjs-config.json放在assets/background文件夹下\n在layouts/partials/footer/custom.html中添加以下代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;div id=\u0026#34;particles-js\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;{{ (resources.Get \u0026#34;background/particles.min.js\u0026#34;).RelPermalink }}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; particlesJS.load(\u0026#39;particles-js\u0026#39;, \u0026#39;{{ (resources.Get \u0026#34;background/particlesjs-config.json\u0026#34;).RelPermalink }}\u0026#39;, function() { console.log(\u0026#39;particles.js loaded - callback\u0026#39;); }); \u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; #particles-js { position: fixed; top: 0; left: 0; width: 100%; height: 100%; z-index: -1; } \u0026lt;/style\u0026gt; ","date":"2025-01-02T00:00:00Z","image":"https://example.com/post/hugo-beautify/blog2.jpg","permalink":"https://example.com/post/hugo-beautify/","title":"Hugo美化\u0026优化(stack主题)"},{"content":"拷贝构造函数 参考文章 csdn：C++拷贝构造函数\n概述 拷贝构造函数，又称复制构造函数，是一种特殊的构造函数，它由编译器调用来完成一些基于同一类的其他对象的构造及初始化。\n其唯一的形参必须是引用，但并不限制为const，一般普遍的会加上const限制。\n调用拷贝构造函数的情形 一个对象作为函数参数，以值传递的方式传入函数体（函数传参，类类型的值传递） 1 2 3 4 5 6 7 8 9 10 11 12 class Complex { }; void Fun(Complex c1) { } int main() { Complex c1(1,2); Fun(c1); // 这里就调用了默认的拷贝构造函数 } 一个对象作为函数返回值，以值传递的方式从函数返回;（函数的返回类型是类，从局部对象到临时对象的拷贝构造） 1 2 3 4 5 Complex Fun() { Complex c(10,20); return c; // 这里会调用 } 一个对象用于给另外一个对象进行初始化(常称为赋值初始化);（用已有对象去初始化本类的其他对象） 1 2 3 4 5 6 int main() { Complex c1(1,2); Complex c2(c1); // 此处 Complex c3=c1; // 此处 } 浅拷贝与深拷贝 当对象的成员变量中存在指针变量时，用存在的对象初始化新建对象时指针变量一同初始化，但这时调用一般拷贝构造函数（浅拷贝）会使新对象中的指针指向和初始化对象指针指向一致，那么当用来初始化的对象在释放内存时会释放掉指针指向的内存，而当新创建的对象释放时会出现程序错误，以为这个指针指向的内存被释放了两次。因此我们需要手动提供另一种拷贝构造函数（深拷贝）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class MyClass { public: int* data; MyClass(int d) { data = new int(d); // 动态分配内存 } ~MyClass() { delete data; // 释放内存 } MyClass(const MyClass\u0026amp; other) { data = new int(*other.data); // 深拷贝：分配新内存并复制内容 } }; int main() { MyClass original(10); MyClass copy(original); // 调用深拷贝构造函数 return 0; } 虚析构函数 总的来说虚析构函数是为了避免内存泄露，而且是当子类中会有指针成员变量时才会使用得到的。也就说虚析构函数使得在删除指向子类对象的基类指针时可以调用子类的析构函数达到释放子类中堆内存的目的，而防止内存泄露的.\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 #include \u0026lt;iostream\u0026gt; using namespace std; class Fish { public: Fish() { cout \u0026lt;\u0026lt; \u0026#34;Constructed Fish\u0026#34; \u0026lt;\u0026lt; endl; } // 如果这里不是虚析构函数，那么delete pFish时只会调用基类的析构函数，而不会调用子类的析构函数 virtual ~Fish() // virtual destructor! { cout \u0026lt;\u0026lt; \u0026#34;Destroyed Fish\u0026#34; \u0026lt;\u0026lt; endl; } }; class Tuna : public Fish { public: Tuna() { cout \u0026lt;\u0026lt; \u0026#34;Constructed Tuna\u0026#34; \u0026lt;\u0026lt; endl; } ~Tuna() { cout \u0026lt;\u0026lt; \u0026#34;Destroyed Tuna\u0026#34; \u0026lt;\u0026lt; endl; } }; void DeleteFishMemory(Fish *pFish) { delete pFish; } int main() { cout \u0026lt;\u0026lt; \u0026#34;Allocating a Tuna on the free store:\u0026#34; \u0026lt;\u0026lt; endl; Tuna *pTuna = new Tuna; cout \u0026lt;\u0026lt; \u0026#34;Deleting the Tuna: \u0026#34; \u0026lt;\u0026lt; endl; DeleteFishMemory(pTuna); cout \u0026lt;\u0026lt; \u0026#34;Instantiating a Tuna on the stack:\u0026#34; \u0026lt;\u0026lt; endl; Tuna myDinner; cout \u0026lt;\u0026lt; \u0026#34;Automatic destruction as it goes out of scope: \u0026#34; \u0026lt;\u0026lt; endl; return 0; } 常量成员函数 常量对象和非常量对象 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #include \u0026lt;iostream\u0026gt; using namespace std; class MyClass { private: int x; public: MyClass(int n) { x = n; } void setX(int n) // 非常量成员函数 { x = n; } int getX() const // 常量成员函数 { return x; } }; int main() { MyClass obj1(10); // 非常量对象 const MyClass obj2(20); // 常量对象 obj1.setX(30); // 可以修改obj1的数据成员 cout \u0026lt;\u0026lt; \u0026#34;obj1.x = \u0026#34; \u0026lt;\u0026lt; obj1.getX() \u0026lt;\u0026lt; endl; // obj1.x = 30 // obj2.setX(40); // 编译错误，不能修改obj2的数据成员（常量对象不能调用非常量成员函数） cout \u0026lt;\u0026lt; \u0026#34;obj2.x = \u0026#34; \u0026lt;\u0026lt; obj2.getX() \u0026lt;\u0026lt; endl; // obj1.x = 20 return 0; } 常量成员函数 常量成员函数的特点 常量成员函数不会修改类的成员函数，即它们是只读的。因此，常量成员函数不能修改类的数据成员，也不能调用非常量成员函数,因为非常量成员函数可能会修改类的数据成员。 常量成员函数可以被常量对象和非常量对象调用。如果一个对象是常量对象，则只能调用该对象的常量成员函数，而不能调用非常量成员函数。 常量成员函数可以访问类的所有成员变量和常量成员函数。 常量成员函数的作用是保证类的数据成员不被修改，从而提高程序的安全性和可靠性。 常量成员函数通常用于访问类的数据成员，而不是修改它们。 例如：可以使用常量成员函数来实现类的数据成员的读取操作，而使用非常量成员函数来实现类的数据成员的写入操作。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #include \u0026lt;iostream\u0026gt; using namespace std; class Person { private: string name; int age; public: Person(string n, int a) { name = n; age = a; } string getName() const { return name; } int getAge() const { return age; } void show() const { cout \u0026lt;\u0026lt; \u0026#34;Name: \u0026#34; \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34;, Age: \u0026#34; \u0026lt;\u0026lt; age \u0026lt;\u0026lt; endl; } }; int main() { Person p(\u0026#34;Alice\u0026#34;, 20); p.show(); return 0; } 左值和右值 参考文章 csdn：C++ 左值和右值\n左值和右值的定义 左值（loactor value）:存储在内存中、可寻址的数据\n右值（read value）:可以提供数据值的数据（不一定可寻址，例如存储在寄存器中的数据）\n右值引用 左值引用无法引用右值； 常量左值引用可以操作右值，但是无法对右值进行修改； 右值引用可以对右值进行修改； 常量右值引用：引用一个右值，并且不可更改。可以常量左值引用代替。 1 2 3 4 5 6 7 int a = 10; int \u0026amp;b = a; // 左值引用 // int \u0026amp;c = 10; // 错误，左值引用无法操作右值 b = 20; const int \u0026amp;d = 10; // 常量左值引用可以操作右值 int \u0026amp;\u0026amp;e = 20; // 右值引用 e = 25; // 修改右值 因此c++11中引入右值引用\u0026amp;\u0026amp;。\n右值引用使用场景 拷贝构造函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #include \u0026lt;iostream\u0026gt; using namespace std; class demo { public: // 构造函数 demo() : num(new int(0)) { cout \u0026lt;\u0026lt; \u0026#34;construct!\u0026#34; \u0026lt;\u0026lt; endl; } // 拷贝构造函数（深拷贝） demo(const demo \u0026amp;d) : num(new int(*d.num)) { cout \u0026lt;\u0026lt; \u0026#34;copy construct!\u0026#34; \u0026lt;\u0026lt; endl; } ~demo() { cout \u0026lt;\u0026lt; \u0026#34;class destruct!\u0026#34; \u0026lt;\u0026lt; endl; } private: int *num; }; demo get_demo() { return demo(); // 返回一个demo对象，是一个右值 } int main() { demo a (get_demo()); // 拷贝构造 return 0; } 输出：\nconstruct! copy construct! copy construct! class destruct! class destruct! 有些编译器可能会优化，只输出一次拷贝构造函数。\n如上所示，demo 类自定义了一个拷贝构造函数。该函数在拷贝 d.num 指针成员时，必须采用深拷贝的方式，即拷贝该指针成员本身的同时，还要拷贝指针指向的内存资源。否则一旦多个对象中的指针成员指向同一块堆空间，这些对象析构时就会对该空间释放多次，这是不允许的。\ndemo a (get_demo()) 的流程：\n执行 get_demo() 函数，demo()调用构造函数生成一个匿名对象 执行 return demo() ，调用拷贝构造函数拷贝匿名对象，作为函数get_demo()的返回值（get_demo()执行完毕，匿名对象会被销毁） 执行 a(get_demo()), 调用拷贝构造函数(此行代码执行完毕，get_demo()的返回值会被析构) 程序结束前，a被析构。 在这个过程中，底层执行了2次深拷贝。如果指针指向的堆空间较大，会大大降低执行的效率。通过移动构造函数可以解决这个问题。\n何时调用拷贝构造函数？（详见：拷贝构造函数）\n移动构造函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #include \u0026lt;iostream\u0026gt; using namespace std; class demo { public: // 构造函数 demo() : num(new int(0)) { cout \u0026lt;\u0026lt; \u0026#34;construct!\u0026#34; \u0026lt;\u0026lt; endl; } // 拷贝构造函数（深拷贝） demo(const demo \u0026amp;d) : num(new int(*d.num)) { cout \u0026lt;\u0026lt; \u0026#34;copy construct!\u0026#34; \u0026lt;\u0026lt; endl; } // 移动构造函数 demo(demo \u0026amp;\u0026amp;d) : num(d.num) { d.num = nullptr; cout \u0026lt;\u0026lt; \u0026#34;move construct!\u0026#34; \u0026lt;\u0026lt; endl; } ~demo() { cout \u0026lt;\u0026lt; \u0026#34;class destruct!\u0026#34; \u0026lt;\u0026lt; endl; } private: int *num; }; demo get_demo() { demo temp; // 创建一个局部对象 return temp; // 返回局部对象 } int main() { demo a(get_demo()); // 调用移动构造函数 return 0; } 输出：\nconstruct! move construct! class destruct! class destruct! 使用右值引用类型的参数，指针浅拷贝，右值对象指针置为nullptr, 从而，避免拷贝堆空间，完成初始化。\n当类中同时包含拷贝构造函数和移动构造函数时，如果使用临时对象初始化当前类的对象，编译器会优先调用移动构造函数来完成此操作。只有当类中没有合适的移动构造函数时，编译器才会退而求其次，调用拷贝构造函数。\nstd::move()可以将左值转换为右值，从而使用移动构造。\n1 2 3 4 5 demo get_demo() { demo temp; // 创建一个局部对象 return std::move(temp); // 使用 std::move 触发移动构造函数 } 输出是一样的\nmove函数 参考文章 csdn：C++11中的move函数\n智能指针 参考文章 csdn：C++智能指针\n智能指针概述 是原始指针的封装，会自动分配内存，不需要担心潜在的内存泄露。\n为什么使用智能指针 一句话带过：智能指针就是帮我们C++程序员管理动态分配的内存的，它会帮助我们自动释放new出来的内存，从而避免内存泄漏。\n下面的内存泄露的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;memory\u0026gt; using namespace std; // 动态分配内存，没有释放就return void memoryLeak1() { string *str = new string(\u0026#34;动态分配内存！\u0026#34;); return; } // 动态分配内存，虽然有些释放内存的代码，但是被半路截胡return了 int memoryLeak2() { string *str = new string(\u0026#34;内存泄露！\u0026#34;); // ...此处省略一万行代码 // 发生某些异常，需要结束函数 if (1) { return -1; } / // 另外，使用try、catch结束函数，也会造成内存泄漏！ / delete str;\t// 虽然写了释放内存的代码，但是遭到函数中段返回，使得指针没有得到释放 return 1; } int main(void) { memoryLeak1(); memoryLeak2(); return 0; } memoryLeak1函数中，new了一个字符串指针，但是没有delete就已经return结束函数了，导致内存没有被释放，内存泄露！ memoryLeak2函数中，new了一个字符串指针，虽然在函数末尾有些释放内存的代码delete str，但是在delete之前就已经return了，所以内存也没有被释放，内存泄露！\n使用指针，我们没有释放，就会造成内存泄露。但是我们使用普通对象却不会。\n而智能指针本质是对一个普通指针的封装，利用有生命周期的对象自动释放的特性，来实现内存的自动管理。\nauto_ptr auto_ptr 是c++ 98定义的智能指针模板，其定义了管理指针的对象，可以将new获得（直接或间接）的地址赋给这种对象。当对象过期时，其析构函数将使用delete来释放内存！\n用法： 头文件：#include \u0026lt;memory\u0026gt; 用法： auto_ptr\u0026lt;类型\u0026gt; 变量名(new 类型)\n例如：\n1 2 3 auto_ptr\u0026lt; string \u0026gt; str(new string(“我要成为大牛~ 变得很牛逼！”)); auto_ptr\u0026lt;vector\u0026lt; int \u0026gt;\u0026gt; av(new vector\u0026lt; int \u0026gt;()); auto_ptr\u0026lt; int \u0026gt; array(new int[10]); 下面的代码使用new创建一个对象，但是不使用delete，就会发生内存泄露。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #include \u0026#34;iostream\u0026#34; using namespace std; class Test { public: Test() { cout \u0026lt;\u0026lt; \u0026#34;Test的构造函数...\u0026#34; \u0026lt;\u0026lt; endl; } ~Test() { cout \u0026lt;\u0026lt; \u0026#34;Test的析构函数...\u0026#34; \u0026lt;\u0026lt; endl; } int getDebug() { return this-\u0026gt;debug; } private: int debug = 20; }; int main(void) { Test *test = new Test; cout \u0026lt;\u0026lt; test-\u0026gt;getDebug() \u0026lt;\u0026lt; endl; // delete test; return 0; } 输出：\nTest的构造函数... 要释放内存，就得手动delete，或者使用智能指针\n使用智能指针：\n1 2 3 4 5 6 7 8 9 10 11 int main(void) { // Test *test = new Test; auto_ptr\u0026lt;Test\u0026gt; test(new Test); cout \u0026lt;\u0026lt; \u0026#34;test-\u0026gt;debug：\u0026#34; \u0026lt;\u0026lt; test-\u0026gt;getDebug() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;(*test).debug：\u0026#34; \u0026lt;\u0026lt; (*test).getDebug() \u0026lt;\u0026lt; endl; return 0; } 输出：\nTest的构造函数... test-\u0026gt;debug：20 (*test).debug：20 Test的析构函数... 智能指针可以像普通指针一样使用，并且会自动释放内存\n智能指针有三个常用函数：\nget()：获取智能指针管理的指针\n1 2 3 4 5 // 定义智能指针 auto_ptr\u0026lt;Test\u0026gt; test(new Test); Test *tmp = test.get();\t// 获取指针返回 cout \u0026lt;\u0026lt; \u0026#34;tmp-\u0026gt;debug：\u0026#34; \u0026lt;\u0026lt; tmp-\u0026gt;getDebug() \u0026lt;\u0026lt; endl; 但一般不这么使用，因为可以直接使用智能指针操作\nrelease()：释放智能指针管理的指针\n1 2 3 4 5 // 定义智能指针 auto_ptr\u0026lt;Test\u0026gt; test(new Test); Test *tmp2 = test.release();\t// 取消智能指针对动态内存的托管 delete tmp2;\t// 之前分配的内存需要自己手动释放 reset()：重置智能指针管理的指针\n1 2 3 4 5 6 // 定义智能指针 auto_ptr\u0026lt;Test\u0026gt; test(new Test); test.reset();\t// 释放掉智能指针托管的指针内存，并将其置NULL test.reset(new Test());\t// 释放掉智能指针托管的指针内存，并将参数指针取代之 unique_ptr c++11使用unique_ptr替代auto_ptr\nunique_ptr特性：\n基于排他所有权模式：两个指针不能指向同一个资源 无法进行左值unique_ptr复制构造，也无法进行左值复制赋值操作，但允许临时右值赋值构造和赋值 保存指向某个对象的指针，当它本身离开作用域时会自动释放它指向的对象。 在容器中保存指针是安全的 ","date":"2024-12-30T00:00:00Z","image":"https://example.com/post/cpp_study/cpp.jpg","permalink":"https://example.com/post/cpp_study/","title":"C++语法"},{"content":"yaml参数 主框架 1 2 3 4 5 6 baseurl: https://example.com/ languageCode: en-us theme: hugo-theme-stack paginate: 10 title: 个人博客 copyright: serenNan baseurl: 目前是github pages的地址 my-blog\nlanguageCode: 语言代码\ntheme: 主题名称\npaginate: 每页显示的文章数量\ntitle: 网站标题（目前没使用）\ncopyright: 网页最下方显示\n语言 1 2 3 # Theme i18n support # Available values: ar, bn, ca, de, el, en, es, fr, hu, id, it, ja, ko, nl, pt-br, th, uk, zh-cn, zh-hk, zh-tw DefaultContentLanguage: zh-cn DefaultContentLanguage: 默认语言\n网页图标 1 favicon: # e.g.: favicon placed in `static/favicon.ico` of your site folder, then set this field to `/favicon.ico` (`/` is necessary) favicon: 网站图标(将 favicon 放置在站点文件夹的 static/favicon.ico 中，然后将此字段设置为 /favicon.ico（/ 是必需的）。)\n页脚 1 2 3 footer: since: 2024 customText: footer: 页脚\nsince: 年份\ncustomText: 自定义文本\n头像 1 2 3 4 5 6 7 sidebar: emoji: 🐈‍⬛ subtitle: 欢迎来到我的个人博客 avatar: enabled: true local: true src: img/avatar.png sidebar: 侧边栏\navatar: 头像\nsrc: 头像路径\n头像是在 assets/img/avatar.png 中\n文章信息 1 2 3 4 5 6 7 article: math: false toc: true readingTime: true license: enabled: true default: Licensed under CC BY-NC-SA 4.0 article: 文章\nmath: 数学公式\ntoc: 目录\nreadingTime: 阅读时间\nlicense: 许可证\nenabled: 是否启用\ndefault: 默认许可证\n右侧侧边栏 1 2 3 4 5 6 7 8 9 10 11 12 13 14 widgets: homepage: - type: search - type: archives params: limit: 5 - type: categories params: limit: 10 - type: tag-cloud params: limit: 10 page: - type: toc widgets: 小工具 (右边侧边栏)\nsearch: 搜索\narchives: 归档\ncategories: 分类\ntag-cloud: 标签云\ntoc: 目录\n头像下方图标 1 2 3 4 5 6 7 8 9 10 11 12 social: - identifier: github name: GitHub url: https://github.com/CaiJimmy/hugo-theme-stack params: icon: github-2 - identifier: bilibili name: Bilibili url: https://space.bilibili.com/450940909 params: icon: bilibili 头像下方的链接，icon图标放在assets/icons文件夹下，svg后缀。\n左侧侧边栏导航 在content/page文件夹下\nlink链接 在content/page/links.md下 格式:\n1 2 3 4 5 6 7 8 9 links: - title: GitHub description: GitHub is the world\u0026#39;s largest software development platform. website: https://github.com image: https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png - title: TypeScript description: TypeScript is a typed superset of JavaScript that compiles to plain JavaScript. website: https://www.typescriptlang.org image: ts-logo-128.jpg 自定义分类页面 我这里是自定义的分类页面，将归档和分类分开\n在content/categories.md下，每有一个分类就创建一个文件夹，文件夹下放_index.md文件，格式如下：\n注意：是_index.md要加个_\n1 2 3 4 5 6 7 8 title: \u0026#34;文档\u0026#34; date: 2020-03-14T15:40:24+06:00 description : \u0026#34;文档分类\u0026#34; slug: \u0026#34;document\u0026#34; image: 猫.png style: background: \u0026#34;#2a9d8f\u0026#34; color: \u0026#34;#fff\u0026#34; 如果想完善页面，可以在layouts/page/categories.html添加下面的内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 {{ define \u0026#34;body-class\u0026#34; }}template-categories{{ end }} {{ define \u0026#34;main\u0026#34; }} \u0026lt;header\u0026gt; {{- $taxonomy := $.Site.GetPage \u0026#34;taxonomyTerm\u0026#34; \u0026#34;categories\u0026#34; -}} {{- $terms := $taxonomy.Pages -}} {{ if $terms }} \u0026lt;h1 class=\u0026#34;section-title\u0026#34;\u0026gt;分类\u0026lt;/h1\u0026gt; \u0026lt;!-- 这里是标题 --\u0026gt; \u0026lt;div class=\u0026#34;subsection-list\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;article-list--tile\u0026#34; style=\u0026#34;display: flex; flex-direction: column;\u0026#34;\u0026gt; {{ range $terms }} \u0026lt;div class=\u0026#34;category-group\u0026#34; style=\u0026#34;flex: 1 1 auto; margin: 10px;\u0026#34;\u0026gt; \u0026lt;h3 class=\u0026#34;category-title\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt; \u0026lt;/h3\u0026gt; \u0026lt;div class=\u0026#34;article-list--horizontal\u0026#34; style=\u0026#34;display: flex; overflow-x: auto;\u0026#34;\u0026gt; {{ $articles := where .Site.RegularPages \u0026#34;Params.categories\u0026#34; \u0026#34;intersect\u0026#34; (slice .Title) }} {{ range $articles }} \u0026lt;div class=\u0026#34;article-tile\u0026#34; style=\u0026#34;flex: 0 0 auto; margin: 5px;\u0026#34;\u0026gt; {{ partial \u0026#34;article-list/tile\u0026#34; (dict \u0026#34;context\u0026#34; . \u0026#34;size\u0026#34; \u0026#34;250x150\u0026#34; \u0026#34;Type\u0026#34; \u0026#34;taxonomy\u0026#34;) }} \u0026lt;/div\u0026gt; {{ end }} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {{ end }} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {{ end }} \u0026lt;/header\u0026gt; {{ partialCached \u0026#34;footer/footer\u0026#34; . }} {{ end }} 文章 在content/post文件夹下，正文就用markdown格式\n主页blog显示 1 2 3 4 5 6 7 8 title: Chinese Test description: 这是一个副标题 date: 2020-09-09 slug: test-chinese # url显示 image: helena-hertz-wWZzXlDpMog-unsplash.jpg categories: - Test - 测试 创建时间\u0026amp;更新时间 1 2 3 4 5 6 7 8 # 更新时间：优先读取git时间 -\u0026gt; git时间不存在，就读取本地文件修改时间 frontmatter: lastmod: - :git - :fileModTime # 允许获取Git信息\tenableGitInfo: true 在部署文件.github/workflows/deploy.yaml 添加：\n1 2 3 4 5 6 - name: Git Configuration run: | git config --global core.quotePath false git config --global core.autocrlf false git config --global core.safecrlf true git config --global core.ignorecase false 注意缩进要对\nstack默认显示在文章最后面，如果想在主页面的博客文章显示，在layouts/partials/article/components/details.html添加：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \u0026lt;!-- 创建时间\u0026amp;阅读时长 --\u0026gt; \u0026lt;footer class=\u0026#34;article-time\u0026#34;\u0026gt; {{ if $showDate }} \u0026lt;div\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;date\u0026#34; }} \u0026lt;time class=\u0026#34;article-time--published\u0026#34;\u0026gt; {{- .Date | time.Format (or .Site.Params.dateFormat.published \u0026#34;Jan 02, 2006\u0026#34;) -}} \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{ end }} {{ if $showReadingTime }} \u0026lt;div\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;clock\u0026#34; }} \u0026lt;time class=\u0026#34;article-time--reading\u0026#34;\u0026gt; {{ T \u0026#34;article.readingTime\u0026#34; .ReadingTime }} \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{ end }} {{ if and $showDate (ne .Lastmod .Date) }} \u0026lt;span class=\u0026#34;time-divider\u0026#34;\u0026gt;|\u0026lt;/span\u0026gt; {{ end }} {{- if ne .Lastmod .Date -}} \u0026lt;div class=\u0026#34;article-time--lastmod\u0026#34;\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;clock\u0026#34; }} \u0026lt;time\u0026gt; {{ .Lastmod.Format ( or .Site.Params.dateFormat.lastUpdated \u0026#34;Jan 02, 2006 15:04 MST\u0026#34; ) }} \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{- end -}} 自带的有阅读时长，我没开启\n文章末尾也会显示最后修改时间，想删除就去layouts/partials/article/components/footer.html删掉：\n1 2 3 4 5 6 7 8 {{- if ne .Lastmod .Date -}} \u0026lt;section class=\u0026#34;article-lastmod\u0026#34;\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;clock\u0026#34; }} \u0026lt;span\u0026gt; {{ T \u0026#34;article.lastUpdatedOn\u0026#34; }} {{ .Lastmod | time.Format ( or .Site.Params.dateFormat.lastUpdated \u0026#34;Jan 02, 2006 15:04 MST\u0026#34; ) }} \u0026lt;/span\u0026gt; \u0026lt;/section\u0026gt; {{- end -}} ","date":"2024-12-29T00:00:00Z","image":"https://example.com/post/hugo-config/blog1.jpg","permalink":"https://example.com/post/hugo-config/","title":"Hugo配置(stack主题)"},{"content":"基础命令 CSDN博主总结常用命令\n获得基础信息，输出Metadata 打开媒体文件，获取Meta信息，关闭媒体文件\n代码 dumpMetaData.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #include \u0026#34;libavutil/log.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; // 传入命令行参数个数 int main(int argc, char **argv) { // 设置日志级别 av_log_set_level(AV_LOG_DEBUG); // 设置日志输出函数 // 检查参数个数 if (argc \u0026lt; 2) { av_log(NULL, AV_LOG_DEBUG, \u0026#34;Usage:%s infileName.\\n\u0026#34;, argv[0]); return -1; } // 获取输入文件名 const char *infileName = argv[1]; // 初始化所有组件 AVFormatContext *pFormatCtx = NULL; // 打开媒体文件 int ret = avformat_open_input(\u0026amp;pFormatCtx, infileName, NULL, NULL); // av_err2str()函数返回错误信息 if (ret != 0) { // av_err2str()函数返回错误信息 av_log(NULL, AV_LOG_DEBUG, \u0026#34;open input file:%s failed: %s\\n\u0026#34;, infileName, av_err2str(ret)); return -1; } // 获取媒体文件信息 av_dump_format(pFormatCtx, 0, infileName, 0); // 关闭媒体文件 avformat_close_input(\u0026amp;pFormatCtx); return 0; } 容器/文件 (Container/File) 定义: 特定格式的多媒体文件，如 .mp4, .flv, .mov 等。 作用: 存储和组织多媒体数据，包括音频、视频、字幕等。 常见格式: MP4: 广泛用于视频存储和流媒体。 FLV: 主要用于Flash视频。 MOV: 苹果公司开发的视频格式。 媒体流 (Stream) 定义: 一段连续的数据，如一段声音数据、一段视频或者一段字幕数据。 特点: 由不同编码器编码。 类型: 音频流: 存储音频数据。 视频流: 存储视频数据。 字幕流: 存储字幕数据。 数据包 (Packet) 定义: 一个媒体流由大量的数据包组成，是压缩后的数据。 作用: 传输和存储媒体数据的基本单位。 特点: 数据包是压缩后的数据，便于传输和存储。 数据帧 (Frame) 定义: 一个数据包由一个或多个数据帧组成，是非压缩数据。 作用: 原始的、未压缩的媒体数据。 类型: I帧 (Intra Frame): 独立帧，不依赖其他帧。 P帧 (Predictive Frame): 依赖前一帧进行预测。 B帧 (Bidirectional Frame): 依赖前后帧进行预测。 编解码器 (Codec) 定义: 编解码器是以帧为单位实现压缩数据和原始数据之间相互转换的工具。 作用: 用于压缩和解压缩媒体数据。 常见编解码器: 视频编解码器: H.264, H.265, VP9 等。 音频编解码器: AAC, MP3, Vorbis 等。 重要结构体 AVFormatContext: 管理整个多媒体文件的格式和结构。 AVStream: 表示媒体文件中的一个单独的媒体流。 AVCodecContext 与 AVCodec: 管理媒体数据的编码和解码过程。 AVPacket: 表示压缩后的媒体数据。 AVFrame: 表示未压缩的原始媒体数据。 解封装-提取aac数据 AAC（Advanced Audio Coding）是一种高级音频编码技术，广泛用于数字音频压缩和传输。它是由MPEG（Moving Picture Experts Group）开发的，旨在提供比MP3更高的音质和更高的压缩效率。AAC通常用于各种音频应用，包括音乐、视频、广播和流媒体服务。\nAAC的主要特点：\n高音质：AAC能够在较低的比特率下提供比MP3更高的音质。 多通道支持：AAC支持多通道音频，包括立体声、5.1环绕声和7.1环绕声。 低延迟：AAC设计用于低延迟应用，适合实时音频传输。 灵活性：AAC支持多种比特率和采样率，适用于不同的应用场景。 1 2 ffmpeg -y -i out.mp4 -vn -acodec copy out.aac ffplay out.aac 流程 操作步骤 函数名 打开媒体文件 avformat_open_input 获取码流信息 avformat_find_stream_info 获取音频流 av_find_best_stream 初始化 packet av_packet_alloc 读取 packet 数据 av_read_frame 释放 packet 数据 av_packet_unref 关闭媒体文件 avformat_close_input 代码 demuxing_audio.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; int main(int argc, char *argv[]) { // 设置日志级别 av_log_set_level(AV_LOG_DEBUG); // 如果参数小于3，输出使用方法 if (argc \u0026lt; 3) { // argv[0]是程序名 av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input file\u0026gt; \u0026lt;output file\u0026gt;\\n\u0026#34;, argv[0]); return -1; } // 获取命令行的输入音频 const char *inputName = argv[1]; // 获取命令行的输出音频 const char *outputName = argv[2]; av_sdp_create; // 打开输入音频文件 AVFormatContext *inFormatCtx = NULL; // 打开媒体文件，并获取流信息 int ret = avformat_open_input(\u0026amp;inFormatCtx, inputName, NULL, NULL); // 如果打开输入文件失败，返回错误信息 if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open input file \u0026#39;%s\u0026#39;\\n\u0026#34;, inputName); return -1; } // 获取码流信息 ret = avformat_find_stream_info(inFormatCtx, NULL); // 如果ret小于0，则打印错误信息 if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find stream info failed:%s\\n\u0026#34;, av_err2str(ret)); // 就算获取失败，也要关闭输入文件 avformat_close_input(\u0026amp;inFormatCtx); return -1; } // 如果获取成功，则打印信息 int audioIndex = av_find_best_stream(inFormatCtx, AVMEDIA_TYPE_AUDIO, -1, -1, NULL, 0); if (audioIndex \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find audio stream in the input file\\n\u0026#34;); avformat_close_input(\u0026amp;inFormatCtx); return -1; } if (audioIndex \u0026lt; 0) { // 输出错误信息，表示找不到最佳音频流 av_log(NULL, AV_LOG_ERROR, \u0026#34;find best stream failed, index is %d\\n\u0026#34;, audioIndex); avformat_close_input(\u0026amp;inFormatCtx); return -1; } // 打印音频信息 av_log(NULL, AV_LOG_INFO, \u0026#34;the audio index is %d\\n\u0026#34;, audioIndex); // 初始化AVPacket结构体 AVPacket *packet = av_packet_alloc(); if (!packet) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not allocate packet\\n\u0026#34;); avformat_close_input(\u0026amp;inFormatCtx); return -1; } // 存储音频流信息 输出文件 FILE *dest_fp = fopen(outputName, \u0026#34;wb\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open %s file failed\\n\u0026#34;, outputName); // 就算打不开文件也得关闭音频文件 avformat_close_input(\u0026amp;inFormatCtx); // 释放分配的AVPacket av_packet_free(\u0026amp;packet); return -1; } // 有许多PC数据，所以需要循环读取 while (av_read_frame(inFormatCtx, packet) == 0) { // 检查当前包是否属于音频流 if (packet-\u0026gt;stream_index == audioIndex) { // 将音频数据写入输出文件 fwrite(packet-\u0026gt;data, 1, packet-\u0026gt;size, dest_fp); // 检查写入是否成功 if (ret != packet-\u0026gt;size) { // 如果写入的数据大小不等于包的大小，则输出错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;write data failed\\n\u0026#34;); // 关闭输出文件 fclose(dest_fp); // 关闭输入文件 avformat_close_input(\u0026amp;inFormatCtx); // 释放整个结构体 av_packet_free(\u0026amp;packet); return -1; } } // 释放当前包的引用 av_packet_unref(packet); } // 检查输入格式上下文是否已初始化 if (inFormatCtx != NULL) { // 关闭输入文件 avformat_close_input(\u0026amp;inFormatCtx); } // 检查输出文件指针是否已初始化 if (dest_fp != NULL) { // 关闭输出文件 fclose(dest_fp); } if (packet != NULL) { // 释放AVPacket结构体 av_packet_free(\u0026amp;packet); } return 0; } aac音频格式分析 ADTS（Audio Data Transport Stream）和ADIF（Audio Data Interchange Format）是两种用于音频编码的容器格式，主要用于AAC（Advanced Audio Codec）音频编码。它们的主要区别在于数据流的组织方式和使用场景。\nADTS（Audio Data Transport Stream） 定义: ADTS是一种流式传输格式，适用于音频数据的实时传输，如广播、流媒体等。 结构: 每个ADTS帧都包含一个头信息，后面跟着音频数据。头信息中包含了帧的长度、采样率、声道数等信息。 特点: 自包含: 每个ADTS帧都是自包含的，可以独立解码。 流式传输: 适合流式传输，因为每个帧都可以独立处理。 头部信息: 每个帧的头部信息较大，可能会增加一些开销。 ADIF（Audio Data Interchange Format） 定义: ADIF是一种文件格式，适用于音频数据的存储和交换，如音频文件的存储。 结构: ADIF文件包含一个唯一的头信息，后面跟着所有的音频数据。头信息中包含了编码参数、采样率、声道数等信息。 特点: 单一头部: 整个文件只有一个头部信息，减少了冗余。 非流式: 不适合流式传输，因为需要整个文件的头信息才能开始解码。 存储和交换: 适合存储和交换音频数据，因为头部信息只出现一次，减少了文件大小。 总结 ADTS: 适用于流式传输，每个帧自包含，适合实时传输。 ADIF: 适用于文件存储和交换，整个文件只有一个头部信息，适合存储和交换音频数据。 选择哪种格式取决于具体的应用场景：如果需要实时传输音频数据，ADTS是更好的选择；如果需要存储或交换音频文件，ADIF更为合适。\n提取H264视频数据 流程 流程和提取aac文件一样\n操作步骤 函数名 打开媒体文件 avformat_open_input 获取码流信息 avformat_find_stream_info 获取音频流 av_find_best_stream 初始化 packet av_packet_alloc 读取 packet 数据 av_read_frame 释放 packet 数据 av_packet_unref 关闭媒体文件 avformat_close_input 代码 demuxing_video.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 #include \u0026lt;libavutil/avutil.h\u0026gt; #include \u0026lt;libavformat/avformat.h\u0026gt; int main(int argc, char **argv) { av_log_set_level(AV_LOG_DEBUG); if (argc \u0026lt; 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input\u0026gt; \u0026lt;output\u0026gt;\\n\u0026#34;, argv[0]); return -1; } const char *inFilename = argv[1]; const char *outFilename = argv[2]; AVFormatContext *inFmtCtx = NULL; int ret = avformat_open_input(\u0026amp;inFmtCtx, inFilename, NULL, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Open input format failed:%s\\n\u0026#34;, av_err2str(ret)); return -1; } ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Find stream info failed:%s\\n\u0026#34;, av_err2str(ret)); ret = -1; goto fail; } ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Find best stream failed:%s\\n\u0026#34;, av_err2str(ret)); ret = -1; goto fail; } int videoIndex = ret; FILE *dest_fp = fopen(outFilename, \u0026#34;wb\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Open output file failed:%s\\n\u0026#34;, outFilename); ret = -1; goto fail; } AVPacket *packet = av_packet_alloc(); while (av_read_frame(inFmtCtx, packet) == 0) { if (packet-\u0026gt;stream_index == videoIndex) { int writeSize = fwrite(packet-\u0026gt;data, 1, packet-\u0026gt;size, dest_fp); if (writeSize != packet-\u0026gt;size) { // 这里不能释放整个packet，只能释放packet中的data，因为循环之后还会用到packet av_packet_unref(packet); ret = -1; break; } } av_packet_free(\u0026amp;packet); } fclose(dest_fp); fail: if(inFmtCtx != NULL) { avformat_close_input(\u0026amp;inFmtCtx); } if(dest_fp != NULL) { fclose(dest_fp); } return ret; } 成功运行，要用avi格式的视频文件\n如果想提取mp4格式的文件，需要进行以下步骤\nmp4→h264 流程 函数名 描述 av_bsf_get_by_name 根据名称获取比特流过滤器 av_bsf_alloc 分配比特流过滤器上下文 avcodec_parameters_copy 复制编解码器参数 av_bsf_init 初始化比特流过滤器 av_bsf_send_packet 发送数据包到比特流过滤器 av_bsf_receive_packet 从比特流过滤器接收处理后的数据包 av_bsf_free 释放比特流过滤器上下文及相关资源 代码 mp4toh264.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 #include \u0026lt;libavutil/avutil.h\u0026gt; #include \u0026lt;libavformat/avformat.h\u0026gt; #include \u0026lt;libavcodec/bsf.h\u0026gt; int main(int argc, char **argv) { av_log_set_level(AV_LOG_DEBUG); if (argc \u0026lt; 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input\u0026gt; \u0026lt;output\u0026gt;\\n\u0026#34;, argv[0]); return -1; } const char *inFilename = argv[1]; const char *outFilename = argv[2]; AVFormatContext *inFmtCtx = NULL; int ret = avformat_open_input(\u0026amp;inFmtCtx, inFilename, NULL, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Open input format failed:%s\\n\u0026#34;, av_err2str(ret)); return -1; } ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Find stream info failed:%s\\n\u0026#34;, av_err2str(ret)); ret = -1; goto fail; } ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Find best stream failed:%s\\n\u0026#34;, av_err2str(ret)); ret = -1; goto fail; } int videoIndex = ret; FILE *dest_fp = fopen(outFilename, \u0026#34;wb+\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Open output file failed:%s\\n\u0026#34;, outFilename); ret = -1; goto fail; } AVPacket *packet = av_packet_alloc(); const AVBitStreamFilter *bsf = av_bsf_get_by_name(\u0026#34;h264_mp4toannexb\u0026#34;); if(bsf == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;get h264_mp4toannexb bsf failed\\n\u0026#34;); ret = -1; goto fail; } AVBSFContext *bsfCtx = NULL; av_bsf_alloc(bsf, \u0026amp;bsfCtx); avcodec_parameters_copy(bsfCtx-\u0026gt;par_in, inFmtCtx-\u0026gt;streams[videoIndex]-\u0026gt;codecpar); av_bsf_init(bsfCtx); while (av_read_frame(inFmtCtx, packet) == 0) { if (packet-\u0026gt;stream_index == videoIndex) { if(av_bsf_send_packet(bsfCtx, packet) == 0) { while(av_bsf_receive_packet(bsfCtx, packet) == 0) { int writeSize = fwrite(packet-\u0026gt;data, 1, packet-\u0026gt;size, dest_fp); if (writeSize != packet-\u0026gt;size) { // 这里不能释放整个packet，只能释放packet中的data，因为循环之后还会用到packet av_packet_unref(packet); ret = -1; break; } } } } av_packet_free(\u0026amp;packet); } fclose(dest_fp); fail: if(inFmtCtx != NULL) { avformat_close_input(\u0026amp;inFmtCtx); } if(bsfCtx != NULL) { av_bsf_free(\u0026amp;bsfCtx); } if(dest_fp != NULL) { fclose(dest_fp); } return ret; } 转封装-mp4转flv I帧，P帧，B帧 I帧：帧内编码帧（Intra picture），I帧通常是一个GOP的第一帧，经过轻度地压缩，作为随机访问的参考点，可以当成静态图像，I帧压缩可去掉视频的空间冗余信息。\nP帧：前向预测编码帧（predictive frame），通过将图像序列中前面已编码帧的时间冗余信息充分去除来压缩传输数据量的编码图像，也称为预测帧。\nB帧：双向预测内插编码帧，既考虑源图像序列前面的已编码帧，又顾及源图像序列后面的已编码帧之间的时间冗余信息，来压缩传输数据量的编码图像，也称为双向预测帧\nPTS-显示时间戳\nDTS-解码时间戳\n流程 步骤 对应函数 打开输入媒体文件 avformat_open_input 获取输入流信息 avformat_find_stream_info 创建输出流上下文 avformat_alloc_output_context2 创建输出码流的AVStream avformat_new_stream 拷贝编码参数 avcodec_parameters_copy 写入视频文件头 avformat_write_header 读取输入视频流 av_read_frame 计算pts/dts/duration av_rescale_q_rnd/av_rescale_q 写入视频流数据 av_interleaved_write_frame 写入视频文件末尾 av_write_trailer 代码 mp4toflv.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 #include \u0026lt;libavutil/avutil.h\u0026gt; #include \u0026lt;libavformat/avformat.h\u0026gt; int main(int argc, char **argv) { av_log_set_level(AV_LOG_DEBUG); if (argc \u0026lt; 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;infileName\u0026gt; \u0026lt;outfileName\u0026gt;\\n\u0026#34;, argv[0]); return -1; } const char *inFileName = argv[1]; const char *outFileName = argv[2]; AVFormatContext *inFmtCtx = NULL; int ret = avformat_open_input(\u0026amp;inFmtCtx, inFileName, NULL, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input format failed:%s\\n\u0026#34;, av_err2str(ret)); return -1; } ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find input stream failed:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } AVFormatContext *outFmtCtx = NULL; // 分配输出格式上下文 ret = avformat_alloc_output_context2(\u0026amp;outFmtCtx, NULL, NULL, outFileName); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;alloc output format failed:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } // 输入文件的流数量 int streamCount = inFmtCtx-\u0026gt;nb_streams; // 分配一个整数数组，用于存储输入流索引到输出流索引的映射关系，并将其初始化为零 int *handleStreamIndexArray = av_malloc_array(streamCount, sizeof(int)); if (handleStreamIndexArray == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;malloc handle stream index array failed\\n\u0026#34;); goto fail; } int streamIndex = 0; // 用于多媒体处理的循环，主要功能是将输入文件中的音视频流复制到输出文件中 for (int i = 0; i \u0026lt; streamCount; i++) { // 获取输入文件的流 AVStream *inStream = inFmtCtx-\u0026gt;streams[i]; // 判断流的类型（视频，音频或字幕） if (inStream-\u0026gt;codecpar-\u0026gt;codec_type != AVMEDIA_TYPE_VIDEO \u0026amp;\u0026amp; inStream-\u0026gt;codecpar-\u0026gt;codec_type != AVMEDIA_TYPE_AUDIO \u0026amp;\u0026amp; inStream-\u0026gt;codecpar-\u0026gt;codec_type != AVMEDIA_TYPE_SUBTITLE) { // 不处理该流 handleStreamIndexArray[i] = -1; continue; } handleStreamIndexArray[i] = streamIndex++; // 创建新的输出流 AVStream *outStream = NULL; // 在输出文件中创建一个新的流 outStream = avformat_new_stream(outFmtCtx, NULL); if (outStream == NULL) { ret = -1; av_log(NULL, AV_LOG_ERROR, \u0026#34;new output stream failed\\n\u0026#34;); goto fail; } // 复制编解码器参数 avcodec_parameters_copy(outStream-\u0026gt;codecpar, inStream-\u0026gt;codecpar); // 设置输出流的编解码器标签为0 outStream-\u0026gt;codecpar-\u0026gt;codec_tag = 0; } // 判断outFmtCtx-\u0026gt;oformat-\u0026gt;flags是否包含AVFMT_NOFILE标志 [\u0026amp;解释（点击跳转）](https://www.notion.so/if-outFmtCtx-oformat-flags-AVFMT_NOFILE-1187c25c79d08036bde1c286d0b3c943?pvs=21) if (!(outFmtCtx-\u0026gt;oformat-\u0026gt;flags \u0026amp; AVFMT_NOFILE)) { // 以写入模式打开 ret = avio_open(\u0026amp;outFmtCtx-\u0026gt;pb, outFileName, AVIO_FLAG_WRITE); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open output file failed:%s\\n\u0026#34;, outFileName); goto fail; } } // 将输出文件的头部信息写入到输出文件中 ret = avformat_write_header(outFmtCtx, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;write header failed:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } AVPacket *packet = av_packet_alloc(); // 读取输入文件的数据包 while (av_read_frame(inFmtCtx, packet) == 0) { if (packet-\u0026gt;stream_index \u0026gt;= streamCount || handleStreamIndexArray[packet-\u0026gt;stream_index == -1]) { av_packet_unref(packet); } // 获取输入输出文件中对应流索引的流 AVStream *inStream = inFmtCtx-\u0026gt;streams[packet-\u0026gt;stream_index]; AVStream *outStream = outFmtCtx-\u0026gt;streams[packet-\u0026gt;stream_index]; packet-\u0026gt;stream_index = handleStreamIndexArray[packet-\u0026gt;stream_index]; packet-\u0026gt;pts = av_rescale_q(packet-\u0026gt;pts, inStream-\u0026gt;time_base, outStream-\u0026gt;time_base); packet-\u0026gt;dts = av_rescale_q(packet-\u0026gt;dts, inStream-\u0026gt;time_base, outStream-\u0026gt;time_base); packet-\u0026gt;duration = av_rescale_q(packet-\u0026gt;duration, inStream-\u0026gt;time_base, outStream-\u0026gt;time_base); // 将数据包的位置设置为-1 packet-\u0026gt;pos = -1; ret = av_interleaved_write_frame(outFmtCtx, packet); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;write interleaved failed:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } av_packet_unref(packet); } ret = av_write_trailer(outFmtCtx); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;write trailer failed :%s\\n\u0026#34;, av_err2str(ret)); } fail: if (inFmtCtx) { avformat_close_input(\u0026amp;inFmtCtx); } if (outFmtCtx \u0026amp;\u0026amp; !(outFmtCtx-\u0026gt;oformat-\u0026gt;flags \u0026amp; AVFMT_NOFILE)) { avio_closep(\u0026amp;outFmtCtx-\u0026gt;pb); } if (outFmtCtx) { avformat_free_context(outFmtCtx); } if (handleStreamIndexArray) { av_freep(\u0026amp;handleStreamIndexArray); } return ret; } 截取封装文件 时间基与时间戳 时间基：时间刻度，表示每个刻度多少秒（就像一把尺子的刻度）\n时间戳：表示占多少个时间刻度，单位不是秒，而是时间刻度（多少多少cm）\n时间基和时间戳相乘就是时间\nPTS：显示时间戳，在什么时候开始显示这一帧数据，转成时间：PTS * 时间基\nDTS：解码时间戳，在什么时候开始解码这一帧数据，转成时间：DTS * 时间基\n流程 截取封装文件处理流程和转封装流程几乎一样，只是多了一个跳转指定时间戳的步骤。以下是详细流程：\n步骤 对应函数 1. 打开输入媒体文件 avformat_open_input 2. 获取输入流信息 avformat_find_stream_info 3. 创建输出流上下文 avformat_alloc_output_context2 4. 创建输出码流的AVStream avformat_new_stream 5. 拷贝编码参数 avcodec_parameters_copy 6. 写入视频文件头 avformat_write_header 7. 读取输入视频流 av_read_frame 8. 跳转指定时间戳 av_seek_frame 9. 计算pts/dts/duration av_rescale_q_rnd/av_rescale_q 10. 写入视频流数据 av_interleaved_write_frame 11. 写入视频文件末尾 av_write_trailer 代码 demuxing_dir.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 #include \u0026lt;libavutil/avutil.h\u0026gt; #include \u0026lt;libavformat/avformat.h\u0026gt; #include \u0026lt;libavcodec/avcodec.h\u0026gt; int main(int argc, char **argv) { // 设置日志级别 av_log_set_level(AV_LOG_INFO); if (argc \u0026lt; 2) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage:%s \u0026lt;infileName\u0026gt;\\n\u0026#34;, argv[0]); } const char *inFileName = argv[1]; // 打开输入文件 AVFormatContext *inFmtCtx = NULL; // 用于存储输入文件的格式信息 avformat_open_input(\u0026amp;inFmtCtx, inFileName, NULL, NULL); // 打开输入文件inFileName，并将格式信息存储在inFmtCtx中 avformat_find_stream_info(inFmtCtx, NULL); // 查找输入文件的流信息，并将流信息存储在inFmtCtx中 av_dump_format(inFmtCtx, 0, inFileName, 0); // 打印输入文件inFileName的格式信息 av_log(NULL, AV_LOG_INFO, \u0026#34;input file duration:%ld us, %lf s \\n\u0026#34;, inFmtCtx-\u0026gt;duration, inFmtCtx-\u0026gt;duration * av_q2d(AV_TIME_BASE_Q)); // 打印输入文件的总时长，单位为微秒和秒 AV_TIME_BASE_Q是ffmpeg内部的时间基，值为{1, AV_TIME_BASE}，AV_TIME_BASE的值为1000000，即1秒 // AVRational是ffmpeg内部的时间基，值为{num, den}，num为分子，den为分母 AVRational videoTimeBase; AVRational audioTimeBase; for (int i = 0; i \u0026lt; inFmtCtx-\u0026gt;nb_streams; i++) // 遍历输入文件中的所有流 { AVStream *inStream = inFmtCtx-\u0026gt;streams[i]; // 获取输入文件中的第i个流 // 分别判断是否为音频或视频流 if (inStream-\u0026gt;codecpar-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO) { videoTimeBase = inStream-\u0026gt;time_base; av_log(NULL, AV_LOG_INFO, \u0026#34;video timebase:num = %d,den = %d\\n\u0026#34;, videoTimeBase.num, videoTimeBase.den); } else if (inStream-\u0026gt;codecpar-\u0026gt;codec_type == AVMEDIA_TYPE_AUDIO) { audioTimeBase = inStream-\u0026gt;time_base; av_log(NULL, AV_LOG_INFO, \u0026#34;audio timebase:num = %d,den = %d\\n\u0026#34;, audioTimeBase.num, audioTimeBase.den); } } AVPacket *packet = av_packet_alloc(); // 分配一个AVPacket结构体，用于存储解码后的数据 while (av_read_frame(inFmtCtx, packet) \u0026gt;= 0) // 循环读取输入文件中的每个数据包，并将数据包存储在packet中 { AVStream *inStream = inFmtCtx-\u0026gt;streams[packet-\u0026gt;stream_index]; // 获取当前数据包所属的流 av_log(NULL, AV_LOG_INFO, \u0026#34;streamIndex = %d,pts = %ld,ptsTime = %lf,dts = %ld,dtsTime = %lf\\n\u0026#34;, packet-\u0026gt;stream_index, packet-\u0026gt;pts, packet-\u0026gt;pts * av_q2d(inStream-\u0026gt;time_base), packet-\u0026gt;dts, packet-\u0026gt;dts * av_q2d(inStream-\u0026gt;time_base)); // 打印当前数据包的流索引、pts、pts时间、dts、dts时间 } return 0; } 视频解码 如何使用ffmpeg接口对视频解码\nRGB介绍 三原色：RGB色彩模式是工业界的一种颜色标准，是通过对红(R)、绿(G)、蓝(B)三个颜色通道的变化以及它们相互之间的叠加来得到各式各样的颜色的，RGB即是代表红、绿、蓝三个通道的颜色，这个标准几乎包括了人类视力所能感知的所有颜色，是目前运用最广的颜色系统之一。\n显示器：使用RGB三种颜色的发光体作为基本发光单元\n分辨率：手机屏幕分辨率是1280*720，表示屏幕上有1280*720个像素点，每个像素点由RGB三种颜色组成\nRGB格式 调色版：通过编号映射到颜色的一张二维表，如01索引，表示红色 索引格式： RGB1、RGB4、RGB8 是计算机图形学中常见的颜色编码格式，它们代表了不同的颜色深度和存储方式。以下是对这些格式的解释：\nRGB1：\n颜色深度：1位（bit）。 颜色数量：2种颜色（通常是黑色和白色）。 应用场景：常用于早期的单色显示器或简单的图形界面，如文本模式下的显示。 RGB4：\n颜色深度：4位（bit）。 颜色数量：16种颜色。 应用场景：常用于早期的彩色显示器或低分辨率图形界面，如早期的计算机游戏或简单的图形应用程序。 RGB8：\n颜色深度：8位（bit）。 颜色数量：256种颜色。 应用场景：常用于早期的彩色显示器或低分辨率图形界面，如早期的计算机游戏、网页设计中的调色板模式等。 这些格式在现代计算机图形处理中已经较少使用，但在某些特定的应用场景或历史研究中仍然具有参考价值。 像素格式：。。。（后续觉得有必要再补上）\n命令\nffmpeg命令将图片转RGB数据\n1 ffmpeg -i input.png -pix_fmt rgb24 output.rgb 注意输出信息中会输出图片大小，下面的ffplay需要用\n1 Stream #0:0: Video: png, rgba(pc, gbr/bt709/iec61966-2-1), 1920x1200 [SAR 5669:5669 DAR 8:5], 25 fps, 25 tbr, 25 tbn ffplay命令播放RGB数据\n1 ffplay -f output.rgb -pix_fmt rgb24 -s widthxheight output.rgb 其中，width 和 height 是图片的宽度和高度，是必要的信息。\n通过解码，会发现照片内存明显变大，因为RGB格式存储了更多的颜色信息，所以我们需要对照片进行编码\nTODO完善\nYUV介绍 YUV 是一种颜色编码系统，常用于视频和图像处理中。Y 代表亮度（Luminance），U 和 V 代表色度（Chrominance）。YUV 格式有多种变体，如 YUV420、YUV422、YUV444 等。\n流程 函数名 描述 av_find_best_stream 在媒体文件中查找最佳流 avcodec_alloc_context3 分配一个编解码器上下文 avcodec_parameters_to_context 复制编解码器参数 avcodec_find_decoder 查找并获取视频解码器 avcodec_open2 打开解码器上下文，并与指定的解码器关联 av_read_frame 读取帧 avcodec_send_packet 发送数据包到解码器 avcodec_receive_frame 从解码器接收帧 输入指令\n1 2 ./demoBin ../video/test.mp4 test.yuv ffplay test.yuv -video_size 720x1280 -pixel_format yuv420p 如果播放的视频乱码，主要是由于width和linesize大小不一样 后续的更改视频格式的时候会解决这个问题\n代码 decodeVideo.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; #include \u0026#34;libavcodec/avcodec.h\u0026#34; // 定义一个全局变量，用于记录解码的帧数 int frameCount = 0; // 解码视频帧的函数 int decodeVideo(AVCodecContext *codecCtx, AVPacket *packet, FILE *dest_fp) { // 将数据包发送到解码器 int ret = avcodec_send_packet(codecCtx, packet); if (ret != 0) { // 如果发送失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not send packet:%s\\n\u0026#34;, av_err2str(ret)); return -1; } // 分配一个AVFrame结构体，用于存储解码后的帧数据 AVFrame *frame = av_frame_alloc(); // 循环接收解码后的帧数据 while (avcodec_receive_frame(codecCtx, frame) == 0) { // 将帧数据写入输出文件 fwrite(frame-\u0026gt;data[0], 1, codecCtx-\u0026gt;width * codecCtx-\u0026gt;height, dest_fp); fwrite(frame-\u0026gt;data[1], 1, codecCtx-\u0026gt;width * codecCtx-\u0026gt;height / 4, dest_fp); fwrite(frame-\u0026gt;data[2], 1, codecCtx-\u0026gt;width * codecCtx-\u0026gt;height / 4, dest_fp); // 增加帧计数 frameCount++; // 记录当前帧数 av_log(NULL, AV_LOG_INFO, \u0026#34;frameCount:%d\\n\u0026#34;, frameCount); } // 如果帧数据不为空，释放帧内存 if (frame) { av_frame_free(\u0026amp;frame); } return 0; } int main(int argc, char **argv) { // 设置日志级别为调试模式 av_log_set_level(AV_LOG_DEBUG); // 检查命令行参数是否正确 if (argc \u0026lt; 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input\u0026gt; \u0026lt;output\u0026gt;\\n\u0026#34;, argv[0]); return -1; } // 获取输入和输出文件名 const char *inFileName = argv[1]; const char *outFileName = argv[2]; // 定义一个AVFormatContext结构体，用于存储输入文件的格式信息 AVFormatContext *inFmtCtx = NULL; // 打开输入文件 int ret = avformat_open_input(\u0026amp;inFmtCtx, inFileName, NULL, NULL); if (ret != 0) { // 如果打开失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open input file %s\\n\u0026#34;, inFileName); return -1; } // 获取输入文件的流信息 ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret \u0026lt; 0) { // 如果获取失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find stream information:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } // 查找最佳的视频流索引 ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { // 如果查找失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find best stream index:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } // 获取视频流的索引 int videoIndex = ret; // 分配一个AVCodecContext结构体，用于存储解码器上下文信息 AVCodecContext *codecCtx = avcodec_alloc_context3(NULL); if (codecCtx == NULL) { // 如果分配失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not allocate codec context\\n\u0026#34;); ret = -1; goto fail; } // 将流参数复制到解码器上下文 avcodec_parameters_to_context(codecCtx, inFmtCtx-\u0026gt;streams[videoIndex]-\u0026gt;codecpar); // 查找解码器 const AVCodec *decoder = avcodec_find_decoder(codecCtx-\u0026gt;codec_id); if (decoder == NULL) { // 如果查找失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find codec\\n\u0026#34;); ret = -1; goto fail; } // 打开解码器 ret = avcodec_open2(codecCtx, decoder, NULL); if (ret != 0) { // 如果打开失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open codec:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } // 打开输出文件 FILE *dest_fp = fopen(outFileName, \u0026#34;wb+\u0026#34;); if (dest_fp == NULL) { // 如果打开失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open output file %s\\n\u0026#34;, outFileName); ret = -1; goto fail; } // 分配一个AVPacket结构体，用于存储数据包 AVPacket *packet = av_packet_alloc(); // 分配一个AVFrame结构体，用于存储解码后的帧数据 AVFrame *frame = av_frame_alloc(); // 循环读取输入文件中的数据包 while (av_read_frame(inFmtCtx, packet) \u0026gt;= 0) { // 如果数据包属于视频流ff if (packet-\u0026gt;stream_index == videoIndex) { // 解码视频帧 if (decodeVideo(codecCtx, packet, dest_fp) == -1) { ret = -1; av_packet_unref(packet); goto fail; } // 释放数据包引用 av_packet_unref(packet); } } // 刷新解码器，确保所有帧都被解码 decodeVideo(codecCtx, NULL, dest_fp); fail: // 如果输入文件格式上下文不为空，关闭输入文件 if (inFmtCtx) { avformat_close_input(\u0026amp;inFmtCtx); } // 如果解码器上下文不为空，释放解码器上下文 if (codecCtx) { avcodec_free_context(\u0026amp;codecCtx); } // 如果输出文件指针不为空，关闭输出文件 if (dest_fp) { fclose(dest_fp); } return ret; } 更改视频格式 流程 函数名 描述 av_parse_video_size 解析视频尺寸字符串（如 \u0026ldquo;1920x1080\u0026rdquo;）并返回宽度和高度。 sws_getContext 创建一个 SwsContext，用于图像缩放和格式转换。 av_frame_alloc 分配一个 AVFrame 结构体，用于存储解码后的视频帧。 av_image_get_buffer_size 计算给定图像格式和尺寸所需的缓冲区大小。 av_malloc 分配内存，用于存储图像数据。 av_image_fill_arrays 将图像数据填充到 AVFrame 的缓冲区中，并设置相关的行大小和数据指针。 sws_scale 使用 SwsContext 对图像进行缩放或格式转换。 代码 decodeVideoChange.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libswscale/swscale.h\u0026#34; #include \u0026#34;libavutil/parseutils.h\u0026#34; #include \u0026#34;libavutil/imgutils.h\u0026#34; // 定义一个全局变量，用于记录解码的帧数 int frameCount = 0; // 解码视频帧的函数 int decodeVideo(AVCodecContext *codecCtx, AVPacket *packet, struct SwsContext *swsCtx, int destWidth, int destHeight, AVFrame *destFrame, FILE *dest_fp) { // 将数据包发送到解码器 int ret = avcodec_send_packet(codecCtx, packet); if (ret != 0) { // 如果发送失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not send packet:%s\\n\u0026#34;, av_err2str(ret)); return -1; } // 分配一个AVFrame结构体，用于存储解码后的帧数据 AVFrame *frame = av_frame_alloc(); // 循环接收解码后的帧数据 while (avcodec_receive_frame(codecCtx, frame) == 0) { sws_scale(swsCtx, (const uint8_t *const*)frame-\u0026gt;data, frame-\u0026gt;linesize, 0, codecCtx-\u0026gt;height, destFrame-\u0026gt;data, destFrame-\u0026gt;linesize); // 将帧数据写入输出文件 fwrite(destFrame-\u0026gt;data[0], 1, destWidth * destHeight, dest_fp); fwrite(destFrame-\u0026gt;data[1], 1, destWidth * destHeight / 4, dest_fp); fwrite(destFrame-\u0026gt;data[2], 1, destWidth * destHeight / 4, dest_fp); // 增加帧计数 frameCount++; // 记录当前帧数 av_log(NULL, AV_LOG_INFO, \u0026#34;frameCount:%d\\n\u0026#34;, frameCount); // 输出宽高信息,linesize0 1 2 av_log(NULL, AV_LOG_INFO, \u0026#34;width:%d,height:%d,linesize0:%d,linesize1:%d,linesize2:%d\\n\u0026#34;, destWidth, destHeight, destFrame-\u0026gt;linesize[0], destFrame-\u0026gt;linesize[1], destFrame-\u0026gt;linesize[2]); } // 如果帧数据不为空，释放帧内存 if (frame) { av_frame_free(\u0026amp;frame); } return 0; } int main(int argc, char **argv) { // 设置日志级别为调试模式 av_log_set_level(AV_LOG_DEBUG); // 检查命令行参数是否正确 if (argc \u0026lt; 4) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input\u0026gt; \u0026lt;output\u0026gt; \u0026lt;width*height\u0026gt;\\n\u0026#34;, argv[0]); return -1; } // 获取输入和输出文件名 const char *inFileName = argv[1]; const char *outFileName = argv[2]; const char *destVideoSizeString = argv[3]; int destWidth = 0, destHeight = 0; int ret = av_parse_video_size(\u0026amp;destWidth, \u0026amp;destHeight, destVideoSizeString); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;invalid video size:%s\\n\u0026#34;, destVideoSizeString); return -1; } av_log(NULL, AV_LOG_INFO, \u0026#34;destWith:%d,destHeight:%d\\n\u0026#34;, destWidth, destHeight); // 定义一个AVFormatContext结构体，用于存储输入文件的格式信息 AVFormatContext *inFmtCtx = NULL; // 打开输入文件 ret = avformat_open_input(\u0026amp;inFmtCtx, inFileName, NULL, NULL); if (ret != 0) { // 如果打开失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open input file %s\\n\u0026#34;, inFileName); return -1; } // 获取输入文件的流信息 ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret \u0026lt; 0) { // 如果获取失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find stream information:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } // 查找最佳的视频流索引 ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { // 如果查找失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find best stream index:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } // 获取视频流的索引 int videoIndex = ret; // 分配一个AVCodecContext结构体，用于存储解码器上下文信息 AVCodecContext *codecCtx = avcodec_alloc_context3(NULL); if (codecCtx == NULL) { // 如果分配失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not allocate codec context\\n\u0026#34;); ret = -1; goto fail; } // 将流参数复制到解码器上下文 avcodec_parameters_to_context(codecCtx, inFmtCtx-\u0026gt;streams[videoIndex]-\u0026gt;codecpar); // 查找解码器 const AVCodec *decoder = avcodec_find_decoder(codecCtx-\u0026gt;codec_id); if (decoder == NULL) { // 如果查找失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find codec\\n\u0026#34;); ret = -1; goto fail; } // 打开解码器 ret = avcodec_open2(codecCtx, decoder, NULL); if (ret != 0) { // 如果打开失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open codec:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } enum AVPixelFormat destPixfmt = codecCtx-\u0026gt;pix_fmt; struct SwsContext *swsCtx = sws_getContext(codecCtx-\u0026gt;width, codecCtx-\u0026gt;height, codecCtx-\u0026gt;pix_fmt, destWidth, destHeight, destPixfmt, SWS_BICUBIC, NULL, NULL, NULL); if (swsCtx == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not create SwsContext\\n\u0026#34;); ret = -1; goto fail; } AVFrame *destFrame = av_frame_alloc(); uint8_t *outBuffer = av_malloc(av_image_get_buffer_size(destPixfmt, destWidth, destHeight, 1)); av_image_fill_arrays(destFrame-\u0026gt;data, destFrame-\u0026gt;linesize, outBuffer, destPixfmt, destWidth, destHeight, 1); // 打开输出文件 FILE *dest_fp = fopen(outFileName, \u0026#34;wb+\u0026#34;); if (dest_fp == NULL) { // 如果打开失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open output file %s\\n\u0026#34;, outFileName); ret = -1; goto fail; } // 分配一个AVPacket结构体，用于存储数据包 AVPacket *packet = av_packet_alloc(); // 分配一个AVFrame结构体，用于存储解码后的帧数据 AVFrame *frame = av_frame_alloc(); // 循环读取输入文件中的数据包 while (av_read_frame(inFmtCtx, packet) \u0026gt;= 0) { // 如果数据包属于视频流 if (packet-\u0026gt;stream_index == videoIndex) { // 解码视频帧 // if (decodeVideo(codecCtx, packet, dest_fp) == -1) if (decodeVideo(codecCtx, packet, swsCtx, destWidth, destHeight, destFrame, dest_fp) == -1) { ret = -1; av_packet_unref(packet); goto fail; } // 释放数据包引用 av_packet_unref(packet); } } // 刷新解码器，确保所有帧都被解码 // decodeVideo(codecCtx, NULL, dest_fp); decodeVideo(codecCtx, NULL, swsCtx, destWidth, destHeight, destFrame, dest_fp); fail: // 如果输入文件格式上下文不为空，关闭输入文件 if (inFmtCtx) { avformat_close_input(\u0026amp;inFmtCtx); } // 如果解码器上下文不为空，释放解码器上下文 if (codecCtx) { avcodec_free_context(\u0026amp;codecCtx); } // 如果输出文件指针不为空，关闭输出文件 if (dest_fp) { fclose(dest_fp); } if (destFrame) { av_frame_free(\u0026amp;destFrame); } if (outBuffer) { av_free(outBuffer); } return ret; } 解码后的数据存储 解码后的视频数据通常存储在 data[0]、data[1]、data[2] 等数组中。具体来说：\ndata[0]: 存储了 linesize[0] * height 个数据。 data[1] 和 data[2]: 存储了其他平面的数据（如YUV格式中的U和V平面）。 内存对齐和 linesize linesize[0]: 实际上并不等于图像的宽度 width，而是比宽度大。 这种差异是由于内存对齐的需求，以及解码器的CPU和其他优化原因导致的。 sws_scale 函数功能 sws_scale 函数是 FFmpeg 中用于图像缩放和格式转换的核心函数。它主要完成以下功能：\n图像色彩空间转换：\n将图像从一种色彩空间转换为另一种色彩空间，例如从 RGB 转换为 YUV，或者从 YUV420P 转换为 YUV444P。 分辨率缩放：\n调整图像的分辨率，例如将 1920x1080 的图像缩放到 1280x720。 前后图像滤波处理：\n在进行缩放和色彩空间转换时，应用滤波器以平滑图像，减少锯齿和伪影。 BMP文件格式 概念：BMP文件格式，又称为Bitmap（位图）或是DIB（Device-Independent Device，设备无光位图），是Windows操作系统中的标准图像文件格式。由于它可以不作任何变换地保存图像像素域的数据，因此成为我们取得RAW数据的好来源。\n扫描方式：从左到右，从下到上\n文件组成：\n位图文件头（Bitmap File Header）：提供文件的格式，大小等信息 位图信息头（Bitmap Information）：提供图像的尺寸，位平面数，压缩方式，颜色索引等信息。 调色板（Color Palette）：可选，有些位图需要调色板，有些位图，比如真彩色图（24位的BMP）就不需要调色板。 位图数据（Bitmap Data）：图像数据区 文件头结构体：\n1 2 3 4 5 6 7 typedef struct tagBITMAPFILEHEADER { WORD bfType; // 文件类型，必须是0x424D，即字符“BM” DWORD bfSize; // bmp文件大小 WORD bfReserved1; // 保留字 WORD bfReserved2; // 保留字 DWORD bfOffBits; // 实际位图数据的偏移字节数，即前三个部分长度之和 } BITMAPFILEHEADER; 信息头结构体：\n1 2 3 4 5 6 7 8 9 10 11 12 13 typedef struct tagBITMAPINFOHEADER { DWORD biSize; //表示struct tagBITMAPINFOHEADER的长度，设为40 LONG biWidth; //bmp图片宽度 LONG biHeight; //bmp图片高度 WORD biPlanes; //bmp图片平面树，设为1 WORD biBitCount; //bmp图片位数，即1位图，4位图，8位图，24位图等 DWORD biCompression; //bmp图片压缩类型，0表示不压缩 DWORD biSizeImage; //bmp图片数据大小，必须是4的整数倍 LONG biXPelsPerMeter; //bmp图片水平分辨率 LONG biYPelsPerMeter; //bmp图片垂直分辨率 DWORD biClrUsed; //bmp图片实际使用的颜色表中的颜色数 DWORD biClrImportant; //bmp图片对显示有重要影响的颜色索引的数目 } BITMAPINFOHEADER; 视频编码（yuv到h264） 流程 函数名 描述 avcodec_find_encoder 查找编码器 avcodec_alloc_context3 创建编码器上下文 avcodec_open2 打开编码器 av_frame_alloc 分配帧内存 av_image_get_buffer_size 获取图像缓冲区大小 av_image_fill_arrays 填充图像数据数组 avcodec_send_frame 发送帧到编码器 avcodec_receive_packet 从编码器接收数据包 代码 encodeVideoDemo.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026#34;libavutil/parseutils.h\u0026#34; #include \u0026lt;libavcodec/codec.h\u0026gt; #include \u0026lt;libavcodec/packet.h\u0026gt; #include \u0026lt;libavutil/frame.h\u0026gt; #include \u0026lt;libavutil/imgutils.h\u0026gt; #include \u0026lt;libavutil/log.h\u0026gt; #include \u0026lt;libavutil/rational.h\u0026gt; #include \u0026lt;time.h\u0026gt; int writePacketCount = 0; int encodeVideo(AVCodecContext *encoderCtx, AVFrame *frame, AVPacket *packet, FILE *dest_fp) { int ret = avcodec_send_frame(encoderCtx, frame); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;send frame error:%s\\n\u0026#34;, av_err2str(ret)); return -1; } while (ret \u0026gt;= 0) { avcodec_receive_packet(encoderCtx, packet); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) { return 0; } else if (ret \u0026lt; 0) { av_log(NULL,AV_LOG_ERROR,\u0026#34;encoder frrame failed:%s\\n\u0026#34;,av_err2str(ret)); return -1; } fwrite(packet-\u0026gt;data, 1, packet-\u0026gt;size, dest_fp); writePacketCount++; av_log(NULL,AV_LOG_INFO,\u0026#34;writePacketCount : %d\\n\u0026#34;,writePacketCount); av_packet_unref(packet); } } int main(int argc, char **argv) { av_log_set_level(AV_LOG_INFO); if (argc \u0026lt; 5) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;inFile\u0026gt; \u0026lt;outFile\u0026gt; \u0026lt;encodeName\u0026gt; \u0026lt;width x height\u0026gt;\\n\u0026#34;, argv[0]); return -1; } const char *inFileName = argv[1]; const char *outFileName = argv[2]; const char *encoderName = argv[3]; int width = 0, height = 0; int ret = av_parse_video_size(\u0026amp;width, \u0026amp;height, argv[4]); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Invalid size \u0026#39;%s\u0026#39;, must be in the form WxH or a valid size abbreviation\\n\u0026#34;, argv[4]); return -1; } enum AVPixelFormat pixFmt = AV_PIX_FMT_YUV420P; int fps = 30; const AVCodec *encoder = avcodec_find_encoder_by_name(encoderName); if (encoder == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find encoder %s failed\\n\u0026#34;, encoderName); return -1; } AVCodecContext *encoderCtx = avcodec_alloc_context3(encoder); if (encoderCtx == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;alloc encoder context failed!\\n\u0026#34;); return -1; } encoderCtx-\u0026gt;codec_type = AVMEDIA_TYPE_VIDEO; encoderCtx-\u0026gt;pix_fmt = pixFmt; encoderCtx-\u0026gt;width = width; encoderCtx-\u0026gt;height = height; encoderCtx-\u0026gt;time_base = (AVRational){1, fps}; encoderCtx-\u0026gt;bit_rate = 4096000; encoderCtx-\u0026gt;max_b_frames = 0; encoderCtx-\u0026gt;gop_size = 10; ret = avcodec_open2(encoderCtx, encoder, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open encoder failed! %s\\n\u0026#34;, av_err2str(ret)); goto end; } FILE *src_fp = fopen(inFileName, \u0026#34;rb\u0026#34;); if (src_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open infilename error\u0026#34;); ret = -1; goto end; } FILE *dest_fp = fopen(outFileName, \u0026#34;wb\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open outfilename error\u0026#34;); ret = -1; goto end; } AVFrame *frame = av_frame_alloc(); int frameSize = av_image_get_buffer_size(pixFmt, width, height, 1); uint8_t *frameBuffer = av_malloc(frameSize); av_image_fill_arrays(frame-\u0026gt;data, frame-\u0026gt;linesize, frameBuffer, pixFmt, width, height, 1); int pictureSize = width * height; AVPacket *packet = av_packet_alloc(); int readFrameCount = 0; while (fread(frameBuffer, 1, pictureSize * 3 / 2, src_fp) == pictureSize * 3 / 2) { // Y 1 U 1/4 V 1/4 frame-\u0026gt;data[0] = frameBuffer; frame-\u0026gt;data[1] = frameBuffer + pictureSize; frame-\u0026gt;data[2] = frameBuffer + pictureSize + pictureSize / 4; readFrameCount++; av_log(NULL, AV_LOG_INFO, \u0026#34;readFrameCount: %d\\n\u0026#34;, readFrameCount); encodeVideo(encoderCtx, frame, packet, dest_fp); } end: if (encoderCtx) { avcodec_free_context(\u0026amp;encoderCtx); } if (src_fp) { fclose(src_fp); } if (dest_fp) { fclose(dest_fp); } if (frameBuffer) { av_freep(\u0026amp;frameBuffer); } return ret; } 音频解码 PCM介绍 PCM（Pulse Code Modulation）是一种用于数字音频的标准编码格式。它通过将模拟音频信号转换为数字信号来表示音频数据。PCM 编码的基本原理是将模拟音频信号在时间上进行采样，并将每个采样点的幅度值量化为离散的数字值。\n核心过程：采样-\u0026gt;量化-\u0026gt;编码\nPCM关键要素 采样率（Sample Rate）：每秒采样的次数，常见的采样率有 44.1 kHz、48 kHz 等。 量化格式（Sample Format）：每个采样点的位数，常见的量化格式有 16 位、24 位等。 声道数（Channels）：音频信号的声道数，如单声道、立体声等。 PCM数据格式 存储格式\n双声道：采样数据按LRLR方式存储，即左声道和右声道交替存储，存储的时候与字节序有关。 单声道：采样数据按时间顺序存储（有时也会采用LRLR方式，但另一个声道数据为0）。 存储格式分为Packed和Planner两种，对于双通道音频，Packed为两个声道的数据交错存储;Planner为两个声道的数据分开存储。\nPacked：LRLRLR Planner：LLLRRR ffmpeg音频解码后的数据存放在AVFrame结构体中：\nPacked格式下，frame.data[0]存放所有声道的数据。 Planner格式下，frame.data[i]存放第i个声道的数据。 左声道data[0]:LLLL\u0026hellip; 右声道data[1]:RRRR\u0026hellip; Planner模式是ffmpeg内部存储模式，实际使用的音频文件都是Packed模式。\nPCM计算 大小计算：以CD的音质为例：量化格式为16比特（2字节），采样率为44100，声道数为2。 比特率为：16 * 44100 * 2 = 1378.125 kbps 每秒存储空间：1378.125 * 60/8/1024 = 10.09MB ffmpeg提取pcm数据命令： 1 ffmpeg -i input.aac -ar 48000 -ac 2 -f s16le output.pcm ffplay播放pcm数据命令： 1 ffplay -ar 48000 -ac 2 -f s16le output.pcm 通过上述指令播放不成功的话，可以尝试转换PCM文件\n1 2 ffmpeg -f s16le -ar 48000 -ac 2 -i output.pcm output_stereo.wav ffplay output_stereo.wav 流程 函数名 描述 avformat_open_input() 打开输入文件或流并读取头部信息。 avformat_find_stream_info() 读取一些数据包以获取流信息。 av_find_best_stream() 查找最佳流（音频、视频或字幕）。 avcodec_alloc_context3() 分配解码器上下文。 avcodec_parameters_to_context() 将流参数复制到解码器上下文中。 avcodec_find_decoder() 查找合适的解码器。 avcodec_open2() 打开解码器。 av_frame_alloc() 分配AVFrame结构体。 av_samples_get_buffer_size() 计算音频缓冲区的大小。 avcodec_fill_audio_frame() 填充音频帧的缓冲区。 av_read_frame() 从输入文件或流中读取数据包。 avcodec_send_packet() 将数据包发送到解码器进行解码。 avcodec_receive_frame() 从解码器接收解码后的帧。 代码 decodeAudio.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026lt;libavcodec/codec.h\u0026gt; #include \u0026lt;libavcodec/packet.h\u0026gt; #include \u0026lt;time.h\u0026gt; int decodeAudio(AVCodecContext *decoderCtx, AVPacket *packet, AVFrame *frame, FILE *dest_fp) { int ret = avcodec_send_packet(decoderCtx, packet); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;send packet to decoder failed: %s\\n\u0026#34;, av_err2str(ret)); return -1; } int channel = 0; while (ret \u0026gt;= 0) { ret = avcodec_receive_frame(decoderCtx, frame); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) { return 0; } else if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;decode packet failed: %s\\n\u0026#34;, av_err2str(ret)); return -1; } int dataSize = av_get_bytes_per_sample(decoderCtx-\u0026gt;sample_fmt); if (dataSize \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;get bytes per sample failed\\n\u0026#34;); return -1; } // frame fltp 2 /* data[0] L L L L data[1] R R R R --\u0026gt; L R L R L R L R */ for (int i = 0; i \u0026lt; frame-\u0026gt;nb_samples; i++) { for (channel = 0; channel \u0026lt; decoderCtx-\u0026gt;ch_layout.nb_channels; channel++) { fwrite(frame-\u0026gt;data[channel] + dataSize * i, 1, dataSize, dest_fp); } } } return 0; } int main(int argc, char **argv) { av_log_set_level(AV_LOG_DEBUG); if (argc \u0026lt; 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input\u0026gt; \u0026lt;output\u0026gt;\\n\u0026#34;, argv[0]); } const char *inFileName = argv[1]; const char *outFileName = argv[2]; AVFormatContext *inFmtCtx = NULL; int ret = avformat_open_input(\u0026amp;inFmtCtx, inFileName, NULL, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open %s failed\\n\u0026#34;, inFileName); return -1; } ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find stream error:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_AUDIO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find best stream error:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } int audioStreamIndex = ret; AVCodecContext *decoderCtx = avcodec_alloc_context3(NULL); if (decoderCtx == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;alloc codec context failed\\n\u0026#34;); goto fail; } ret = avcodec_parameters_to_context(decoderCtx, inFmtCtx-\u0026gt;streams[audioStreamIndex]-\u0026gt;codecpar); const AVCodec *decoder = avcodec_find_decoder(decoderCtx-\u0026gt;codec_id); if (decoder == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find decoder %d failed\\n\u0026#34;, decoderCtx-\u0026gt;codec_id); ret = -1; goto fail; } ret = avcodec_open2(decoderCtx, decoder, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open decoder error:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } FILE *dest_fp = fopen(outFileName, \u0026#34;wb\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open %s failed\\n\u0026#34;, outFileName); ret = -1; goto fail; } AVFrame *frame = av_frame_alloc(); int frameSize = av_samples_get_buffer_size(NULL, decoderCtx-\u0026gt;ch_layout.nb_channels, frame-\u0026gt;nb_samples, decoderCtx-\u0026gt;sample_fmt, 1); uint8_t *frameBuffer = av_malloc(frameSize); avcodec_fill_audio_frame(frame, decoderCtx-\u0026gt;ch_layout.nb_channels, decoderCtx-\u0026gt;sample_fmt, frameBuffer, frameSize, 1); AVPacket *packet = av_packet_alloc(); while (av_read_frame(inFmtCtx, packet) \u0026gt;= 0) { if (packet-\u0026gt;stream_index == audioStreamIndex) { decodeAudio(decoderCtx, packet, frame, dest_fp); } av_packet_unref(packet); } decodeAudio(decoderCtx, NULL, frame, dest_fp); fail: if (inFmtCtx) { avformat_close_input(\u0026amp;inFmtCtx); } if (decoderCtx) { avcodec_free_context(\u0026amp;decoderCtx); } if (frame) { av_frame_free(\u0026amp;frame); } if (frameBuffer) { av_freep(frameBuffer); } if (dest_fp) { fclose(dest_fp); } return ret; } 运行指令\n1 2 3 4 5 ./demoBin ../video/test.aac ../video/test_decode_by_code.pcm ffmpeg -f f32le -ar 44100 -ac 2 -i ../video/test_decode_by_code.pcm ../video/test_decode_by_code_stereo.wav ffplay ../video/test_decode_by_code_stereo.wav 音频编码 流程 函数名 描述 av_frame_alloc 分配一个AVFrame结构体 av_frame_get_buffer 为AVFrame分配缓冲区 avcodec_find_encoder_by_name 根据名称查找编码器 avcodec_alloc_context3 分配编码器上下文 avcodec_open2 打开编码器 avcodec_send_frame 发送帧到编码器 avcodec_receive_packet 从编码器接收编码后的数据包 运行指令\n1 2 3 ffmpeg -ac 2 -ar 44100 -f s16le -i test.pcm -acodec libfdk_aac test1.aac ffplay test1.aac 代码 encodeAudioDemo.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026lt;libavcodec/codec.h\u0026gt; #include \u0026lt;libavcodec/packet.h\u0026gt; #include \u0026lt;libavutil/channel_layout.h\u0026gt; #include \u0026lt;libavutil/error.h\u0026gt; #include \u0026lt;libavutil/log.h\u0026gt; #include \u0026lt;libavutil/frame.h\u0026gt; #include \u0026lt;libavutil/samplefmt.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;time.h\u0026gt; int encodeAudio(AVCodecContext *encoderCtx, AVFrame *frame, AVPacket *packet, FILE *dest_fp) { int ret = avcodec_send_frame(encoderCtx, frame); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;send frame to encoder failed:%s\\n\u0026#34;, av_err2str(ret)); return -1; } while (ret \u0026gt;= 0) { ret = avcodec_receive_packet(encoderCtx, packet); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) { return 0; } else if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;receive packet from encoder failed:%s\\n\u0026#34;, av_err2str(ret)); return -1; } fwrite(packet-\u0026gt;data, 1, packet-\u0026gt;size, dest_fp); av_packet_unref(packet); } return 0; } int main(int argc, char **argv) { av_log_set_level(AV_LOG_INFO); if (argc \u0026lt; 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input file\u0026gt; \u0026lt;output file\u0026gt;\\n\u0026#34;, argv[0]); return -1; } const char *inFileName = argv[1]; const char *outFileName = argv[2]; AVFrame *frame = av_frame_alloc(); if (!frame) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not allocate video frame\\n\u0026#34;); return -1; } frame-\u0026gt;sample_rate = 44100; // 这里代码有些不同 frame-\u0026gt;ch_layout.nb_channels = 2; av_channel_layout_from_mask(\u0026amp;frame-\u0026gt;ch_layout, AV_CH_LAYOUT_STEREO); frame-\u0026gt;format = AV_SAMPLE_FMT_S16; frame-\u0026gt;nb_samples = 1024; av_frame_get_buffer(frame, 0); int ret = 0; const AVCodec *encoder = avcodec_find_encoder_by_name(\u0026#34;libfdk_aac\u0026#34;); if (!encoder) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find encoder failed\\n\u0026#34;); ret = -1; goto end; } AVCodecContext *encoderCtx = avcodec_alloc_context3(encoder); if (!encoderCtx) { av_log(NULL, AV_LOG_ERROR, \u0026#34;alloc encoder context failed\\n\u0026#34;); ret = -1; goto end; } encoderCtx-\u0026gt;sample_fmt = frame-\u0026gt;format; encoderCtx-\u0026gt;sample_rate = frame-\u0026gt;sample_rate; encoderCtx-\u0026gt;ch_layout.nb_channels = frame-\u0026gt;ch_layout.nb_channels; encoderCtx-\u0026gt;ch_layout = frame-\u0026gt;ch_layout; ret = avcodec_open2(encoderCtx, encoder, NULL); if (ret \u0026lt; 0) { av_log(NULL,AV_LOG_ERROR,\u0026#34;open encoder failed:%s\\n\u0026#34;,av_err2str(ret)); ret = -1; goto end; } FILE *src_fp = fopen(inFileName, \u0026#34;rb\u0026#34;); if (src_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input file failed\\n\u0026#34;); ret = -1; goto end; } FILE *dest_fp = fopen(outFileName, \u0026#34;wb+\u0026#34;); if (src_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open output file failed\\n\u0026#34;); ret = -1; goto end; } AVPacket *packet = av_packet_alloc(); while (1) { int readSize = fread(frame-\u0026gt;data[0], 1, frame-\u0026gt;linesize[0], src_fp); if (readSize == 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;finish read infile\\n\u0026#34;); break; } encodeAudio(encoderCtx, frame, packet, dest_fp); } encodeAudio(encoderCtx, NULL, packet, dest_fp); end: if (frame) { av_frame_free(\u0026amp;frame); } if (encoderCtx) { avcodec_free_context(\u0026amp;encoderCtx); } if (src_fp) { fclose(src_fp); } if (dest_fp) { fclose(dest_fp); } return ret; } 指令\n1 2 3 ./demoBin test.pcm aac_by_code.aac ffplay aac_by_code.aac 视频采集 视频采集命令 查看设备列表： 1 ffmpeg -hide_banner -devices 查看dshow支持的参数： 1 ffmpeg -h demuxer=dshow 查看dshow支持的设备： 1 ffmpeg -f dshow -list_devices true -i dummy 一般是Integrated Camera，这是本地摄像头\n采集摄像头画面： 1 ffmpeg -f dshow -i video=\u0026#34;Integrated Camera\u0026#34; ./video/output.mp4 播放摄像头采集画面：\n1 ffplay output.mp4 流程 函数名 描述 avdevice_register_all 注册所有可用的设备 avformat_alloc_context 分配格式上下文 av_dict_set 设置字典选项 av_find_input_format 查找输入格式 avformat_open_input 打开输入文件 avformat_find_stream_info 查找流信息 av_find_best_stream 查找最佳流 avcodec_alloc_context3 分配编解码器上下文 avcode_parameters_to_context 将参数复制到上下文 avcodec_find_decoder 查找解码器 avcodec_open2 打开编解码器 av_read_frame 读取帧 avcode_send_packet 发送数据包 avcodec_receive_frame 接收帧 颜色空间格式转换：\n函数名 描述 sws_getContext 获取缩放上下文 av_frame_alloc 分配帧 av_image_get_buffer_size 获取图像缓冲区大小 av_malloc 分配内存 av_image_fill_arrays 填充图像数组 sws_scale 缩放图像 先用ffmpeg指令试一下视频采集格式，后续代码写的时候要用对应采集的格式。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libavdevice/avdevice.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026#34;libavutil/imgutils.h\u0026#34; #include \u0026#34;libswscale/swscale.h\u0026#34; #include \u0026lt;libavcodec/packet.h\u0026gt; #include \u0026lt;libavutil/dict.h\u0026gt; #include \u0026lt;libavutil/frame.h\u0026gt; #include \u0026lt;libavutil/log.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;time.h\u0026gt; // 显示可用的摄像头设备 // ffmpeg -f dshow -list_devices true -i dummy void dshowListDevices() { const AVInputFormat *inFmt = av_find_input_format(\u0026#34;dshow\u0026#34;); if (inFmt == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find dshow failed!\\n\u0026#34;); } // 设置参数 AVDictionary *options = NULL; av_dict_set(\u0026amp;options, \u0026#34;list_devices\u0026#34;, \u0026#34;true\u0026#34;, 0); AVFormatContext *inFmtCtx = avformat_alloc_context(); // 第二个参数是URL int ret = avformat_open_input(\u0026amp;inFmtCtx, \u0026#34;video=Integrated Camera\u0026#34;, inFmt, \u0026amp;options); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input format failed:%s\\n\u0026#34;, av_err2str(ret)); return; } if (inFmtCtx) { avformat_close_input(\u0026amp;inFmtCtx); avformat_free_context(inFmtCtx); } } void decodeVideo(struct SwsContext *swsCtx, AVCodecContext *decoderCtx, AVFrame *destFrame, AVPacket *packet, FILE *dest_fp) { if (avcodec_send_packet(decoderCtx, packet) == 0) { AVFrame *frame = av_frame_alloc(); while (avcodec_receive_frame(decoderCtx, frame) \u0026gt;= 0) { sws_scale(swsCtx, (const uint8_t *const *)frame-\u0026gt;data, frame-\u0026gt;linesize, 0, decoderCtx-\u0026gt;height, destFrame-\u0026gt;data, destFrame-\u0026gt;linesize); fwrite(destFrame-\u0026gt;data[0], 1, decoderCtx-\u0026gt;width * decoderCtx-\u0026gt;height, dest_fp); fwrite(destFrame-\u0026gt;data[1], 1, decoderCtx-\u0026gt;width * decoderCtx-\u0026gt;height / 4, dest_fp); fwrite(destFrame-\u0026gt;data[2], 1, decoderCtx-\u0026gt;width * decoderCtx-\u0026gt;height / 4, dest_fp); } av_frame_free(\u0026amp;frame); } } int main(int argc, char *argv[]) { av_log_set_level(AV_LOG_INFO); if (argc \u0026lt; 2) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage:%s \u0026lt;outFileName\u0026gt; \\n\u0026#34;, argv[0]); return -1; } const char *outFileName = argv[1]; avdevice_register_all(); dshowListDevices(); AVFormatContext *inFmtCtx = avformat_alloc_context(); const AVInputFormat *inFmt = av_find_input_format(\u0026#34;dshow\u0026#34;); if (inFmt == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input format failed!\\n\u0026#34;); goto end; } AVDictionary *options = NULL; av_dict_set(\u0026amp;options, \u0026#34;framerate\u0026#34;, \u0026#34;30\u0026#34;, 0); int ret = avformat_open_input(\u0026amp;inFmtCtx, \u0026#34;video=Integrated Camera\u0026#34;, inFmt, \u0026amp;options); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find stream info failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find best stream failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } int videoIndex = ret; // 创建解码器上下文 AVCodecContext *decoderCtx = avcodec_alloc_context3(NULL); ret = avcodec_parameters_to_context(decoderCtx, inFmtCtx-\u0026gt;streams[videoIndex]-\u0026gt;codecpar); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;copy parameters to context failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } const AVCodec *decoder = avcodec_find_decoder(decoderCtx-\u0026gt;codec_id); if (decoder == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find decoder failed!\\n\u0026#34;); ret = -1; goto end; } ret = avcodec_open2(decoderCtx, decoder, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open decoder failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } AVFrame *destFrame = av_frame_alloc(); enum AVPixelFormat destPixFmt = AV_PIX_FMT_YUV420P; uint8_t *outBuffer = av_malloc(av_image_get_buffer_size(destPixFmt, decoderCtx-\u0026gt;width, decoderCtx-\u0026gt;height, 1)); av_image_fill_arrays(destFrame-\u0026gt;data, destFrame-\u0026gt;linesize, outBuffer, destPixFmt, decoderCtx-\u0026gt;width, decoderCtx-\u0026gt;height, 1); struct SwsContext *swsCtx = sws_getContext(decoderCtx-\u0026gt;coded_width, decoderCtx-\u0026gt;coded_height, decoderCtx-\u0026gt;pix_fmt, decoderCtx-\u0026gt;width, decoderCtx-\u0026gt;height, destPixFmt, 0, NULL, NULL, NULL); if (swsCtx == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;create sws context failed!\\n\u0026#34;); ret = -1; goto end; } FILE *dest_fp = fopen(outFileName, \u0026#34;wb+\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open out put file %s failed!\\n\u0026#34;, outFileName); ret = -1; goto end; } AVPacket *packet = av_packet_alloc(); while (1) { if (av_read_frame(inFmtCtx, packet) == 0) { if (packet-\u0026gt;stream_index == videoIndex) { decodeVideo(swsCtx, decoderCtx, destFrame, packet, dest_fp); } } av_packet_unref(packet); } decodeVideo(swsCtx,decoderCtx, destFrame,NULL, dest_fp); end: if (inFmtCtx) { avformat_free_context(inFmtCtx); } if (decoderCtx) { avcodec_free_context(\u0026amp;decoderCtx); } if (dest_fp) { fclose(dest_fp); } if (outBuffer) { av_freep(\u0026amp;outBuffer); } return ret; } 音频采集 音频采集命令 采集麦克风声音：\n1 ffmpeg -f dshow -i audio=\u0026#34;阵列麦克风 (AMD Audio Device)\u0026#34; -ar 44100 -f f32le output.pcm 播放麦克风采集：\n1 ffplay -ar 44100 -f f32le output.pcm 流程 函数名 描述 avdevice_register_all 注册所有可用的设备 avformat_alloc_context 分配格式上下文 av_dict_set 设置字典选项 av_find_input_format 查找输入格式 avformat_open_input 打开输入文件 avformat_find_stream_info 查找流信息 av_find_best_stream 查找最佳流 avcodec_alloc_context3 分配编解码器上下文 avcode_parameters_to_context 将参数复制到上下文 avcodec_find_decoder 查找解码器 avcodec_open2 打开编解码器 av_read_frame 读取帧 avcode_send_packet 发送数据包 avcodec_receive_frame 接收帧 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libavdevice/avdevice.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026#34;libavutil/imgutils.h\u0026#34; #include \u0026#34;libswscale/swscale.h\u0026#34; #include \u0026lt;libavcodec/packet.h\u0026gt; #include \u0026lt;libavutil/dict.h\u0026gt; #include \u0026lt;libavutil/frame.h\u0026gt; #include \u0026lt;libavutil/log.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;time.h\u0026gt; // 显示可用的摄像头设备 // ffmpeg -f dshow -list_devices true -i dummy void dshowListDevices() { const AVInputFormat *inFmt = av_find_input_format(\u0026#34;dshow\u0026#34;); if (inFmt == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find dshow failed!\\n\u0026#34;); } // 设置参数 AVDictionary *options = NULL; av_dict_set(\u0026amp;options, \u0026#34;list_devices\u0026#34;, \u0026#34;true\u0026#34;, 0); AVFormatContext *inFmtCtx = avformat_alloc_context(); // 第二个参数是URL int ret = avformat_open_input(\u0026amp;inFmtCtx, \u0026#34;video=Integrated Camera\u0026#34;, inFmt, \u0026amp;options); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input format failed:%s\\n\u0026#34;, av_err2str(ret)); return; } if (inFmtCtx) { avformat_close_input(\u0026amp;inFmtCtx); avformat_free_context(inFmtCtx); } } void decodeAudio(AVCodecContext *decoderCtx, AVPacket *packet, FILE *dest_fp) { if (avcodec_send_packet(decoderCtx, packet) == 0) { AVFrame *frame = av_frame_alloc(); while (avcodec_receive_frame(decoderCtx, frame) \u0026gt;= 0) { fwrite(frame-\u0026gt;data[0], 1, frame-\u0026gt;linesize[0], dest_fp); } av_frame_free(\u0026amp;frame); } } int main(int argc, char *argv[]) { av_log_set_level(AV_LOG_INFO); if (argc \u0026lt; 2) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage:%s \u0026lt;outFileName\u0026gt; \\n\u0026#34;, argv[0]); return -1; } const char *outFileName = argv[1]; avdevice_register_all(); dshowListDevices(); AVFormatContext *inFmtCtx = avformat_alloc_context(); const AVInputFormat *inFmt = av_find_input_format(\u0026#34;dshow\u0026#34;); if (inFmt == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input format failed!\\n\u0026#34;); goto end; } AVDictionary *options = NULL; // av_dict_set(\u0026amp;options, \u0026#34;framerate\u0026#34;, \u0026#34;30\u0026#34;, 0); int ret = avformat_open_input(\u0026amp;inFmtCtx, \u0026#34;audio=阵列麦克风 (AMD Audio Device)\u0026#34;, inFmt, \u0026amp;options); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find stream info failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_AUDIO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find best stream failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } int audioIndex = ret; // 创建解码器上下文 AVCodecContext *decoderCtx = avcodec_alloc_context3(NULL); ret = avcodec_parameters_to_context(decoderCtx, inFmtCtx-\u0026gt;streams[audioIndex]-\u0026gt;codecpar); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;copy parameters to context failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } const AVCodec *decoder = avcodec_find_decoder(decoderCtx-\u0026gt;codec_id); if (decoder == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find decoder failed!\\n\u0026#34;); ret = -1; goto end; } ret = avcodec_open2(decoderCtx, decoder, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open decoder failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } #if 0 AVFrame *destFrame = av_frame_alloc(); enum AVPixelFormat destPixFmt = AV_PIX_FMT_YUV420P; uint8_t *outBuffer = av_malloc(av_image_get_buffer_size(destPixFmt, decoderCtx-\u0026gt;width, decoderCtx-\u0026gt;height, 1)); av_image_fill_arrays(destFrame-\u0026gt;data, destFrame-\u0026gt;linesize, outBuffer, destPixFmt, decoderCtx-\u0026gt;width, decoderCtx-\u0026gt;height, 1); struct SwsContext *swsCtx = sws_getContext(decoderCtx-\u0026gt;coded_width, decoderCtx-\u0026gt;coded_height, decoderCtx-\u0026gt;pix_fmt, decoderCtx-\u0026gt;width, decoderCtx-\u0026gt;height, destPixFmt, 0, NULL, NULL, NULL); if (swsCtx == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;create sws context failed!\\n\u0026#34;); ret = -1; goto end; } #endif FILE *dest_fp = fopen(outFileName, \u0026#34;wb+\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open out put file %s failed!\\n\u0026#34;, outFileName); ret = -1; goto end; } AVPacket *packet = av_packet_alloc(); while (1) { if (av_read_frame(inFmtCtx, packet) == 0) { if (packet-\u0026gt;stream_index == audioIndex) { // decodeVideo(swsCtx, decoderCtx, destFrame, packet, dest_fp); decodeAudio(decoderCtx, packet, dest_fp); } } av_packet_unref(packet); } // decodeVideo(swsCtx, decoderCtx, destFrame, NULL, dest_fp); decodeAudio(decoderCtx, NULL, dest_fp); end: if (inFmtCtx) { avformat_free_context(inFmtCtx); } if (decoderCtx) { avcodec_free_context(\u0026amp;decoderCtx); } if (dest_fp) { fclose(dest_fp); } return ret; } 采集完后要用指令\n1 ffplay -f s16le -ar 44100 code.pcm 才可以播放，可能是参数的不同\n","date":"2024-12-29T00:00:00Z","image":"https://example.com/post/video_base/player1.jpg","permalink":"https://example.com/post/video_base/","title":"音视频基础"}]