[{"content":"Qt 中的基础窗口类 文章中主要介绍了Qt中常用的窗口类, 主要内容包括: 窗口类的基类QWidget, 对话框基类QDialog, 带菜单栏工具栏状态栏的QMainWindow, 消息对话框QMessageBox, 文件对话框QFileDialog, 字体对话框QFontDialog, 颜色对话框QColorDialog, 输入型对话框QInputDialog, 进度条对话框QProgressDialog, 资源文件。\n1. QWidget QWidget类是所有窗口类的父类(控件类是也属于窗口类), 并且QWidget类的父类的QObject, 也就意味着所有的窗口类对象只要指定了父对象, 都可以实现内存资源的自动回收。 在前面入门章节中已经为大家介绍了QWidget的一些特点, 为了让大家能够对这个类有更深入的了解, 下面来说一说这个类常用的一些API函数。\n1.1 设置父对象 1 2 3 4 5 6 7 8 9 // 构造函数 QWidget::QWidget(QWidget *parent = nullptr, Qt::WindowFlags f = Qt::WindowFlags()); // 公共成员函数 // 给当前窗口设置父对象 void QWidget::setParent(QWidget *parent); void QWidget::setParent(QWidget *parent, Qt::WindowFlags f); // 获取当前窗口的父对象, 没有父对象返回 nullptr QWidget *QWidget::parentWidget() const; 1.2 窗口位置 1 2 3 4 5 6 7 8 9 10 11 12 //------------- 窗口位置 ------------- // 得到相对于当前窗口父窗口的几何信息, 边框也被计算在内 QRect QWidget::frameGeometry() const; // 得到相对于当前窗口父窗口的几何信息, 不包括边框 const QRect \u0026amp;geometry() const; // 设置当前窗口的几何信息(位置和尺寸信息), 不包括边框 void setGeometry(int x, int y, int w, int h); void setGeometry(const QRect \u0026amp;); // 移动窗口, 重新设置窗口的位置 void move(int x, int y); void move(const QPoint \u0026amp;); 窗口位置设定和位置获取的测试代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 获取当前窗口的位置信息 void MainWindow::on_positionBtn_clicked() { QRect rect = this-\u0026gt;frameGeometry(); qDebug() \u0026lt;\u0026lt; \u0026#34;左上角: \u0026#34; \u0026lt;\u0026lt; rect.topLeft() \u0026lt;\u0026lt; \u0026#34;右上角: \u0026#34; \u0026lt;\u0026lt; rect.topRight() \u0026lt;\u0026lt; \u0026#34;左下角: \u0026#34; \u0026lt;\u0026lt; rect.bottomLeft() \u0026lt;\u0026lt; \u0026#34;右下角: \u0026#34; \u0026lt;\u0026lt; rect.bottomRight() \u0026lt;\u0026lt; \u0026#34;宽度: \u0026#34; \u0026lt;\u0026lt; rect.width() \u0026lt;\u0026lt; \u0026#34;高度: \u0026#34; \u0026lt;\u0026lt; rect.height(); } // 重新设置当前窗口的位置以及宽度, 高度 void MainWindow::on_geometryBtn_clicked() { int x = 100 + rand() % 500; int y = 100 + rand() % 500; int width = this-\u0026gt;width() + 10; int height = this-\u0026gt;height() + 10; setGeometry(x, y, width, height); } // 通过 move() 方法移动窗口 void MainWindow::on_moveBtn_clicked() { QRect rect = this-\u0026gt;frameGeometry(); move(rect.topLeft() + QPoint(10, 20)); } Qt 的信号-槽机制允许通过特定的命名模式自动生成槽函数与信号的连接，无需手动使用 connect 语句。格式如下：\n1.3 窗口尺寸 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 //------------- 窗口尺寸 ------------- // 获取当前窗口的尺寸信息 QSize size() const // 重新设置窗口的尺寸信息 void resize(int w, int h); void resize(const QSize \u0026amp;); // 获取当前窗口的最大尺寸信息 QSize maximumSize() const; // 获取当前窗口的最小尺寸信息 QSize minimumSize() const; // 设置当前窗口固定的尺寸信息 void QWidget::setFixedSize(const QSize \u0026amp;s); void QWidget::setFixedSize(int w, int h); // 设置当前窗口的最大尺寸信息 void setMaximumSize(const QSize \u0026amp;); void setMaximumSize(int maxw, int maxh); // 设置当前窗口的最小尺寸信息 void setMinimumSize(const QSize \u0026amp;); void setMinimumSize(int minw, int minh); // 获取当前窗口的高度 int height() const; // 获取当前窗口的最小高度 int minimumHeight() const; // 获取当前窗口的最大高度 int maximumHeight() const; // 给窗口设置固定的高度 void QWidget::setFixedHeight(int h); // 给窗口设置最大高度 void setMaximumHeight(int maxh); // 给窗口设置最小高度 void setMinimumHeight(int minh); // 获取当前窗口的宽度 int width() const; // 获取当前窗口的最小宽度 int minimumWidth() const; // 获取当前窗口的最大宽度 int maximumWidth() const; // 给窗口设置固定宽度 void QWidget::setFixedWidth(int w); // 给窗口设置最大宽度 void setMaximumWidth(int maxw); // 给窗口设置最小宽度 void setMinimumWidth(int minw); 1.4 窗口标题和图标 1 2 3 4 5 6 7 8 9 10 11 12 13 //------------- 窗口图标 ------------- // 得到当前窗口的图标 QIcon windowIcon() const; // 构造图标对象, 参数为图片的路径 QIcon::QIcon(const QString \u0026amp;fileName); // 设置当前窗口的图标 void setWindowIcon(const QIcon \u0026amp;icon); //------------- 窗口标题 ------------- // 得到当前窗口的标题 QString windowTitle() const; // 设置当前窗口的标题 void setWindowTitle(const QString \u0026amp;); 1.5 信号 1 2 3 4 5 6 7 // QWidget::setContextMenuPolicy(Qt::ContextMenuPolicy policy); // 窗口的右键菜单策略 contextMenuPolicy() 参数设置为 Qt::CustomContextMenu, 按下鼠标右键发射该信号 [signal] void QWidget::customContextMenuRequested(const QPoint \u0026amp;pos); // 窗口图标发生变化, 发射此信号 [signal] void QWidget::windowIconChanged(const QIcon \u0026amp;icon); // 窗口标题发生变化, 发射此信号 [signal] void QWidget::windowTitleChanged(const QString \u0026amp;title); 1.6 槽函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 //------------- 窗口显示 ------------- // 关闭当前窗口 [slot] bool QWidget::close(); // 隐藏当前窗口 [slot] void QWidget::hide(); // 显示当前创建以及其子窗口 [slot] void QWidget::show(); // 全屏显示当前窗口, 只对windows有效 [slot] void QWidget::showFullScreen(); // 窗口最大化显示, 只对windows有效 [slot] void QWidget::showMaximized(); // 窗口最小化显示, 只对windows有效 [slot] void QWidget::showMinimized(); // 将窗口回复为最大化/最小化之前的状态, 只对windows有效 [slot] void QWidget::showNormal(); //------------- 窗口状态 ------------- // 判断窗口是否可用 bool QWidget::isEnabled() const; // 非槽函数 // 设置窗口是否可用, 不可用窗口无法接收和处理窗口事件 // 参数true-\u0026gt;可用, false-\u0026gt;不可用 [slot] void QWidget::setEnabled(bool); // 设置窗口是否可用, 不可用窗口无法接收和处理窗口事件 // 参数true-\u0026gt;不可用, false-\u0026gt;可用 [slot] void QWidget::setDisabled(bool disable); // 设置窗口是否可见, 参数为true-\u0026gt;可见, false-\u0026gt;不可见 [slot] virtual void QWidget::setVisible(bool visible); 2. QDialog 2.1 常用API 对话框类是QWidget类的子类, 处理继承自父类的属性之外, 还有一些自己所特有的属性, 常用的一些API函数如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 构造函数 QDialog::QDialog(QWidget *parent = nullptr, Qt::WindowFlags f = Qt::WindowFlags()); // 模态显示窗口 [virtual slot] int QDialog::exec(); // 隐藏模态窗口, 并且解除模态窗口的阻塞, 将 exec() 的返回值设置为 QDialog::Accepted [virtual slot] void QDialog::accept(); // 隐藏模态窗口, 并且解除模态窗口的阻塞, 将 exec() 的返回值设置为 QDialog::Rejected [virtual slot] void QDialog::reject(); // 关闭对话框并将其结果代码设置为r。finished()信号将发出r; // 如果r是QDialog::Accepted 或 QDialog::Rejected，则还将分别发出accept()或Rejected()信号。 [virtual slot] void QDialog::done(int r); [signal] void QDialog::accepted(); [signal] void QDialog::rejected(); [signal] void QDialog::finished(int result); 2.2 常用使用方法 1 2 3 场景介绍: 1. 有两个窗口, 主窗口和一个对话框子窗口 2. 对话框窗口先显示, 根据用户操作选择是否显示主窗口 关于对话框窗口类的操作\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 对话框窗口中三个普通按钮按下之后对应的槽函数 void MyDialog::on_acceptBtn_clicked() { this-\u0026gt;accept(); // exec()函数返回值为QDialog::Accepted } void MyDialog::on_rejectBtn_clicked() { this-\u0026gt;reject(); // exec()函数返回值为QDialog::Rejected } void MyDialog::on_donBtn_clicked() { // exec()函数返回值为 done() 的参数, 并根据参数发射出对应的信号 this-\u0026gt;done(666); } 根据用户针对对话框窗口的按钮操作, 进行相应的逻辑处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 创建对话框对象 MyDialog dlg; int ret = dlg.exec(); if(ret == QDialog::Accepted) { qDebug() \u0026lt;\u0026lt; \u0026#34;accept button clicked...\u0026#34;; // 显示主窗口 MainWindow* w = new MainWindow; w-\u0026gt;show(); } else if(ret == QDialog::Rejected) { qDebug() \u0026lt;\u0026lt; \u0026#34;reject button clicked...\u0026#34;; // 不显示主窗口 ...... ...... } else { // ret == 666 qDebug() \u0026lt;\u0026lt; \u0026#34;done button clicked...\u0026#34;; // 根据需求进行逻辑处理 ...... ...... } 3. QDialog的子类 3.1 QMessageBox QMessageBox 对话框类是 QDialog 类的子类, 通过这个类可以显示一些简单的提示框, 用于展示警告、错误、问题等信息。关于这个类我们只需要掌握一些静态方法的使用就可以了。\nAPI - 静态函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 // 显示一个模态对话框, 将参数 text 的信息展示到窗口中 [static] void QMessageBox::about(QWidget *parent, const QString \u0026amp;title, const QString \u0026amp;text); /* 参数: - parent: 对话框窗口的父窗口 - title: 对话框窗口的标题 - text: 对话框窗口中显示的提示信息 - buttons: 对话框窗口中显示的按钮(一个或多个) - defaultButton 1. defaultButton指定按下Enter键时使用的按钮。 2. defaultButton必须引用在参数 buttons 中给定的按钮。 3. 如果defaultButton是QMessageBox::NoButton, QMessageBox会自动选择一个合适的默认值。 */ // 显示一个信息模态对话框 [static] QMessageBox::StandardButton QMessageBox::information( QWidget *parent, const QString \u0026amp;title, const QString \u0026amp;text, QMessageBox::StandardButtons buttons = Ok, QMessageBox::StandardButton defaultButton = NoButton); // 显示一个错误模态对话框 [static] QMessageBox::StandardButton QMessageBox::critical( QWidget *parent, const QString \u0026amp;title, const QString \u0026amp;text, QMessageBox::StandardButtons buttons = Ok, QMessageBox::StandardButton defaultButton = NoButton); // 显示一个问题模态对话框 [static] QMessageBox::StandardButton QMessageBox::question( QWidget *parent, const QString \u0026amp;title, const QString \u0026amp;text, QMessageBox::StandardButtons buttons = StandardButtons(Yes | No), QMessageBox::StandardButton defaultButton = NoButton); // 显示一个警告模态对话框 [static] QMessageBox::StandardButton QMessageBox::warning( QWidget *parent, const QString \u0026amp;title, const QString \u0026amp;text, QMessageBox::StandardButtons buttons = Ok, QMessageBox::StandardButton defaultButton = NoButton); 测试代码 测试代码片段\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 void MainWindow::on_msgbox_clicked() { QMessageBox::about(this, \u0026#34;about\u0026#34;, \u0026#34;这是一个简单的消息提示框!!!\u0026#34;); QMessageBox::critical(this, \u0026#34;critical\u0026#34;, \u0026#34;这是一个错误对话框-critical...\u0026#34;); int ret = QMessageBox::question(this, \u0026#34;question\u0026#34;, \u0026#34;你要保存修改的文件内容吗???\u0026#34;, QMessageBox::Save|QMessageBox::Cancel, QMessageBox::Cancel); if(ret == QMessageBox::Save) { QMessageBox::information(this, \u0026#34;information\u0026#34;, \u0026#34;恭喜你保存成功了, o(*￣︶￣*)o!!!\u0026#34;); } else if(ret == QMessageBox::Cancel) { QMessageBox::warning(this, \u0026#34;warning\u0026#34;, \u0026#34;你放弃了保存, ┭┮﹏┭┮ !!!\u0026#34;); } } 3.2 QFileDialog QFileDialog 对话框类是 QDialog 类的子类, 通过这个类可以选择要打开/保存的文件或者目录。关于这个类我们只需要掌握一些静态方法的使用就可以了。\nAPI - 静态函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 /* 通用参数: - parent: 当前对话框窗口的父对象也就是父窗口 - caption: 当前对话框窗口的标题 - dir: 当前对话框窗口打开的默认目录 - options: 当前对话框窗口的一些可选项,枚举类型, 一般不需要进行设置, 使用默认值即可 - filter: 过滤器, 在对话框中只显示满足条件的文件, 可以指定多个过滤器, 使用 ;; 分隔 - 样式举例: - Images (*.png *.jpg) - Images (*.png *.jpg);;Text files (*.txt) - selectedFilter: 如果指定了多个过滤器, 通过该参数指定默认使用哪一个, 不指定默认使用第一个过滤器 */ // 打开一个目录, 得到这个目录的绝对路径 [static] QString QFileDialog::getExistingDirectory( QWidget *parent = nullptr, const QString \u0026amp;caption = QString(), const QString \u0026amp;dir = QString(), QFileDialog::Options options = ShowDirsOnly); // 打开一个文件, 得到这个文件的绝对路径 [static] QString QFileDialog::getOpenFileName( QWidget *parent = nullptr, const QString \u0026amp;caption = QString(), const QString \u0026amp;dir = QString(), const QString \u0026amp;filter = QString(), QString *selectedFilter = nullptr, QFileDialog::Options options = Options()); // 打开多个文件, 得到这多个文件的绝对路径 [static] QStringList QFileDialog::getOpenFileNames( QWidget *parent = nullptr, const QString \u0026amp;caption = QString(), const QString \u0026amp;dir = QString(), const QString \u0026amp;filter = QString(), QString *selectedFilter = nullptr, QFileDialog::Options options = Options()); // 打开一个目录, 使用这个目录来保存指定的文件 [static] QString QFileDialog::getSaveFileName( QWidget *parent = nullptr, const QString \u0026amp;caption = QString(), const QString \u0026amp;dir = QString(), const QString \u0026amp;filter = QString(), QString *selectedFilter = nullptr, QFileDialog::Options options = Options()); 测试代码 打开一个已存在的本地目录\n1 2 3 4 5 void MainWindow::on_filedlg_clicked() { QString dirName = QFileDialog::getExistingDirectory(this, \u0026#34;打开目录\u0026#34;, \u0026#34;e:\\\\temp\u0026#34;); QMessageBox::information(this, \u0026#34;打开目录\u0026#34;, \u0026#34;您选择的目录是: \u0026#34; + dirName); } 打开一个本地文件\n1 2 3 4 5 6 7 void MainWindow::on_filedlg_clicked() { QString arg(\u0026#34;Text files (*.txt)\u0026#34;); QString fileName = QFileDialog::getOpenFileName( this, \u0026#34;Open File\u0026#34;, \u0026#34;e:\\\\temp\u0026#34;, \u0026#34;Images (*.png *.jpg);;Text files (*.txt)\u0026#34;, \u0026amp;arg); QMessageBox::information(this, \u0026#34;打开文件\u0026#34;, \u0026#34;您选择的文件是: \u0026#34; + fileName); } 打开多个本地文件\n1 2 3 4 5 6 7 8 9 10 { QStringList fileNames = QFileDialog::getOpenFileNames( this, \u0026#34;Open File\u0026#34;, \u0026#34;e:\\\\temp\u0026#34;, \u0026#34;Images (*.png *.jpg);;Text files (*.txt)\u0026#34;); QString names; for (int i = 0; i \u0026lt; fileNames.size(); ++i) { names += fileNames.at(i) + \u0026#34; \u0026#34;; } QMessageBox::information(this, \u0026#34;打开文件(s)\u0026#34;, \u0026#34;您选择的文件是: \u0026#34; + names); } 打开保存文件对话框\n1 2 3 4 5 void MainWindow::on_filedlg_clicked() { QString fileName = QFileDialog::getSaveFileName(this, \u0026#34;保存文件\u0026#34;, \u0026#34;e:\\\\temp\u0026#34;); QMessageBox::information(this, \u0026#34;保存文件\u0026#34;, \u0026#34;您指定的保存数据的文件是: \u0026#34; + fileName); } 3.3 QFontDialog QFontDialog类是QDialog的子类, 通过这个类我们可以得到一个进行字体属性设置的对话框窗口, 和前边介绍的对话框类一样, 我们只需要调用这个类的静态成员函数就可以得到想要的窗口了。\nQFont 字体类 关于字体的属性信息, 在QT框架中被封装到了一个叫QFont的类中, 下边为大家介绍一下这个类的API, 了解一下关于这个类的使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // 构造函数 QFont::QFont(); /* 参数: - family: 本地字库中的字体名, 通过 office 等文件软件可以查看 - pointSize: 字体的字号 - weight: 字体的粗细, 有效范围为 0 ~ 99 - italic: 字体是否倾斜显示, 默认不倾斜 */ QFont::QFont(const QString \u0026amp;family, int pointSize = -1, int weight = -1, bool italic = false); // 设置字体 void QFont::setFamily(const QString \u0026amp;family); // 根据字号设置字体大小 void QFont::setPointSize(int pointSize); // 根据像素设置字体大小 void QFont::setPixelSize(int pixelSize); // 设置字体的粗细程度, 有效范围: 0 ~ 99 void QFont::setWeight(int weight); // 设置字体是否加粗显示 void QFont::setBold(bool enable); // 设置字体是否要倾斜显示 void QFont::setItalic(bool enable); // 获取字体相关属性(一般规律: 去掉设置函数的 set 就是获取相关属性对应的函数名) QString QFont::family() const; bool QFont::italic() const; int QFont::pixelSize() const; int QFont::pointSize() const; bool QFont::bold() const; int QFont::weight() const; 如果一个QFont对象被创建, 并且进行了初始化, 我们可以将这个属性设置给某个窗口, 或者设置给当前应用程序对象。\n1 2 3 4 5 6 7 8 9 10 11 // QWidget 类 // 得到当前窗口使用的字体 const QWidget::QFont\u0026amp; font() const; // 给当前窗口设置字体, 只对当前窗口类生效 void QWidget::setFont(const QFont \u0026amp;); // QApplication 类 // 得到当前应用程序对象使用的字体 [static] QFont QApplication::font(); // 给当前应用程序对象设置字体, 作用于当前应用程序的所有窗口 [static] void QApplication::setFont(const QFont \u0026amp;font, const char *className = nullptr); QFontDialog类的静态API 1 2 3 4 5 6 7 8 9 10 11 12 13 14 /* 参数: - ok: 传出参数, 用于判断是否获得了有效字体信息, 指定一个布尔类型变量地址 - initial: 字体对话框中默认选中并显示该字体信息, 用于对话框的初始化 - parent: 字体对话框窗口的父对象 - title: 字体对话框的窗口标题 - options: 字体对话框选项, 使用默认属性即可, 一般不设置 */ [static] QFont QFontDialog::getFont( bool *ok, const QFont \u0026amp;initial, QWidget *parent = nullptr, const QString \u0026amp;title = QString(), QFontDialog::FontDialogOptions options = FontDialogOptions()); [static] QFont QFontDialog::getFont(bool *ok, QWidget *parent = nullptr); 测试代码 通过字体对话框选择字体, 并将选择的字体设置给当前窗口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void MainWindow::on_fontdlg_clicked() { #if 1 // 方式1 bool ok; QFont ft = QFontDialog::getFont( \u0026amp;ok, QFont(\u0026#34;微软雅黑\u0026#34;, 12, QFont::Bold), this, \u0026#34;选择字体\u0026#34;); qDebug() \u0026lt;\u0026lt; \u0026#34;ok value is: \u0026#34; \u0026lt;\u0026lt; ok; #else // 方式2 QFont ft = QFontDialog::getFont(NULL); #endif // 将选择的字体设置给当前窗口对象 this-\u0026gt;setFont(ft); } 3.4 QColorDialog QColorDialog类是QDialog的子类, 通过这个类我们可以得到一个选择颜色的对话框窗口, 和前边介绍的对话框类一样, 我们只需要调用这个类的静态成员函数就可以得到想要的窗口了。\n颜色类 QColor 关于颜色的属性信息, 在QT框架中被封装到了一个叫QColor的类中, 下边为大家介绍一下这个类的API, 了解一下关于这个类的使用。 各种颜色都是基于红, 绿, 蓝这三种颜色调配而成的, 并且颜色还可以进行透明度设置, 默认是不透明的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 构造函数 QColor::QColor(Qt::GlobalColor color); QColor::QColor(int r, int g, int b, int a = ...); QColor::QColor(); // 参数设置 red, green, blue, alpha, 取值范围都是 0-255 void QColor::setRed(int red);\t// 红色 void QColor::setGreen(int green);\t// 绿色 void QColor::setBlue(int blue);\t// 蓝色 void QColor::setAlpha(int alpha);\t// 透明度, 默认不透明(255) void QColor::setRgb(int r, int g, int b, int a = 255); int QColor::red() const; int QColor::green() const; int QColor::blue() const; int QColor::alpha() const; void QColor::getRgb(int *r, int *g, int *b, int *a = nullptr) const; 静态API函数 1 2 3 4 5 6 7 8 9 10 11 12 // 弹出颜色选择对话框, 并返回选中的颜色信息 /* 参数: - initial: 对话框中默认选中的颜色, 用于窗口初始化 - parent: 给对话框窗口指定父对象 - title: 对话框窗口的标题 - options: 颜色对话框窗口选项, 使用默认属性即可, 一般不需要设置 */ [static] QColor QColorDialog::getColor( const QColor \u0026amp;initial = Qt::white, QWidget *parent = nullptr, const QString \u0026amp;title = QString(), QColorDialog::ColorDialogOptions options = ColorDialogOptions()); 测试代码 场景描述:\n1. 在窗口上放一个标签控件\n2. 通过颜色对话框选择一个颜色, 将选中的颜色显示到标签控件上\n3. 将选中的颜色的 RGBA 值分别显示出来\n1 2 3 4 5 6 7 8 9 10 11 12 13 void MainWindow::on_colordlg_clicked() { QColor color = QColorDialog::getColor(); QBrush brush(color); QRect rect(0, 0, ui-\u0026gt;color-\u0026gt;width(), ui-\u0026gt;color-\u0026gt;height()); QPixmap pix(rect.width(), rect.height()); QPainter p(\u0026amp;pix); p.fillRect(rect, brush); ui-\u0026gt;color-\u0026gt;setPixmap(pix); QString text = QString(\u0026#34;red: %1, green: %2, blue: %3, 透明度: %4\u0026#34;) .arg(color.red()).arg(color.green()).arg(color.blue()).arg(color.alpha()); ui-\u0026gt;colorlabel-\u0026gt;setText(text); } 3.5 QInputDialog QInputDialog类是QDialog的子类, 通过这个类我们可以得到一个输入对话框窗口, 根据实际需求我们可以在这个输入窗口中输入整形, 浮点型, 字符串类型的数据, 并且还可以显示下拉菜单供使用者选择。 和前边介绍的对话框类一样, 我们只需要调用这个类的静态成员函数就可以得到想要的窗口了。\nAPI - 静态函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 // 得到一个可以输入浮点数的对话框窗口, 返回对话框窗口中输入的浮点数 /* 参数: - parent: 对话框窗口的父窗口 - title: 对话框窗口显示的标题信息 - label: 对话框窗口中显示的文本信息(用于描述对话框的功能) - value: 对话框窗口中显示的浮点值, 默认为 0 - min: 对话框窗口支持显示的最小数值 - max: 对话框窗口支持显示的最大数值 - decimals: 浮点数的精度, 默认保留小数点以后1位 - ok: 传出参数, 用于判断是否得到了有效数据, 一般不会使用该参数 - flags: 对话框窗口的窗口属性, 使用默认值即可 */ [static] double QInputDialog::getDouble( QWidget *parent, const QString \u0026amp;title, const QString \u0026amp;label, double value = 0, double min = -2147483647, double max = 2147483647, int decimals = 1, bool *ok = nullptr, Qt::WindowFlags flags = Qt::WindowFlags()); // 得到一个可以输入整形数的对话框窗口, 返回对话框窗口中输入的整形数 /* 参数: - parent: 对话框窗口的父窗口 - title: 对话框窗口显示的标题信息 - label: 对话框窗口中显示的文本信息(用于描述对话框的功能) - value: 对话框窗口中显示的整形值, 默认为 0 - min: 对话框窗口支持显示的最小数值 - max: 对话框窗口支持显示的最大数值 - step: 步长, 通过对话框提供的按钮调节数值每次增长/递减的量 - ok: 传出参数, 用于判断是否得到了有效数据, 一般不会使用该参数 - flags: 对话框窗口的窗口属性, 使用默认值即可 */ [static] int QInputDialog::getInt( QWidget *parent, const QString \u0026amp;title, const QString \u0026amp;label, int value = 0, int min = -2147483647, int max = 2147483647, int step = 1, bool *ok = nullptr, Qt::WindowFlags flags = Qt::WindowFlags()); // 得到一个带下来菜单的对话框窗口, 返回选择的菜单项上边的文本信息 /* 参数: - parent: 对话框窗口的父窗口 - title: 对话框窗口显示的标题信息 - label: 对话框窗口中显示的文本信息(用于描述对话框的功能) - items: 字符串列表, 用于初始化窗口中的下拉菜单, 每个字符串对应一个菜单项 - current: 通过菜单项的索引指定显示下拉菜单中的哪个菜单项, 默认显示第一个(编号为0) - editable: 设置菜单项上的文本信息是否可以进行编辑, 默认为true, 即可以编辑 - ok: 传出参数, 用于判断是否得到了有效数据, 一般不会使用该参数 - flags: 对话框窗口的窗口属性, 使用默认值即可 - inputMethodHints: 设置显示模式, 默认没有指定任何特殊显示格式, 显示普通文本字符串 - 如果有特殊需求, 可以参数帮助文档进行相关设置 */ [static] QString QInputDialog::getItem( QWidget *parent, const QString \u0026amp;title, const QString \u0026amp;label, const QStringList \u0026amp;items, int current = 0, bool editable = true, bool *ok = nullptr, Qt::WindowFlags flags = Qt::WindowFlags(), Qt::InputMethodHints inputMethodHints = Qt::ImhNone); // 得到一个可以输入多行数据的对话框窗口, 返回用户在窗口中输入的文本信息 /* 参数: - parent: 对话框窗口的父窗口 - title: 对话框窗口显示的标题信息 - label: 对话框窗口中显示的文本信息(用于描述对话框的功能) - text: 指定显示到多行输入框中的文本信息, 默认是空字符串 - ok: 传出参数, 用于判断是否得到了有效数据, 一般不会使用该参数 - flags: 对话框窗口的窗口属性, 使用默认值即可 - inputMethodHints: 设置显示模式, 默认没有指定任何特殊显示格式, 显示普通文本字符串 - 如果有特殊需求, 可以参数帮助文档进行相关设置 */ [static] QString QInputDialog::getMultiLineText( QWidget *parent, const QString \u0026amp;title, const QString \u0026amp;label, const QString \u0026amp;text = QString(), bool *ok = nullptr, Qt::WindowFlags flags = Qt::WindowFlags(), Qt::InputMethodHints inputMethodHints = Qt::ImhNone); // 得到一个可以输入单行信息的对话框窗口, 返回用户在窗口中输入的文本信息 /* 参数: - parent: 对话框窗口的父窗口 - title: 对话框窗口显示的标题信息 - label: 对话框窗口中显示的文本信息(用于描述对话框的功能) - mode: 指定单行编辑框中数据的反馈模式, 是一个 QLineEdit::EchoMode 类型的枚举值 - QLineEdit::Normal: 显示输入的字符。这是默认值 - QLineEdit::NoEcho: 不要展示任何东西。这可能适用于连密码长度都应该保密的密码。 - QLineEdit::Password: 显示与平台相关的密码掩码字符，而不是实际输入的字符。 - QLineEdit::PasswordEchoOnEdit: 在编辑时按输入显示字符，否则按密码显示字符。 - text: 指定显示到单行输入框中的文本信息, 默认是空字符串 - ok: 传出参数, 用于判断是否得到了有效数据, 一般不会使用该参数 - flags: 对话框窗口的窗口属性, 使用默认值即可 - inputMethodHints: 设置显示模式, 默认没有指定任何特殊显示格式, 显示普通文本字符串 - 如果有特殊需求, 可以参数帮助文档进行相关设置 */ [static] QString QInputDialog::getText( QWidget *parent, const QString \u0026amp;title, const QString \u0026amp;label, QLineEdit::EchoMode mode = QLineEdit::Normal, const QString \u0026amp;text = QString(), bool *ok = nullptr, Qt::WindowFlags flags = Qt::WindowFlags(), Qt::InputMethodHints inputMethodHints = Qt::ImhNone); 测试代码 整形输入框\n1 2 3 4 5 void MainWindow::on_inputdlg_clicked() { int ret = QInputDialog::getInt(this, \u0026#34;年龄\u0026#34;, \u0026#34;您的当前年龄: \u0026#34;, 10, 1, 100, 2); QMessageBox::information(this, \u0026#34;年龄\u0026#34;, \u0026#34;您的当前年龄: \u0026#34; + QString::number(ret)); } 浮点型输入框\n1 2 3 4 5 void MainWindow::on_inputdlg_clicked() { double ret = QInputDialog::getDouble(this, \u0026#34;工资\u0026#34;, \u0026#34;您的工资: \u0026#34;, 2000, 1000, 6000, 2); QMessageBox::information(this, \u0026#34;工资\u0026#34;, \u0026#34;您的当前工资: \u0026#34; + QString::number(ret)); } 带下拉菜单的输入框\n1 2 3 4 5 6 7 void MainWindow::on_inputdlg_clicked() { QStringList items; items \u0026lt;\u0026lt; \u0026#34;苹果\u0026#34; \u0026lt;\u0026lt; \u0026#34;橙子\u0026#34; \u0026lt;\u0026lt; \u0026#34;橘子\u0026#34; \u0026lt;\u0026lt; \u0026#34;葡萄\u0026#34; \u0026lt;\u0026lt; \u0026#34;香蕉\u0026#34; \u0026lt;\u0026lt; \u0026#34;哈密瓜\u0026#34;; QString item = QInputDialog::getItem(this, \u0026#34;请选择你喜欢的水果\u0026#34;, \u0026#34;你最喜欢的水果:\u0026#34;, items, 1, false); QMessageBox::information(this, \u0026#34;水果\u0026#34;, \u0026#34;您最喜欢的水果是: \u0026#34; + item); } 多行字符串输入框\n1 2 3 4 5 void MainWindow::on_inputdlg_clicked() { QString info = QInputDialog::getMultiLineText(this, \u0026#34;表白\u0026#34;, \u0026#34;您最想对漂亮小姐姐说什么呢?\u0026#34;, \u0026#34;呦吼吼...\u0026#34;); QMessageBox::information(this, \u0026#34;知心姐姐\u0026#34;, \u0026#34;您最想对小姐姐说: \u0026#34; + info); } 单行字符串输入框\n1 2 3 4 5 void MainWindow::on_inputdlg_clicked() { QString text = QInputDialog::getText(this, \u0026#34;密码\u0026#34;, \u0026#34;请输入新的密码\u0026#34;, QLineEdit::Password, \u0026#34;helloworld\u0026#34;); QMessageBox::information(this, \u0026#34;密码\u0026#34;, \u0026#34;您设置的密码是: \u0026#34; + text); } 3.6 QProgressDialog QProgressDialog类是QDialog的子类, 通过这个类我们可以得到一个带进度条的对话框窗口, 这种类型的对话框窗口一般常用于文件拷贝、数据传输等实时交互的场景中。\n常用API 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 // 构造函数 /* 参数: - labelText: 对话框中显示的提示信息 - cancelButtonText: 取消按钮上显示的文本信息 - minimum: 进度条最小值 - maximum: 进度条最大值 - parent: 当前窗口的父对象 - f: 当前进度窗口的flag属性, 使用默认属性即可, 无需设置 */ QProgressDialog::QProgressDialog( QWidget *parent = nullptr, Qt::WindowFlags f = Qt::WindowFlags()); QProgressDialog::QProgressDialog( const QString \u0026amp;labelText, const QString \u0026amp;cancelButtonText, int minimum, int maximum, QWidget *parent = nullptr, Qt::WindowFlags f = Qt::WindowFlags()); // 设置取消按钮显示的文本信息 [slot] void QProgressDialog::setCancelButtonText(const QString \u0026amp;cancelButtonText); // 公共成员函数和槽函数 QString QProgressDialog::labelText() const; void QProgressDialog::setLabelText(const QString \u0026amp;text); // 得到进度条最小值 int QProgressDialog::minimum() const; // 设置进度条最小值 void QProgressDialog::setMinimum(int minimum); // 得到进度条最大值 int QProgressDialog::maximum() const; // 设置进度条最大值 void QProgressDialog::setMaximum(int maximum); // 设置进度条范围(最大和最小值) [slot] void QProgressDialog::setRange(int minimum, int maximum); // 得到进度条当前的值 int QProgressDialog::value() const; // 设置进度条当前的值 void QProgressDialog::setValue(int progress); bool QProgressDialog::autoReset() const; // 当value() = maximum()时，进程对话框是否调用reset()，此属性默认为true。 void QProgressDialog::setAutoReset(bool reset); bool QProgressDialog::autoClose() const; // 当value() = maximum()时，进程对话框是否调用reset()并且隐藏，此属性默认为true。 void QProgressDialog::setAutoClose(bool close); // 判断用户是否按下了取消键, 按下了返回true, 否则返回false bool wasCanceled() const; // 重置进度条 // 重置进度对话框。wascancelled()变为true，直到进程对话框被重置。进度对话框被隐藏。 [slot] void QProgressDialog::cancel(); // 重置进度对话框。如果autoClose()为真，进程对话框将隐藏。 [slot] void QProgressDialog::reset(); // 信号 // 当单击cancel按钮时，将发出此信号。默认情况下，它连接到cancel()槽。 [signal] void QProgressDialog::canceled(); // 设置窗口的显示状态(模态, 非模态) /* 参数: Qt::NonModal -\u0026gt; 非模态 Qt::WindowModal\t-\u0026gt; 模态, 阻塞父窗口 Qt::ApplicationModal -\u0026gt; 模态, 阻塞应用程序中的所有窗口 */ void QWidget::setWindowModality(Qt::WindowModality windowModality); 测试代码 场景描述:\n1. 基于定时器模拟文件拷贝的场景\n2. 点击窗口按钮, 进度条窗口显示, 同时启动定时器\n3. 通过定时器信号, 按照固定频率更新对话框窗口进度条\n4. 当进度条当前值 == 最大值, 关闭定时器, 关闭并析构进度对话框\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 void MainWindow::on_progressdlg_clicked() { // 1. 创建进度条对话框窗口对象 QProgressDialog *progress = new QProgressDialog( \u0026#34;正在拷贝数据...\u0026#34;, \u0026#34;取消拷贝\u0026#34;, 0, 100, this); // 2. 初始化并显示进度条窗口 progress-\u0026gt;setWindowTitle(\u0026#34;请稍后\u0026#34;); progress-\u0026gt;setWindowModality(Qt::WindowModal); progress-\u0026gt;show(); // 3. 更新进度条 static int value = 0; QTimer *timer = new QTimer; connect(timer, \u0026amp;QTimer::timeout, this, [=]() { progress-\u0026gt;setValue(value); value++; // 当value \u0026gt; 最大值的时候 if(value \u0026gt; progress-\u0026gt;maximum()) { timer-\u0026gt;stop(); value = 0; delete progress; delete timer; } }); connect(progress, \u0026amp;QProgressDialog::canceled, this, [=]() { timer-\u0026gt;stop(); value = 0; delete progress; delete timer; }); timer-\u0026gt;start(50); } 4. QMainWindow QMainWindow是标准基础窗口中结构最复杂的窗口, 其组成如下:\n提供了菜单栏, 工具栏, 状态栏, 停靠窗口 菜单栏: 只能有一个, 位于窗口的最上方 工具栏: 可以有多个, 默认提供了一个, 窗口的上下左右都可以停靠 状态栏: 只能有一个, 位于窗口最下方 停靠窗口: 可以有多个, 默认没有提供, 窗口的上下左右都可以停靠 4.1 菜单栏 添加菜单项\n关于顶级菜单可以直接在UI窗口中双击, 直接输入文本信息即可, 对应子菜单项也可以通过先双击在输入的方式完成添加, 但是这种方式不支持中文的输入。\n常用的添加方式\n一般情况下, 我们都是先在外面创建出QAction对象, 然后再将其拖拽到某个菜单下边, 这样子菜单项的添加就完成了。\n通过代码的方式添加菜单或者菜单项\n1 2 3 4 5 6 7 8 9 10 11 // 给菜单栏添加菜单 QAction *QMenuBar::addMenu(QMenu *menu); QMenu *QMenuBar::addMenu(const QString \u0026amp;title); QMenu *QMenuBar::addMenu(const QIcon \u0026amp;icon, const QString \u0026amp;title); // 给菜单对象添加菜单项(QAction) QAction *QMenu::addAction(const QString \u0026amp;text); QAction *QMenu::addAction(const QIcon \u0026amp;icon, const QString \u0026amp;text); // 添加分割线 QAction *QMenu::addSeparator(); 菜单项 QAction 事件的处理\n单击菜单项, 该对象会发出一个信号 1 2 // 点击QAction对象发出该信号 [signal] void QAction::triggered(bool checked = false); 示例代码\n1 2 3 4 5 // save_action 是某个菜单项对象名, 点击这个菜单项会弹出一个对话框 connect(ui-\u0026gt;save_action, \u0026amp;QAction::triggered, this, [=]() { QMessageBox::information(this, \u0026#34;Triggered\u0026#34;, \u0026#34;我是菜单项, 你不要调戏我...\u0026#34;); }); 4.2 工具栏 ","date":"2025-03-19T00:00:00Z","image":"https://serennan.github.io/post/qt-base-5/cover.png","permalink":"https://serennan.github.io/post/qt-base-5/","title":"【Qt 入门】5 基础窗口类"},{"content":"Qt 定时器类 QTimer 在进行窗口程序的处理过程中, 经常要周期性的执行某些操作, 或者制作一些动画效果，看似比较复杂的问题使用定时器就可以完美的解决这些问题， Qt中提供了两种定时器方式一种是使用Qt中的事件处理函数这个在后续章节会给大家做细致的讲解，本节主要给大家介绍一下Qt中的定时器类 QTimer的使用方法。\n要使用它，只需创建一个QTimer类对象，然后调用其 start() 函数开启定时器，此后QTimer对象就会周期性的发出 timeout() 信号。我们先来了解一下这个类的相关API。\n1. public/slot function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // 构造函数 // 如果指定了父对象, 创建的堆内存可以自动析构 QTimer::QTimer(QObject *parent = nullptr); // 设置定时器时间间隔为 msec 毫秒 // 默认值是0，一旦窗口系统事件队列中的所有事件都已经被处理完，一个时间间隔为0的QTimer就会触发 void QTimer::setInterval(int msec); // 获取定时器的时间间隔, 返回值单位: 毫秒 int QTimer::interval() const; // 根据指定的时间间隔启动或者重启定时器, 需要调用 setInterval() 设置时间间隔 [slot] void QTimer::start(); // 启动或重新启动定时器，超时间隔为msec毫秒。 [slot] void QTimer::start(int msec); // 推荐使用 // 停止定时器。 [slot] void QTimer::stop(); // 设置定时器精度 /* 参数: - Qt::PreciseTimer -\u0026gt; 精确的精度, 毫秒级 - Qt::CoarseTimer -\u0026gt; 粗糙的精度, 和1毫秒的误差在5%的范围内, 默认精度 - Qt::VeryCoarseTimer -\u0026gt; 非常粗糙的精度, 精度在1秒左右 */ void QTimer::setTimerType(Qt::TimerType atype); Qt::TimerType QTimer::timerType() const;\t// 获取当前定时器的精度 // 如果定时器正在运行，返回true; 否则返回false。 bool QTimer::isActive() const; // 判断定时器是否只触发一次 bool QTimer::isSingleShot() const; // 设置定时器是否只触发一次, 参数为true定时器只触发一次, 为false定时器重复触发, 默认为false void QTimer::setSingleShot(bool singleShot); 2. signals 这个类的信号只有一个, 当定时器超时时，该信号就会被发射出来。给这个信号通过conect()关联一个槽函数, 就可以在槽函数中处理超时事件了。\n1 [signal] void QTimer::timeout(); 3. static public function 1 2 3 4 5 6 7 8 9 10 11 // 其他同名重载函数可以自己查阅帮助文档 /* 功能: 在msec毫秒后发射一次信号, 并且只发射一次 参数: - msec: 在msec毫秒后发射信号 - receiver: 接收信号的对象地址 - method: 槽函数地址 */ [static] void QTimer::singleShot( int msec, const QObject *receiver, PointerToMemberFunction method); 4. 定时器使用举例 周期性定时器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // 创建定时器对象 QTimer* timer = new QTimer(this); // 修改定时器对象的精度 timer-\u0026gt;setTimerType(Qt::PreciseTimer); // 按钮 loopBtn 的点击事件 // 点击按钮启动或者关闭定时器, 定时器启动, 周期性得到当前时间 connect(ui-\u0026gt;loopBtn, \u0026amp;QPushButton::clicked, this, [=]() { // 启动定时器 if(timer-\u0026gt;isActive()) { timer-\u0026gt;stop(); // 关闭定时器 ui-\u0026gt;loopBtn-\u0026gt;setText(\u0026#34;开始\u0026#34;); } else { ui-\u0026gt;loopBtn-\u0026gt;setText(\u0026#34;关闭\u0026#34;); timer-\u0026gt;start(1000); // 1000ms == 1s } }); connect(timer, \u0026amp;QTimer::timeout, this, [=]() { QTime tm = QTime::currentTime(); // 格式化当前得到的系统时间 QString tmstr = tm.toString(\u0026#34;hh:mm:ss.zzz\u0026#34;); // 设置要显示的时间 ui-\u0026gt;curTime-\u0026gt;setText(tmstr); }); 一次性定时器\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 点击按钮 onceBtn 只发射一次信号 // 点击按钮一次, 发射一个信号, 得到某一个时间点的时间 connect(ui-\u0026gt;onceBtn, \u0026amp;QPushButton::clicked, this, [=]() { // 获取2s以后的系统时间, 不创建定时器对象, 直接使用类的静态方法 QTimer::singleShot(2000, this, [=](){ QTime tm = QTime::currentTime(); // 格式化当前得到的系统时间 QString tmstr = tm.toString(\u0026#34;hh:mm:ss.zzz\u0026#34;); // 设置要显示的时间 ui-\u0026gt;onceTime-\u0026gt;setText(tmstr); }); }); ","date":"2025-03-18T00:00:00Z","image":"https://serennan.github.io/post/qt-base-4/cover.png","permalink":"https://serennan.github.io/post/qt-base-4/","title":"【Qt 入门】4 定时器"},{"content":"Qt中的信号槽 1. 信号和槽概述 信号槽是 Qt 框架引以为豪的机制之一。所谓信号槽，实际就是观察者模式(发布-订阅模式)。当某个事件发生之后，比如，按钮检测到自己被点击了一下，它就会发出一个信号（signal）。这种发出是没有目的的，类似广播。如果有对象对这个信号感兴趣，它就会使用连接（connect）函数，意思是，将想要处理的信号和自己的一个函数（称为槽（slot））绑定来处理这个信号。也就是说，当信号发出时，被连接的槽函数会自动被回调。这就类似观察者模式：当发生了感兴趣的事件，某一个操作就会被自动触发。\n1.1 信号的本质 信号是由于用户对窗口或控件进行了某些操作，导致窗口或控件产生了某个特定事件，这时候Qt对应的窗口类会发出某个信号，以此对用户的挑选做出反应。\n因此根据上述的描述我们得到一个结论 – 信号的本质就是事件，比如：\n按钮单击、双击 窗口刷新 鼠标移动、鼠标按下、鼠标释放 键盘输入 那么在Qt中信号是通过什么形式呈现给使用者的呢？\n我们对哪个窗口进行操作, 哪个窗口就可以捕捉到这些被触发的事件。 对于使用者来说触发了一个事件，我们就可以得到Qt框架给我们发出的某个特定信号。 信号的呈现形式就是函数， 也就是说某个事件产生了， Qt框架就会调用某个对应的信号函数， 通知使用者。 在QT中信号的发出者是某个实例化的类对象，对象内部可以进行相关事件的检测。\n1.2 槽的本质 在Qt中 槽函数是一类特殊的功能的函数 ，在编码过程中 也可以作为类的普通成员函数来使用 。之所以称之为槽函数是因为它们还有一个职责就是对Qt框架中产生的信号进行处理。\n1 2 举个简单的例子： 女朋友说：“我肚子饿了！”，于是我带她去吃饭。 上边例子中相当于女朋友发出了一个信号， 我收到了信号并其将其处理掉了。\n实例对象 角色 描述 女朋友 信号发出者 信号携带的信息: 我饿了 我 信号接收者 处理女朋友发射的信号: 带他去吃饭 在Qt中槽函数的所有者也是某个类的实例对象。\n1.3 信号和槽的关系 在Qt中信号和槽函数都是独立的个体，本身没有任何联系，但是由于某种特性需求我们可以将二者连接到一起，好比牛郎和织女想要相会必须要有喜鹊为他们搭桥一样。在Qt中我们需要使用 QOjbect 类中的 connect 函数进二者的关联。\n连接信号和槽的 connect() 函数原型如下, 其中 PointerToMemberFunction 是一个指向函数地址的指针\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 QMetaObject::Connection QObject::connect( const QObject *sender, PointerToMemberFunction signal, const QObject *receiver, PointerToMemberFunction method, Qt::ConnectionType type = Qt::AutoConnection); 参数: - sender: 发出信号的对象 - signal: 属于 sender 对象, 信号是一个函数, 这个参数的类型是函数 指针, 信号函数地址 - receiver: 信号接收者 - method: 属于 receiver 对象, 当检测到 sender 发出了signal 信号, receiver 对象调用 method 方法，信号发出之后的处理动作 // 参数 signal 和 method 都是函数地址, 因此简化之后的 connect() 如下: connect(const QObject *sender, \u0026amp;QObject::signal, const QObject *receiver, \u0026amp;QObject::method); 使用connect()进行信号槽连接的注意事项:\nconnect函数相对于做了信号处理动作的注册 调用conenct函数的sender对象的信号并没有产生, 因此receiver对象的method也不会被调用 method槽函数本质是一个回调函数, 调用的时机是信号产生之后, 调用是Qt框架来执行的 connect中的sender和recever两个指针必须被实例化了, 否则conenct不会成功 2. 标准信号槽使用 2.1 标准信号/槽 在Qt提供的很多标准类中都可以对用户触发的某些特定事件进行检测, 因此当用户做了这些操作之后, 事件被触发类的内部就会产生对应的信号, 这些信号都是Qt类内部自带的, 因此称之为标准信号。\n同样的，在Qt的很多类内部为我们了提供了很多功能函数，并且这些函数也可以作为触发的信号的处理动作，有这类特性的函数在Qt中称之为标准槽函数。\n系统自带的信号和槽通常如何查找呢，这个就需要利用帮助文档了，这里不过多介绍。\n2.2 使用 掌握标准信号、槽的查找方式之后以及connect()函数的作用之后, 下面通过一个简单的例子给大家讲解一下他们的使用方式。\n1 2 3 4 功能实现： 点击窗口上的按钮, 关闭窗口 功能分析: - 按钮: 信号发出者 -\u0026gt; QPushButton 类型 - 窗口: 信号的接收者和处理者 -\u0026gt; QWidget 类型 需要使用的标准信号槽函数\n1 2 3 4 // 单击按钮发出的信号 [signal] void QAbstractButton::clicked(bool checked = false) // 关闭窗口的槽函数 [slot] bool QWidget::close(); 对于上边的需求只需要一句代码, 只需要写一句代码就能实现了\n1 2 // 单击按钮关闭窗口 connect(ui-\u0026gt;closewindow, \u0026amp;QPushButton::clicked, this, \u0026amp;MainWindow::close); connect()操作一般写在窗口的构造函数中, 相当于在事件产生之前在qt框架中先进行注册, 这样在程序运行过程中假设产生了按钮的点击事件, 框架就会调用信号接收者对象对应的槽函数了, 如果信号不产生, 槽函数也就一直不会被调用。\n3. 自定义信号槽使用 Qt框架提供的信号槽在某些特定场景下是无法满足我们的项目需求的，因此我们还设计自己需要的的信号和槽，同样还是使用connect()对自定义的信号槽进行连接。\n如果想要在QT类中自定义信号槽, 需要满足一些条件, 并且有些事项也需要注意:\n要编写新的类并且让其继承Qt的某些标准类 这个新的子类必须从QObject类或者是QObject子类进行派生 在定义类的头文件中加入 Q_OBJECT 宏 1 2 3 4 5 6 // 在头文件派生类的时候，首先像下面那样引入Q_OBJECT宏： class MyMainWindow : public QWidget { Q_OBJECT ...... } 3.1 自定义信号 在Qt中信号的本质是事件, 但是在框架中也是以函数的形式存在的, 只不过信号对应的函数只有声明, 没有定义。如果Qt中的标准信号不能满足我们的需求，可以在程序中进行信号的自定义，当自定义信号对应的事件产生之后，认为的将这个信号发射出去即可（其实就是调用一下这个信号函数）。\n下边给大家阐述一下, 自定义信号的要求和注意事项:\n信号是类的成员函数 返回值必须是 void 类型 信号的名字可以根据实际情况进行指定 参数可以随意指定，信号也支持重载 信号需要使用 signals 关键字进行声明，使用方法类似于 public 等关键字 信号函数只需要声明，不需要定义（没用函数体实现） 在程序中发射自定义信号：发送信号的本质就是调用信号函数 习惯性在信号函数前加关键字：emit，但是可以省略不写 emit 只是显示的声明一下信号要被发射了，没有特殊含义 底层 emit == #define emit 1 2 3 4 5 6 7 8 9 10 11 // 举例: 信号重载 // Qt中的类想要使用信号槽机制必须要从QObject类派生(直接或间接派生都可以) class Test : public QObject { Q_OBJECT signals: void testsignal(); // 参数的作用是数据传递, 谁调用信号函数谁就指定实参 // 实参最终会被传递给槽函数 void testsignal(int a); }; 3.2 自定义槽 槽函数就是信号的处理动作，在Qt中槽函数可以作为普通的成员函数来使用。如果标准槽函数提供的功能满足不了需求，可以自己定义槽函数进行某些特殊功能的实现。自定义槽函数和自定义的普通函数写法是一样的。\n下边给大家阐述一下, 自定义槽的要求和注意事项:\n返回值必须是 void 类型 槽也是函数, 因此也支持重载 槽函数需要指定多少个参数, 需要看连接的信号的参数个数 槽函数的参数是用来接收信号传递的数据的, 信号传递的数据就是信号的参数 1 2 3 举例: 信号函数: void testsig(int a, double b); 槽函数: void testslot(int a, double b); 总结： 槽函数的参数应该和对应的信号的参数个数, 从左到右类型依次对应\n信号的参数可以大于等于槽函数的参数个数 == 信号传递的数据被忽略了\n1 2 信号函数: void testsig(int a, double b); 槽函数: void testslot(int a); Qt中槽函数的类型是多样的 Qt中的槽函数可以是类的成员函数、全局函数、静态函数、Lambda表达式（匿名函数） 槽函数可以使用关键字进行声明: slots (Qt5中slots可以省略不写) public slots: private slots: –\u0026gt; 这样的槽函数不能在类外部被调用 protected slots: –\u0026gt; 这样的槽函数不能在类外部被调用 1 2 3 4 5 6 7 8 9 10 11 // 槽函数书写格式举例 // 类中的这三个函数都可以作为槽函数来使用 class Test : public QObject { public: void testSlot(); static void testFunc(); public slots: void testSlot(int id); }; 自定义信号槽的使用：\n1 2 还是上边的场景: 女朋友说：“我肚子饿了！”，于是我带她去吃饭。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // class GirlFriend class GirlFriend : public QObject { Q_OBJECT public: explicit GirlFriend(QObject *parent = nullptr); signals: void hungry();\t// 不能表达出想要吃什么 void hungry(QString msg);\t// 可以通过参数表达想要吃什么 }; // class Me class Me : public QObject { Q_OBJECT public: explicit Me(QObject *parent = nullptr); public slots: // 槽函数 void eatMeal(); // 不能知道信号发出者要吃什么 void eatMeal(QString msg); // 可以知道信号发出者要吃什么 }; 4. 信号槽拓展 一个信号可以连接多个槽函数, 发送一个信号有多个处理动作\n需要写多个connect（）连接 信号的接收者可以是一个对象, 也可以是多个对象 一个槽函数可以连接多个信号, 多个不同的信号, 处理动作是相同的\n需要写多个connect（）连接 信号可以连接信号\n信号接收者可以不处理接收的信号, 而是继续发射新的信号，这相当于传递了数据, 并没有对数据进行处理\n1 2 connect(const QObject *sender, \u0026amp;QObject::signal, const QObject *receiver, \u0026amp;QObject::siganl-new); 信号槽是可以断开的\n1 2 disconnect(const QObject *sender, \u0026amp;QObject::signal, const QObject *receiver, \u0026amp;QObject::method); 5. Lambda 表达式 Lambda表达式是 C++ 11 最重要也是最常用的特性之一，是现代编程语言的一个特点，简洁，提高了代码的效率并且可以使程序更加灵活，Qt是完全支持c++语法的， 因此在Qt中也可以使用Lambda表达式。\n5.1 语法格式 Lambda表达式就是一个匿名函数， 语法格式如下：\n1 2 3 4 5 6 [capture](params) opt -\u0026gt; ret {body;}; - capture: 捕获列表 - params: 参数列表 - opt: 函数选项 - ret: 返回值类型 - body: 函数体 关于Lambda表达式的细节介绍:\n捕获列表: 捕获一定范围内的变量 [] - 不捕捉任何变量 [\u0026amp;] - 捕获外部作用域中所有变量, 并作为引用在函数体内使用 (按引用捕获) [=] - 捕获外部作用域中所有变量, 并作为副本在函数体内使用 (按值捕获) 拷贝的副本在匿名函数体内部是只读的 [=, \u0026amp;foo] - 按值捕获外部作用域中所有变量, 并按照引用捕获外部变量 foo [bar] - 按值捕获 bar 变量, 同时不捕获其他变量 [\u0026amp;bar] - 按引用捕获 bar 变量, 同时不捕获其他变量 [this] - 捕获当前类中的this指针 让lambda表达式拥有和当前类成员函数同样的访问权限 如果已经使用了 \u0026amp; 或者 =, 默认添加此选项 参数列表: 和普通函数的参数列表一样\nopt 选项 –\u0026gt; 可以省略\nmutable: 可以修改按值传递进来的拷贝（注意是能修改拷贝，而不是值本身） exception: 指定函数抛出的异常，如抛出整数类型的异常，可以使用throw(); 返回值类型: 标识函数返回值的类型，当返回值为void，或者函数体中只有一处return的地方（此时编译器可以自动推断出返回值类型）时，这部分可以省略 函数体: 函数的实现，这部分不能省略，但函数体可以为空。 5.2 定义和调用 因为Lambda表达式是一个匿名函数, 因此是没有函数声明的, 直接在程序中进行代码的定义即可, 但是如果只定义匿名函数在程序执行过程中是不会被调用的。\n1 2 3 4 5 6 7 8 9 // 匿名函数的定义, 程序执行这个匿名函数是不会被调用的 [](){ qDebug() \u0026lt;\u0026lt; \u0026#34;hello, 我是一个lambda表达式...\u0026#34;; }; // 调用匿名函数 [](){ qDebug() \u0026lt;\u0026lt; \u0026#34;hello, 我是一个lambda表达式...\u0026#34;; }(); 在Lambda表达式的捕获列表中也就是 [] 内部添加不同的关键字, 就可以在函数体中使用外部变量了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 在匿名函数外部定义变量 int a=100, b=200, c=300; // 调用匿名函数 [](){ // 打印外部变量的值 qDebug() \u0026lt;\u0026lt; \u0026#34;a:\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; \u0026#34;, b: \u0026#34; \u0026lt;\u0026lt; b \u0026lt;\u0026lt; \u0026#34;, c:\u0026#34; \u0026lt;\u0026lt; c; // error, 不能使用任何外部变量 } [\u0026amp;](){ qDebug() \u0026lt;\u0026lt; \u0026#34;hello, 我是一个lambda表达式...\u0026#34;; qDebug() \u0026lt;\u0026lt; \u0026#34;使用引用的方式传递数据: \u0026#34;; qDebug() \u0026lt;\u0026lt; \u0026#34;a+1:\u0026#34; \u0026lt;\u0026lt; a++ \u0026lt;\u0026lt; \u0026#34;, b+c= \u0026#34; \u0026lt;\u0026lt; b+c; }(); // 值拷贝的方式使用外部数据 [=](int m, int n)mutable{ qDebug() \u0026lt;\u0026lt; \u0026#34;hello, 我是一个lambda表达式...\u0026#34;; qDebug() \u0026lt;\u0026lt; \u0026#34;使用拷贝的方式传递数据: \u0026#34;; // 拷贝的外部数据在函数体内部是只读的, 如果不添加 mutable 关键字是不能修改这些只读数据的值的 // 添加 mutable 允许修改的数据是拷贝到函数内部的副本, 对外部数据没有影响 qDebug() \u0026lt;\u0026lt; \u0026#34;a+1:\u0026#34; \u0026lt;\u0026lt; a++ \u0026lt;\u0026lt; \u0026#34;, b+c= \u0026#34; \u0026lt;\u0026lt; b+c; qDebug() \u0026lt;\u0026lt; \u0026#34;m+1: \u0026#34; \u0026lt;\u0026lt; ++m \u0026lt;\u0026lt; \u0026#34;, n: \u0026#34; \u0026lt;\u0026lt; n; }(1, 2); Qt 中的应用\n1 2 3 connect(ui-\u0026gt;hungry, \u0026amp;QPushButton::clicked, this, [=]() { m_girlfriend-\u0026gt;hungry(\u0026#34;意大利面\u0026#34;); }); ","date":"2025-03-17T00:00:00Z","image":"https://serennan.github.io/post/qt-base-3/cover.png","permalink":"https://serennan.github.io/post/qt-base-3/","title":"【Qt 入门】3 信号槽"},{"content":"1. 两数之和 Leetcode 1 题，两数之和,难度 Easy\n给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。\n你可以假设每种输入只会对应一个答案，并且你不能使用两次相同的元素。\n你可以按任意顺序返回答案，有效答案只有一个\n这道题的解题思路比较简单，但是要熟悉哈希表和迭代器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Solution { public: vector\u0026lt;int\u0026gt; twoSum(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { unordered_map\u0026lt;int, int\u0026gt; hashtable; for (int i = 0; i \u0026lt; nums.size(); ++i) { auto it = hashtable.find(target - nums[i]); if (it != hashtable.end()) { return {it-\u0026gt;second, i}; } hashtable[nums[i]] = i; } return {}; } }; TODO 其他题\n","date":"2025-03-14T00:00:00Z","permalink":"https://serennan.github.io/post/leetcode-hashtable/","title":"哈希表"},{"content":"由于插件 Qt Configure 帮我们创建的文件全都丢在 src 文件夹下，这时如果创建多个窗口类，工程结构就显得复杂。所以本次博客帮助大家完善一下工程结构。\n特别鸣谢小伙伴 YusJade 帮我解决结构调整带来的问题。\n博客链接：CMake + Qt 无法编译.ui 文件的解决办法\nQt 项目工程结构调整 工程结构 将头文件，源文件和ui文件分别放到对应文件夹：\n1 2 3 4 5 6 7 8 9 10 11 12 13 ├── include │ ├── dialog.h │ ├── mainwindow.h │ └── widget.h ├── src │ ├── dialog.cpp │ ├── main.cpp │ ├── mainwindow.cpp │ └── widget.cpp ├── ui │ ├── dialog.ui │ ├── mainwindow.ui │ └── widget.ui CMakeLists.txt 文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 cmake_minimum_required(VERSION 3.20) # CMake install : https://cmake.org/download/ project(mainwindow LANGUAGES CXX) set(CMAKE_INCLUDE_CURRENT_DIR ON) set(CMAKE_PREFIX_PATH \u0026#34;/usr/local/Qt/Qt6.5.3/6.5.3/gcc_64\u0026#34;) # Qt Kit Dir set(CMAKE_AUTOUIC ON) set(CMAKE_AUTOMOC ON) set(CMAKE_AUTORCC ON) set(CMAKE_CXX_STANDARD 17) set(CMAKE_CXX_STANDARD_REQUIRED ON) find_package(Qt6 COMPONENTS Widgets REQUIRED) # Qt COMPONENTS # aux_source_directory(./src srcs) set(SOURCE ${CMAKE_SOURCE_DIR}/src/main.cpp ${CMAKE_SOURCE_DIR}/src/mainwindow.cpp ${CMAKE_SOURCE_DIR}/src/widget.cpp ${CMAKE_SOURCE_DIR}/src/dialog.cpp ) set(INCLUDE ${CMAKE_SOURCE_DIR}/include/dialog.h ${CMAKE_SOURCE_DIR}/include/mainwindow.h ${CMAKE_SOURCE_DIR}/include/widget.h ) set(CMAKE_AUTOUIC_SEARCH_PATHS ${CMAKE_SOURCE_DIR}/ui) set(UI_FILES ${CMAKE_SOURCE_DIR}/ui/dialog.ui ${CMAKE_SOURCE_DIR}/ui/mainwindow.ui ${CMAKE_SOURCE_DIR}/ui/widget.ui ) add_compile_options(\u0026#34;$\u0026lt;$\u0026lt;C_COMPILER_ID:MSVC\u0026gt;:/utf-8\u0026gt;\u0026#34;) add_compile_options(\u0026#34;$\u0026lt;$\u0026lt;CXX_COMPILER_ID:MSVC\u0026gt;:/utf-8\u0026gt;\u0026#34;) add_executable(${PROJECT_NAME} WIN32 ${SOURCE} ${INCLUDE} ${UI_FILES} ) target_include_directories(${PROJECT_NAME} PRIVATE ${CMAKE_SOURCE_DIR}/include ) target_link_libraries(${PROJECT_NAME} PRIVATE Qt6::Widgets) # Qt5 Shared Library ","date":"2025-03-12T00:00:00Z","image":"https://serennan.github.io/post/qt-structure/cover.png","permalink":"https://serennan.github.io/post/qt-structure/","title":"【Qt 配置】工程结构调整"},{"content":"Qt中的基础数据类型 1. QByteArray 在Qt中QByteArray可以看做是c语言中 char*的升级版本。我们在使用这种类型的时候可通过这个类的构造函数申请一块动态内存，用于存储我们需要处理的字符串数据。\n下面给大家介绍一下这个类中常用的一些API函数，大家要养成遇到问题主动查询帮助文档的好习惯。\n构造函数 1 2 3 4 5 6 7 // 构造空对象, 里边没有数据 QByteArray::QByteArray(); // 将data中的size个字符进行构造, 得到一个字节数组对象 // 如果 size==-1 函数内部自动计算字符串长度, 计算方式为: strlen(data) QByteArray::QByteArray(const char *data, int size = -1); // 构造一个长度为size个字节, 并且每个字节值都为ch的字节数组 QByteArray::QByteArray(int size, char ch); 数据操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 在尾部追加数据 // 其他重载的同名函数可参考Qt帮助文档, 此处略 QByteArray \u0026amp;QByteArray::append(const QByteArray \u0026amp;ba); void QByteArray::push_back(const QByteArray \u0026amp;other); // 头部添加数据 // 其他重载的同名函数可参考Qt帮助文档, 此处略 QByteArray \u0026amp;QByteArray::prepend(const QByteArray \u0026amp;ba); void QByteArray::push_front(const QByteArray \u0026amp;other); // 插入数据, 将ba插入到数组第 i 个字节的位置(从0开始) // 其他重载的同名函数可参考Qt帮助文档, 此处略 QByteArray \u0026amp;QByteArray::insert(int i, const QByteArray \u0026amp;ba); // 删除数据 // 从大字符串中删除len个字符, 从第pos个字符的位置开始删除 QByteArray \u0026amp;QByteArray::remove(int pos, int len); // 从字符数组的尾部删除 n 个字节 void QByteArray::chop(int n); // 从字节数组的 pos 位置将数组截断 (前边部分留下, 后边部分被删除) void QByteArray::truncate(int pos); // 将对象中的数据清空, 使其为null void QByteArray::clear(); // 字符串替换 // 将字节数组中的 子字符串 before 替换为 after // 其他重载的同名函数可参考Qt帮助文档, 此处略 QByteArray \u0026amp;QByteArray::replace(const QByteArray \u0026amp;before, const QByteArray \u0026amp;after); 子字符串查找和判断 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 判断字节数组中是否包含子字符串 ba, 包含返回true, 否则返回false bool QByteArray::contains(const QByteArray \u0026amp;ba) const; bool QByteArray::contains(const char *ba) const; // 判断字节数组中是否包含子字符 ch, 包含返回true, 否则返回false bool QByteArray::contains(char ch) const; // 判断字节数组是否以字符串 ba 开始, 是返回true, 不是返回false bool QByteArray::startsWith(const QByteArray \u0026amp;ba) const; bool QByteArray::startsWith(const char *ba) const; // 判断字节数组是否以字符 ch 开始, 是返回true, 不是返回false bool QByteArray::startsWith(char ch) const; // 判断字节数组是否以字符串 ba 结尾, 是返回true, 不是返回false bool QByteArray::endsWith(const QByteArray \u0026amp;ba) const; bool QByteArray::endsWith(const char *ba) const; // 判断字节数组是否以字符 ch 结尾, 是返回true, 不是返回false bool QByteArray::endsWith(char ch) const; 遍历 1 2 3 4 5 6 7 8 9 // 使用迭代器 iterator QByteArray::begin(); iterator QByteArray::end(); // 使用数组的方式进行遍历 // i的取值范围 0 \u0026lt;= i \u0026lt; size() // 用的更多 char QByteArray::at(int i) const; char QByteArray::operator[](int i) const; 查看字节数 1 2 3 4 5 6 7 8 9 10 // 返回字节数组对象中字符的个数 int QByteArray::length() const; int QByteArray::size() const; int QByteArray::count() const; // 返回字节数组对象中 子字符串ba 出现的次数 int QByteArray::count(const QByteArray \u0026amp;ba) const; int QByteArray::count(const char *ba) const; // 返回字节数组对象中 字符串ch 出现的次数 int QByteArray::count(char ch) const; 类型转换 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // 将QByteArray类型的字符串 转换为 char* 类型 char *QByteArray::data(); const char *QByteArray::data() const; // int, short, long, float, double -\u0026gt; QByteArray // 其他重载的同名函数可参考Qt帮助文档, 此处略 QByteArray \u0026amp;QByteArray::setNum(int n, int base = 10); QByteArray \u0026amp;QByteArray::setNum(short n, int base = 10); QByteArray \u0026amp;QByteArray::setNum(qlonglong n, int base = 10); QByteArray \u0026amp;QByteArray::setNum(float n, char f = \u0026#39;g\u0026#39;, int prec = 6); QByteArray \u0026amp;QByteArray::setNum(double n, char f = \u0026#39;g\u0026#39;, int prec = 6); [static] QByteArray QByteArray::number(int n, int base = 10); [static] QByteArray QByteArray::number(qlonglong n, int base = 10); [static] QByteArray QByteArray::number(double n, char f = \u0026#39;g\u0026#39;, int prec = 6); // QByteArray -\u0026gt; int, short, long, float, double int QByteArray::toInt(bool *ok = Q_NULLPTR, int base = 10) const; short QByteArray::toShort(bool *ok = Q_NULLPTR, int base = 10) const; long QByteArray::toLong(bool *ok = Q_NULLPTR, int base = 10) const; float QByteArray::toFloat(bool *ok = Q_NULLPTR) const; double QByteArray::toDouble(bool *ok = Q_NULLPTR) const; // std::string -\u0026gt; QByteArray [static] QByteArray QByteArray::fromStdString(const std::string \u0026amp;str); // QByteArray -\u0026gt; std::string std::string QByteArray::toStdString() const; // 所有字符转换为大写 QByteArray QByteArray::toUpper() const; // 所有字符转换为小写 QByteArray QByteArray::toLower() const; 2. QString QString也是封装了字符串, 但是内部的编码为utf8, UTF-8属于Unicode字符集, 它固定使用多个字节（window为2字节, linux为3字节）来表示一个字符，这样可以将世界上几乎所有语言的常用字符收录其中。\n下面给大家介绍一下这个类中常用的一些API函数。\n构造函数 1 2 3 4 5 6 7 // 构造一个空字符串对象 QString::QString(); // 将 char* 字符串 转换为 QString 类型 QString::QString(const char *str); // 将 QByteArray 转换为 QString 类型 QString::QString(const QByteArray \u0026amp;ba); // 其他重载的同名构造函数可参考Qt帮助文档, 此处略 数据操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // 尾部追加数据 // 其他重载的同名函数可参考Qt帮助文档, 此处略 QString \u0026amp;QString::append(const QString \u0026amp;str); QString \u0026amp;QString::append(const char *str); QString \u0026amp;QString::append(const QByteArray \u0026amp;ba); void QString::push_back(const QString \u0026amp;other); // 头部添加数据 // 其他重载的同名函数可参考Qt帮助文档, 此处略 QString \u0026amp;QString::prepend(const QString \u0026amp;str); QString \u0026amp;QString::prepend(const char *str); QString \u0026amp;QString::prepend(const QByteArray \u0026amp;ba); void QString::push_front(const QString \u0026amp;other); // 插入数据, 将 str 插入到字符串第 position 个字符的位置(从0开始) // 其他重载的同名函数可参考Qt帮助文档, 此处略 QString \u0026amp;QString::insert(int position, const QString \u0026amp;str); QString \u0026amp;QString::insert(int position, const char *str); QString \u0026amp;QString::insert(int position, const QByteArray \u0026amp;str); // 删除数据 // 从大字符串中删除len个字符, 从第pos个字符的位置开始删除 QString \u0026amp;QString::remove(int position, int n); // 从字符串的尾部删除 n 个字符 void QString::chop(int n); // 从字节串的 position 位置将字符串截断 (前边部分留下, 后边部分被删除) void QString::truncate(int position); // 将对象中的数据清空, 使其为null void QString::clear(); // 字符串替换 // 将字节数组中的 子字符串 before 替换为 after // 参数 cs 为是否区分大小写, 默认区分大小写 // 其他重载的同名函数可参考Qt帮助文档, 此处略 QString \u0026amp;QString::replace(const QString \u0026amp;before, const QString \u0026amp;after, Qt::CaseSensitivity cs = Qt::CaseSensitive); 子字符串查找和判断 1 2 3 4 5 6 7 8 9 10 11 // 参数 cs 为是否区分大小写, 默认区分大小写 // 其他重载的同名函数可参考Qt帮助文档, 此处略 // 判断字符串中是否包含子字符串 str, 包含返回true, 否则返回false bool QString::contains(const QString \u0026amp;str, Qt::CaseSensitivity cs = Qt::CaseSensitive) const; // 判断字符串是否以字符串 ba 开始, 是返回true, 不是返回false bool QString::startsWith(const QString \u0026amp;s, Qt::CaseSensitivity cs = Qt::CaseSensitive) const; // 判断字符串是否以字符串 ba 结尾, 是返回true, 不是返回false bool QString::endsWith(const QString \u0026amp;s, Qt::CaseSensitivity cs = Qt::CaseSensitive) const; 遍历 1 2 3 4 5 6 7 8 // 使用迭代器 iterator QString::begin(); iterator QString::end(); // 使用数组的方式进行遍历 // i的取值范围 0 \u0026lt;= position \u0026lt; size() const QChar QString::at(int position) const const QChar QString::operator[](int position) const; 查看字节数 1 2 3 4 5 6 7 8 // 返回字节数组对象中字符的个数 (字符个数和字节个数是不同的概念) int QString::length() const; int QString::size() const; int QString::count() const; // 返回字节串对象中 子字符串 str 出现的次数 // 参数 cs 为是否区分大小写, 默认区分大小写 int QString::count(const QStringRef \u0026amp;str, Qt::CaseSensitivity cs = Qt::CaseSensitive) const; 类型转换 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // 将int, short, long, float, double 转换为 QString 类型 // 其他重载的同名函数可参考Qt帮助文档, 此处略 QString \u0026amp;QString::setNum(int n, int base = 10); QString \u0026amp;QString::setNum(short n, int base = 10); QString \u0026amp;QString::setNum(long n, int base = 10); QString \u0026amp;QString::setNum(float n, char format = \u0026#39;g\u0026#39;, int precision = 6); QString \u0026amp;QString::setNum(double n, char format = \u0026#39;g\u0026#39;, int precision = 6); [static] QString QString::number(long n, int base = 10); [static] QString QString::number(int n, int base = 10); [static] QString QString::number(double n, char format = \u0026#39;g\u0026#39;, int precision = 6); // 将 QString 转换为 int, short, long, float, double 类型 int QString::toInt(bool *ok = Q_NULLPTR, int base = 10) const; short QString::toShort(bool *ok = Q_NULLPTR, int base = 10) const; long QString::toLong(bool *ok = Q_NULLPTR, int base = 10) const float QString::toFloat(bool *ok = Q_NULLPTR) const; double QString::toDouble(bool *ok = Q_NULLPTR) const; // 将标准C++中的 std::string 类型 转换为 QString 类型 [static] QString QString::fromStdString(const std::string \u0026amp;str); // 将 QString 转换为 标准C++中的 std::string 类型 std::string QString::toStdString() const; // QString -\u0026gt; QByteArray // 转换为本地编码, 跟随操作系统 QByteArray QString::toLocal8Bit() const; // 转换为 Latin-1 编码的字符串 不支持中文 QByteArray QString::toLatin1() const; // 转换为 utf8 编码格式的字符串 (常用) QByteArray QString::toUtf8() const; // 所有字符转换为大写 QString QString::toUpper() const; // 所有字符转换为小写 QString QString::toLower() const; 字符串格式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 其他重载的同名函数可参考Qt帮助文档, 此处略 QString QString::arg(const QString \u0026amp;a, int fieldWidth = 0, QChar fillChar = QLatin1Char( \u0026#39; \u0026#39; )) const; QString QString::arg(int a, int fieldWidth = 0, int base = 10, QChar fillChar = QLatin1Char( \u0026#39; \u0026#39; )) const; // 示例程序 int i; // 假设该变量表示当前文件的编号 int total; // 假设该变量表示文件的总个数 QString fileName; // 假设该变量表示当前文件的名字 // 使用以上三个变量拼接一个动态字符串 QString status = QString(\u0026#34;Processing file %1 of %2: %3\u0026#34;) .arg(i).arg(total).arg(fileName); 3. QVariant QVariant这个类很神奇，或者说方便。很多时候，需要几种不同的数据类型需要传递，如果用结构体，又不大方便，容器保存的也只是一种数据类型，而QVariant则可以统统搞定。\nQVariant 这个类型充当着最常见的数据类型的联合。QVariant 可以保存很多Qt的数据类型，包括QBrush、QColor、QCursor、QDateTime、QFont、QKeySequence、 QPalette、QPen、QPixmap、QPoint、QRect、QRegion、QSize和QString，并且还有C++基本类型，如 int、float等。\n标准类型 将标准类型转换为 QVariant 类型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // 这类转换需要使用QVariant类的构造函数, 由于比较多, 大家可自行查阅Qt帮助文档, 在这里简单写几个 QVariant::QVariant(int val); QVariant::QVariant(bool val); QVariant::QVariant(double val); QVariant::QVariant(const char *val); QVariant::QVariant(const QByteArray \u0026amp;val); QVariant::QVariant(const QString \u0026amp;val); ...... // 使用设置函数也可以将支持的类型的数据设置到QVariant对象中 // 这里的 T 类型, 就是QVariant支持的类型 void QVariant::setValue(const T \u0026amp;value); // 该函数行为和 setValue() 函数完全相同 [static] QVariant QVariant::fromValue(const T \u0026amp;value); // 例子: #if 1 QVariant v; v.setValue(5); #else QVariant v = QVariant::fromValue(5); #endif int i = v.toInt(); // i is now 5 QString s = v.toString(); // s is now \u0026#34;5\u0026#34; 判断 QVariant 中封装的实际数据类型\n1 QVariant::typeId() == QMetaType::type 将QVariant对象转换为实际的数据类型\n1 2 3 4 5 6 7 8 9 // 如果要实现该操作, 可以使用QVariant类提供的 toxxx() 方法, 全部转换可以参考Qt帮助文档 // 在此举列举几个常用函数: bool QVariant::toBool() const; QByteArray QVariant::toByteArray() const; double QVariant::toDouble(bool *ok = Q_NULLPTR) const; float QVariant::toFloat(bool *ok = Q_NULLPTR) const; int QVariant::toInt(bool *ok = Q_NULLPTR) const; QString QVariant::toString() const; ...... 演示代码 头文件\n1 QVariant dataPlus(QVariant a, QVariant b); 源文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #include \u0026#34;MainWindow.h\u0026#34; #include \u0026lt;qcontainerinfo.h\u0026gt; #include \u0026lt;qdebug.h\u0026gt; #include \u0026lt;qglobal.h\u0026gt; #include \u0026lt;qobjectdefs.h\u0026gt; #include \u0026lt;qvariant.h\u0026gt; MainWindow::MainWindow(QWidget* parent) : QMainWindow(parent) , ui(new Ui_MainWindow) { ui-\u0026gt;setupUi(this); int value = dataPlus(10, 20).toInt(); QString str = dataPlus(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;).toString(); qDebug() \u0026lt;\u0026lt; \u0026#34;Int :\u0026#34; \u0026lt;\u0026lt; value; qDebug() \u0026lt;\u0026lt; \u0026#34;String :\u0026#34; \u0026lt;\u0026lt; str; } MainWindow::~MainWindow() { delete ui; } QVariant MainWindow::dataPlus(QVariant a, QVariant b) { QVariant ans; if (a.typeId() == QMetaType::Int \u0026amp;\u0026amp; b.typeId() == QMetaType::Int) { ans = QVariant(a.toInt() + b.toInt()); } else if (a.typeId() == QMetaType::QString \u0026amp;\u0026amp; b.typeId() == QMetaType::QString) { ans.setValue(a.toString() + b.toString()); } return ans; } 我用的是qt6，有些函数已被弃用，所以具体代码和视频讲解的有些不同\n自定义类型 除了标准类型, 我们自定义的类型也可以使用QVariant类进行封装, 被QVariant存储的数据类型需要有一个默认的构造函数和一个拷贝构造函数。为了实现这个功能，首先必须使用Q_DECLARE_METATYPE()宏。通常会将这个宏放在类的声明所在头文件的下面， 原型为：\n1 Q_DECLARE_METATYPE(Type) 使用的具体步骤如下:\n在头文件中声明 1 2 3 4 5 6 7 struct Person { int id; QString name; }; // 自定义类型注册 Q_DECLARE_METATYPE(Person) 在源文件中定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Person p; p.id = 10; p.name = \u0026#34;person\u0026#34;; #if 0 QVariant v; v.setValue(p); #else QVariant v = QVariant::fromValue(p); #endif // 提取出 v 对象中的数据 if (v.canConvert\u0026lt;Person\u0026gt;()) { Person tmp = v.value\u0026lt;Person\u0026gt;(); qDebug() \u0026lt;\u0026lt; tmp.id \u0026lt;\u0026lt; tmp.name; } canConvert函数官方文档：\n1 2 3 4 5 6 7 8 QVariant v = 42; v.canConvert\u0026lt;int\u0026gt;(); // return true v.canConvert\u0026lt;QString\u0026gt;(); // return true MyCustomStruct s; v.setValue(s); v.canConvert\u0026lt;int\u0026gt;(); // return false v.canConvert\u0026lt;MyCustomStruct\u0026gt;(); // return true ","date":"2025-03-12T00:00:00Z","image":"https://serennan.github.io/post/qt-base-2/cover.png","permalink":"https://serennan.github.io/post/qt-base-2/","title":"【Qt 入门】2 基础数据类型"},{"content":"Qt 入门 这一系列Qt知识的笔记是根据爱编程的大丙所写，写的很详细，也有对应的视频讲解。\n第一个Qt项目 这里我为了与视频文件名对应，重新创了一个项目，项目名字是 mainwindow\nmain.cpp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026#34;mainwindow.h\u0026#34; #include \u0026lt;QApplication\u0026gt; #pragma comment(lib, \u0026#34;user32.lib\u0026#34;) int main(int argc, char *argv[]) { // 创建应用程序对象, 在一个Qt项目中实例对象有且仅有一个 // 类的作用: 检测触发的事件, 进行事件循环并处理 QApplication a(argc, argv); // 创建窗口对象 mainwindow w; // 显示窗口 w.show(); // 阻塞函数，应用程序对象开始事件循环，保证应用程序不退出 return a.exec(); } mainwindow.ui 在Qt中每一个窗口都对应一个可编辑的可视化界面（*.ui）, 这个界面对应的是一个xml格式的文件, 一般情况下不需要在xml格式下对这个文件进行编辑, 关于这个文件结构了解即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;ui version=\u0026#34;4.0\u0026#34;\u0026gt; \u0026lt;class\u0026gt;mainwindow\u0026lt;/class\u0026gt; \u0026lt;widget class=\u0026#34;QMainWindow\u0026#34; name=\u0026#34;mainwindow\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;geometry\u0026#34;\u0026gt; \u0026lt;rect\u0026gt; \u0026lt;x\u0026gt;0\u0026lt;/x\u0026gt; \u0026lt;y\u0026gt;0\u0026lt;/y\u0026gt; \u0026lt;width\u0026gt;800\u0026lt;/width\u0026gt; \u0026lt;height\u0026gt;600\u0026lt;/height\u0026gt; \u0026lt;/rect\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;windowTitle\u0026#34;\u0026gt; \u0026lt;string\u0026gt;mainwindow\u0026lt;/string\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;widget class=\u0026#34;QWidget\u0026#34; name=\u0026#34;centralwidget\u0026#34;/\u0026gt; \u0026lt;widget class=\u0026#34;QMenuBar\u0026#34; name=\u0026#34;menubar\u0026#34;/\u0026gt; \u0026lt;widget class=\u0026#34;QStatusBar\u0026#34; name=\u0026#34;statusbar\u0026#34;/\u0026gt; \u0026lt;/widget\u0026gt; \u0026lt;resources/\u0026gt; \u0026lt;connections/\u0026gt; \u0026lt;/ui\u0026gt; mainwindow.h 这个文件是窗口界面对应的类的头文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #pragma once #include \u0026#34;ui_mainwindow.h\u0026#34; #include \u0026lt;QMainWindow\u0026gt; // Qt 标准窗口类头文件 class mainwindow : public QMainWindow { Q_OBJECT; // 这个宏是为了能够使用Qt中的信号槽机制 public: mainwindow(QWidget *parent = nullptr); ~mainwindow(); private: Ui_mainwindow *ui; // 定义指针指向窗口的 UI 对象 }; mainwindow.cpp 这个文件是窗口界面对应的类的源文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 #include \u0026#34;mainwindow.h\u0026#34; mainwindow::mainwindow(QWidget* parent) : QMainWindow(parent) , ui(new Ui_mainwindow) // 基于 mainwindow.ui 创建一个实例对象 { // 将 mainwindow.ui 的示例对象和当前类的对象进行关联 ui-\u0026gt;setupUi(this); } mainwindow::~mainwindow() { delete ui; } Qt 窗口类 基础窗口类 常用的窗口类有3个\n在创建Qt窗口的时候, 需要让自己的窗口类继承上述三个窗口类的其中一个\nQWidget\n所有窗口类的基类\nQt中的控件(按钮, 输入框, 单选框…)也属于窗口, 基类都是 QWidget\n可以内嵌到其他窗口中: 没有边框 可以不内嵌单独显示: 独立的窗口, 有边框\nQDialog\n对话框类, 后边的章节会具体介绍这个窗口 不能内嵌到其他窗口中\nQMainWindow\n有工具栏, 状态栏, 菜单栏, 后边的章节会具体介绍这个窗口不能内嵌到其他窗口中 QWidget 所有窗口的基类\n内嵌窗口\n依附于某一个大的窗口, 作为了大窗口的一部分 大窗口就是这个内嵌窗口的父窗口 父窗口显示的时候, 内嵌的窗口也就被显示出来了 不内嵌窗口\n这类窗口有边框, 有标题栏 需要调用函数才可以显示 代码 由于我们使用的是 cmake 构建项目，即使使用的是Qtcreator，也没法跟视频一样直接添加一个新文件，所以我们只能手动添加。\n不过依然可以在 VScode使用Qtconfigure快速构建一个新的项目，命名为widget好了，但是需要做一些修改：\nwidget.h\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #pragma once #include \u0026#34;ui_widget.h\u0026#34; #include \u0026lt;QWidget\u0026gt; class widget : public QWidget // 继承 QWidget 而不是 QMainWindow { Q_OBJECT public: widget(QWidget *parent = nullptr); ~widget(); private: Ui_widget *ui; }; widget.cpp\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026#34;widget.h\u0026#34; widget::widget(QWidget *parent) : QWidget(parent), // 初始化列表也要记得修改类型 ui(new Ui_widget) { ui-\u0026gt;setupUi(this); } widget::~widget() { delete ui; } widget.ui\n1 \u0026lt;widget class=\u0026#34;QWidget\u0026#34; name=\u0026#34;newwindow\u0026#34;\u0026gt; 要修改成 QWidget\nmainwindow.cpp\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #include \u0026#34;mainwindow.h\u0026#34; #include \u0026#34;src/newwindow.h\u0026#34; mainwindow::mainwindow(QWidget *parent) : QMainWindow(parent), ui(new Ui_mainwindow) // 基于 mainwindow.ui 创建一个实例对象 { // 将 mainwindow.ui 的示例对象和当前类的对象进行关联 ui-\u0026gt;setupUi(this); // 一般在 qt 的构造函数中进行初始化操作（窗口，数据，...） // 显示当前窗口的时候，显示另外一个窗口 NewWindow #if 0 // 创建窗口对象，没有给 w 对象指定父对象 newwindow *w = new newwindow; w-\u0026gt;show(); #else // 创建窗口对象，没有给 w 对象指定父对象 // newwindow(QWidget* parent = nullptr); newwindow *w = new newwindow(this); #endif } mainwindow::~mainwindow() { delete ui; } QDialog 对话框窗口类\n有模态和非模态两种\n不能内嵌\n代码 1 2 3 4 5 6 7 8 9 10 11 12 #if 0 // 创建对话框窗口 dialog *dlg = new dialog(this); // 非模态 dlg-\u0026gt;show(); #else // 创建对话框窗口 dialog *dlg = new dialog(this); // 模态,exec() // 阻塞程序运行 dlg-\u0026gt;exec(); #endif 使用模态时，启动程序发现只有两个子窗口，主窗口没显示，这是因为 exec() 函数阻塞程序运行，导致主窗口的构造函数没有运行完。\n且这时候我们无法关闭 widget 窗口，只有当我们把dialog窗口关闭时，widget窗口才能被聚焦，且主窗口也会显示。\nQMainWindow 具有菜单栏，工具栏，状态栏\n工程结构调整 太多窗口类堆在src文件夹下可能难以维护，所以可以看这篇文章调整一下工程结构： 【Qt配置】工程结构调整\n","date":"2025-03-09T00:00:00Z","image":"https://serennan.github.io/post/qt-base-1/cover.png","permalink":"https://serennan.github.io/post/qt-base-1/","title":"【Qt 入门】1 入门"},{"content":"VS 配置 Qt6 教程 雷神后面的视频是要开发一个图形界面，这里我使用vscode + qt + cmake来开发。\n1. 安装qt6 这里网上很多教程，推荐一个 CSDN 上的教程：Qt6入门教程 2：Qt6下载与安装\n主要区别是我下载的是 linux版本\n以及选择组件时，我使用的是6.5.3版本\n2. 安装插件 vscode安装好 Qt Tools 和 Qt Configure 这两个插件，并配置一下Qt Configure。\n注意这里的Qt Dir 存放的是安装好的qt的根目录，我这里多一个 Qt文件夹是因为我下载了多个版本的qt\n3. 启动项目 打开一个空文件夹，按下shift + ctrl + p 输入指令：\n1 QtConfigure:New Project 然后根据提示，项目名字 -\u0026gt; qt 组件 -\u0026gt; cmake -\u0026gt; 是否生成 ui 文件\n然后会生成下面这些文件\n1 2 3 4 5 6 7 . ├── CMakeLists.txt └── src ├── ffmpeg_qt.cpp ├── ffmpeg_qt.h ├── ffmpeg_qt.ui └── main.cpp 注意这里打开 CMakeLists.txt 文件会发现用的是 Qt5 的东西\n但我下载的是 Qt6 ，所以这里得改成 Qt6\n接下来用 CMake 来配置项目，按下shift + ctrl + p 输入指令：\n1 CMake：Configure with CMake Debugger 配置完运行项目\n出现窗口说明配置成功\n4. 单独修改ui界面 右键 ui 文件选择 Edit in Qt Designer 可以修改 ui 文件\n拖入一个按钮检验一下，保存并退出，再去查看ui文件会发现已经帮我们加上相应的代码，重新运行项目\n问题 如果没有出现窗口，可能还需要安装一个 VcXsrv\n后续再找时间写一个安装教程，这里先放一个别人的视频教程：\n","date":"2025-03-08T00:00:00Z","image":"https://serennan.github.io/post/qt-configure/cover.png","permalink":"https://serennan.github.io/post/qt-configure/","title":"【Qt 配置】 VS + Qt6"},{"content":"本文参考：我写了一首诗，把滑动窗口算法变成了默写题\n算法逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 int left = 0, right = 0; while (right \u0026lt; s.size()) { // 增大窗口 window.add(s[right]); right++; while (window needs shrink) { // 缩小窗口 window.remove(s[left]); left++; } } 这个算法技巧的时间复杂度是 O(N)，比字符串暴力算法要高效得多。\n其实最主要的是细节问题：比如说如何向窗口中添加新元素，如何缩小窗口，在窗口滑动的哪个阶段更新结果。\n代码框架 下面是一套滑动窗口算法的代码框架：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /* 滑动窗口算法框架 */ void slidingWindow(string s, string t) { unordered_map\u0026lt;char, int\u0026gt; need, window; for (char c : t) need[c]++; int left = 0, right = 0; int valid = 0; while (right \u0026lt; s.size()) { // c 是将移入窗口的字符 char c = s[right]; // 右移窗口 right++; // 进行窗口内数据的一系列更新 ... /*** debug 输出的位置 ***/ printf(\u0026#34;window: [%d, %d)\\n\u0026#34;, left, right); /********************/ // 判断左侧窗口是否要收缩 while (window needs shrink) { // d 是将移出窗口的字符 char d = s[left]; // 左移窗口 left++; // 进行窗口内数据的一系列更新 ... } } } 其中两处 \u0026hellip; 表示的更新窗口数据的地方，直接往里面填就行\n而且，这两个 \u0026hellip; 处的操作分别是右移和左移窗口更新操作，会发现它们操作是完全对称的。\n下面四道 LeetCode 原题来套这个框架\n一 最小覆盖子串 LeetCode 76 题，最小覆盖子串，难度 Hard：\n就是说要在 S(source) 中找到包含 T(target) 中全部字母的一个子串，且这个子串一定是所有可能子串中最短的。\n如果使用暴力解法，代码大概是这样的：\n1 2 3 4 for (int i = 0; i \u0026lt; s.size(); i++) for (int j = i + 1; j \u0026lt; s.size(); j++) if s[i:j] 包含 t 的所有字母: 更新答案 思路虽然简单，但是算法复杂度大于 O(N2)\n滑动窗口算法的思路是这样：\n1、我们在字符串 S 中使用双指针中的左右指针技巧，初始化 left = right = 0，把索引左闭右开区间 [left, right) 称为一个「窗口」。\n2、我们先不断地增加 right 指针扩大窗口 [left, right)，直到窗口中的字符串符合要求（包含了 T 中的所有字符）。\n3、此时，我们停止增加 right，转而不断增加 left 指针缩小窗口 [left, right)，直到窗口中的字符串不再符合要求（不包含 T 中的所有字符了）。同时，每次增加 left，我们都要更新一轮结果。\n4、重复第 2 和第 3 步，直到 right 到达字符串 S 的尽头。\n这个思路其实也不难，第 2 步相当于在寻找一个「可行解」，然后第 3 步在优化这个「可行解」，最终找到最优解，也就是最短的覆盖子串。左右指针轮流前进，窗口大小增增减减，窗口不断向右滑动，这就是「滑动窗口」这个名字的来历。\n下面画图理解一下，needs 和 window 相当于计数器，分别记录 T 中字符出现次数和「窗口」中的相应字符的出现次数。\n初始状态：\n增加 right，直到窗口 [left, right) 包含了 T 中所有字符：\n现在开始增加 left，缩小窗口 [left, right)：\n直到窗口中的字符串不再符合要求，left 不再继续移动：\n之后重复上述过程，先移动 right，再移动 left…… 直到 right 指针到达字符串 S 的末端，算法结束。\n上述过程就是滑动串口的算法思想，现在来看这个滑动窗口代码框架如何使用：\n首先，初始化 window 和 need 两个哈希表，记录窗口中的字符和需要凑齐的字符：\n1 2 unordered_map\u0026lt;char, int\u0026gt; need, window; for (char c : t) need[c]++; 然后，使用 left 和 right 变量初始化窗口的两端，不要忘了，区间 [left, right) 是左闭右开的，所以初始情况下窗口没有包含任何元素：\n1 2 3 4 5 int left = 0, right = 0; int valid = 0; while (right \u0026lt; s.size()) { // 开始滑动 } 其中 valid 变量表示窗口中满足 need 条件的字符个数，如果 valid 和 need.size 的大小相同，则说明窗口已满足条件，已经完全覆盖了串 T。\n现在开始套模板，只需要思考以下四个问题：\n当移动 right 扩大窗口，即加入字符时，应该更新哪些数据？\n什么条件下，窗口应该暂停扩大，开始移动 left 缩小窗口？\n当移动 left 缩小窗口，即移出字符时，应该更新哪些数据？\n我们要的结果应该在扩大窗口时还是缩小窗口时进行更新？ 如果一个字符进入窗口，应该增加 window 计数器；如果一个字符将移出窗口的时候，应该减少 window 计数器；当 valid 满足 need 时应该收缩窗口；应该在收缩窗口的时候更新最终结果。\n这里示例就用前面的图：\n1 2 S {E, B, B, A, N, C, F} T {A, B, C} 完整代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 string minWindow(string s, string t) { unordered_map\u0026lt;char, int\u0026gt; need, window; // need {A : 1, B : 1, C : 1} for (char c : t) need[c]++; int left = 0, right = 0; int valid = 0; // 记录最小覆盖子串的起始索引及长度 int start = 0, len = INT_MAX; while (right \u0026lt; s.size()) { // c 是将移入窗口的字符 char c = s[right]; // 右移窗口 right++; // 进行窗口内数据的一系列更新 if (need.count(c)) { window[c]++; // window{A : 1, B : 1, C : 0} valid = 2 if (window[c] == need[c]) { valid++; } } // 判断左侧窗口是否要收缩 while (valid == need.size()) { // 在这里更新最小覆盖子串 if (right - left \u0026lt; len) { start = left; len = right - left; } // d 是将移出窗口的字符 char d = s[left]; // 左移窗口 left++; // 进行窗口内数据的一系列更新 if (need.count(d)) { if (window[d] == need[d]) { valid--; } window[d]--; } } } // 返回最小覆盖子串 return len == INT_MAX ? \u0026#34;\u0026#34; : s.substr(start, len); } 需要注意的是，当我们发现某个字符在 window 的数量满足了 need 的需要，就要更新 valid，表示有一个字符已经满足要求。而且，你能发现，两次对窗口内数据的更新操作是完全对称的。\n当 valid == need.size() 时，说明 T 中所有字符已经被覆盖，已经得到一个可行的覆盖子串，现在应该开始收缩窗口了，以便得到「最小覆盖子串」。\n移动 left 收缩窗口时，窗口内的字符都是可行解，所以应该在收缩窗口的阶段进行最小覆盖子串的更新，以便从可行解中找到长度最短的最终结果。\n二 字符串排列 LeetCode 567 题，字符串排列，难度 Medium：\n注意输入的 s1 是可以包含重复字符的。\n这种题目，是明显的滑动窗口算法，相当给你一个 S 和一个 T，请问你 S 中是否存在一个子串，包含 T 中所有字符且不包含其他字符？\n先复制粘贴之前的算法框架代码，然后明确刚才提出的 4 个问题，即可写出这道题的答案：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // 判断 s 中是否存在 t 的排列 bool checkInclusion(string t, string s) { unordered_map\u0026lt;char, int\u0026gt; need, window; for (char c : t) need[c]++; int left = 0, right = 0; int valid = 0; while (right \u0026lt; s.size()) { char c = s[right]; right++; // 进行窗口内数据的一系列更新 if (need.count(c)) { window[c]++; if (window[c] == need[c]) { valid++; } } // 判断左侧窗口是否要收缩 while (right - left \u0026gt;= t.size()) { // 在这里判断是否找到了合法的子串 if (valid == need.size()) return true; char d = s[left]; left++; // 进行窗口内数据的一系列更新 if (need.count(d)) { if (window[d] == need[d]) { valid--; } window[d]--; } } } // 未找到符合条件的子串 return false; } 对于这道题的解法代码，基本上和最小覆盖子串一模一样，只需要改变两个地方：\n本题移动 left 缩小窗口的时机是窗口大小大于 t.size() 时，应为排列嘛，显然长度应该是一样的。\n当发现 valid == need.size() 时，就说明窗口中就是一个合法的排列，所以立即返回 true。 至于如何处理窗口的扩大和缩小，和最小覆盖子串完全相同。\n三 找所有字母异位词 这是 LeetCode 第 438 题，找到字符串中所有字母异位词，难度 Medium：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 vector\u0026lt;int\u0026gt; findAnagrams(string s, string t) { unordered_map\u0026lt;char, int\u0026gt; need, window; for (char c : t) need[c]++; int left = 0, right = 0; int valid = 0; vector\u0026lt;int\u0026gt; res; // 记录结果 while (right \u0026lt; s.size()) { char c = s[right]; right++; // 进行窗口内数据的一系列更新 if (need.count(c)) { window[c]++; if (window[c] == need[c]) { valid++; } } // 判断左侧窗口是否要收缩 while (right - left \u0026gt;= t.size()) { // 当窗口符合条件时，把起始索引加入 res if (valid == need.size()) res.push_back(left); char d = s[left]; left++; // 进行窗口内数据的一系列更新 if (need.count(d)) { if (window[d] == need[d]) { valid--; } window[d]--; } } } return res; } 四 最长无重复子串 这是 LeetCode 第 3 题，最长无重复子串，难度 Medium：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Solution { public: int lengthOfLongestSubstring(string s) { unordered_map\u0026lt;char, int\u0026gt; window,need; int len = 0; int left = 0, right = 0; while(right \u0026lt; s.size()) { char c = s[right]; window[c]++; right++; while(window[c] \u0026gt; 1) { char d = s[left]; left++; window[d]--; } len = max(len,right - left); } return len; } }; 注意长度更新得在完成收缩之后。\n","date":"2025-03-05T00:00:00Z","image":"https://serennan.github.io/post/leetcode-window/cover.png","permalink":"https://serennan.github.io/post/leetcode-window/","title":"滑动窗口"},{"content":"Static 用法 本博客参照：CPlusPlusThings\n加上了一些自己的理解\n当与不同类型一起使用时，static关键字具有不同的含义。我们可以使用static关键字：\n静态变量： 函数中的变量，类中的变量\n静态类的成员： 类对象和类中的函数\n现在让我们详细看一下静态的这些用法\n静态变量 函数中的静态变量\n当变量声明为static时，空间将在程序的生命周期内分配。即使多次调用该函数，静态变量的空间也只分配一次，前一次调用中的变量值通过下一次函数调用传递。这对于在C / C ++或需要存储先前函数状态的任何其他应用程序非常有用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; void demo() { // static variable static int count = 0; cout \u0026lt;\u0026lt; count \u0026lt;\u0026lt; \u0026#34; \u0026#34;; // value is updated and // will be carried to next // function calls count++; } int main() { for (int i = 0; i \u0026lt; 5; i++) demo(); return 0; } 输出：\n1 0 1 2 3 4 可以在上面的程序中看到变量count被声明为static。因此，它的值通过函数调用来传递。每次调用函数时，都不会对变量计数进行初始化。\n类中的静态变量 初始化 由于声明为static的变量只被初始化一次，因为它们在单独的静态存储中分配了空间，因此类中的静态变量由对象共享。对于不同的对象，不能有相同静态变量的多个副本。也是因为这个原因，静态变量不能使用构造函数初始化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // variables inside a class #include \u0026lt;iostream\u0026gt; using namespace std; class Apple { public: static int i; Apple(){ // Do nothing }; }; int Apple::i = 0; // 要在类外初始化 int main() { Apple obj1; Apple obj2; obj1.i = 2; obj2.i = 3; // prints value of i cout \u0026lt;\u0026lt; obj1.i \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; obj2.i; } 输出：\n1 3 3 静态对象 就像变量一样，对象也在声明为static时具有范围，直到程序的生命周期。\n对象是非静态的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #include \u0026lt;iostream\u0026gt; using namespace std; class Apple { int i; public: Apple() { i = 0; cout \u0026lt;\u0026lt; \u0026#34;Inside Constructor\\n\u0026#34;; } ~Apple() { cout \u0026lt;\u0026lt; \u0026#34;Inside Destructor\\n\u0026#34;; } }; int main() { int x = 0; if (x == 0) { Apple obj; } cout \u0026lt;\u0026lt; \u0026#34;End of main\\n\u0026#34;; } 输出：\n1 2 3 Inside Constructor Inside Destructor End of main 在上面的程序中，对象在if块内声明为非静态。因此，变量的范围仅在if块内。因此，当创建对象时，将调用构造函数，并且在if块的控制权越过析构函数的同时调用，因为对象的范围仅在声明它的if块内。 如果我们将对象声明为静态，现在让我们看看输出的变化。\n对象是静态的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #include \u0026lt;iostream\u0026gt; using namespace std; class Apple { int i; public: Apple() { i = 0; cout \u0026lt;\u0026lt; \u0026#34;Inside Constructor\\n\u0026#34;; } ~Apple() { cout \u0026lt;\u0026lt; \u0026#34;Inside Destructor\\n\u0026#34;; } }; int main() { int x = 0; if (x == 0) { static Apple obj; } cout \u0026lt;\u0026lt; \u0026#34;End of main\\n\u0026#34;; } 输出：\n1 2 3 Inside Constructor End of main Inside Destructor 可以清楚地看到输出的变化。现在，在main结束后调用析构函数。这是因为静态对象的范围是贯穿程序的生命周期。\n静态函数 就像类中的静态数据成员或静态变量一样，静态成员函数也不依赖于类的对象。允许使用对象和 . 来调用静态成员函数。但建议使用类名和范围解析运算符调用静态成员。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #include \u0026lt;iostream\u0026gt; using namespace std; class Apple { public: void A() { _static = 1; non_static = 1; B(); cout \u0026lt;\u0026lt; \u0026#34;A\u0026#34; \u0026lt;\u0026lt; endl; } static void B() { _static = 1; non_static = 1; // error A(); // error cout \u0026lt;\u0026lt; \u0026#34;B\u0026#34; \u0026lt;\u0026lt; endl; } private: int non_static; static int _static; }; // main function int main() { Apple a; a.A(); Apple :: B(); } 静态成员函数仅能访问静态数据成员或其他静态成员函数，它们无法访问类的非静态数据成员或成员函数。\n限定访问范围 static还有限定访问范围的作用（类似于匿名名字空间）\n1 2 3 4 5 6 7 8 // source1.cpp extern void sayHello(); const char *msg = \u0026#34;Hello World!\\n\u0026#34;; int main() { sayHello(); return 0; } 1 2 3 4 5 6 7 // source2.cpp #include \u0026lt;cstdio\u0026gt; extern char *msg; void sayHello() { printf(\u0026#34;%s\u0026#34;, msg); } 编译指令：\n1 2 3 g++ -c source1.cpp -o source1.o g++ -c source2.cpp -o source2.o g++ source1.o source2.o -o hello_program g++对于上面两个代码文件是可以正常编译并且打印Hello World!，但如果给source1.cpp中的msg加上static，则会导致undefined reference to \u0026lsquo;msg\u0026rsquo;的编译错误：\n1 2 3 4 5 6 7 8 // source1.cpp extern void sayHello(); static const char* msg = \u0026#34;Hello World!\\n\u0026#34;; int main() { sayHello(); return 0; } static关键字将变量的作用域限制在其定义的编译单元内部。这样，msg变量只能在source1.cpp中使用，对其他文件不可见。\n","date":"2025-03-04T00:00:00Z","image":"https://serennan.github.io/post/cpp_static/cover.png","permalink":"https://serennan.github.io/post/cpp_static/","title":"【C++ 基础进阶】 Static"},{"content":"脱离开发环境的独立播放器 视频链接 main() 函数参数 main()函数的参数 argc argv：全称为ARGument Counter 和 ARGument Vector。其中argv存储了来自于命令行的参数；而argc存储了参数的个数。\n例如在命令行中输入“ffmpeg -i test.mkv test.ts ”，则argc取值为4， 而argv[]数组取值如下：\nargv[0]=\u0026ldquo;ffmpeg\u0026rdquo; argv[1]=\u0026quot;-i\u0026quot; argv[2]=\u0026ldquo;test.mkv\u0026rdquo; argv[3]=\u0026ldquo;test.ts\u0026rdquo; 动态链接库 windows 后缀是dll，linux后缀是so\n动态链接库不能被编译进应用程序。因而使用应用程序的时候必须在相同目录下保存用到的动态链接库文件\nCMakeLists.txt其实已经链接好动态库了\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 #include \u0026#34;SDL2/SDL_keycode.h\u0026#34; extern \u0026#34;C\u0026#34; { #include \u0026lt;SDL2/SDL.h\u0026gt; #include \u0026lt;libavcodec/avcodec.h\u0026gt; #include \u0026lt;libavformat/avformat.h\u0026gt; #include \u0026lt;libavutil/imgutils.h\u0026gt; #include \u0026lt;libswscale/swscale.h\u0026gt; } const int bpp = 12; int screen_w = 500, screen_h = 500; const int pixel_w = 320, pixel_h = 180; unsigned char buffer[pixel_w * pixel_h * bpp / 8]; // SDL_USEREVENT是SDL库中预定义的一个用户事件起始值 // 刷新事件 #define REFRESH_EVENT (SDL_USEREVENT + 1) // 中断事件 #define BREAK_EVENT (SDL_USEREVENT + 2) // 暂停事件 #define PAUSE_EVENT (SDL_USEREVENT + 3) // 线程退出标志 int thread_exit = 0; // 暂停标志 bool pause = false; int refresh_video(void *opaque) { thread_exit = 0; pause = false; while (!thread_exit) { if (!pause) { SDL_Event event; event.type = REFRESH_EVENT; SDL_PushEvent(\u0026amp;event); } SDL_Delay(40); } thread_exit = 0; pause = false; // 推送一个退出主线程的事件 SDL_Event event; event.type = BREAK_EVENT; SDL_PushEvent(\u0026amp;event); SDL_Delay(40); return 0; } int main(int argc, char *argv[]) { AVFormatContext *pFormatCtx = NULL; int videoindex = -1; AVCodecContext *pCodecCtx = NULL; const AVCodec *pCodec = NULL; AVFrame *pFrame = NULL, *pFrameYUV = NULL; unsigned char *out_buffer = NULL; AVPacket *packet = NULL; int ret = 0; struct SwsContext *img_convert_ctx = NULL; if (argc != 2) { printf(\u0026#34;输入格式错误！程序名 文件名\u0026#34;); return 1; } const char *filepath = argv[1]; FILE *fp_yuv = fopen(\u0026#34;output.yuv\u0026#34;, \u0026#34;wb+\u0026#34;); // 初始化FFmpeg库 avformat_network_init(); // 打开输入文件 if (avformat_open_input(\u0026amp;pFormatCtx, filepath, NULL, NULL) != 0) { printf(\u0026#34;Couldn\u0026#39;t open input stream.\\n\u0026#34;); return -1; } // 获取流信息 if (avformat_find_stream_info(pFormatCtx, NULL) \u0026lt; 0) { printf(\u0026#34;Couldn\u0026#39;t find stream information.\\n\u0026#34;); return -1; } // 查找视频流 for (int i = 0; i \u0026lt; pFormatCtx-\u0026gt;nb_streams; i++) { if (pFormatCtx-\u0026gt;streams[i]-\u0026gt;codecpar-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO) { videoindex = i; break; } } if (videoindex == -1) { printf(\u0026#34;Didn\u0026#39;t find a video stream.\\n\u0026#34;); return -1; } // 获取解码器 pCodec = avcodec_find_decoder(pFormatCtx-\u0026gt;streams[videoindex]-\u0026gt;codecpar-\u0026gt;codec_id); if (pCodec == NULL) { printf(\u0026#34;Codec not found.\\n\u0026#34;); return -1; } // 创建解码器上下文 pCodecCtx = avcodec_alloc_context3(pCodec); if (!pCodecCtx) { printf(\u0026#34;Could not allocate video codec context\\n\u0026#34;); return -1; } // 复制流参数到解码器上下文 if (avcodec_parameters_to_context(pCodecCtx, pFormatCtx-\u0026gt;streams[videoindex]-\u0026gt;codecpar) \u0026lt; 0) { printf(\u0026#34;Could not copy codec parameters to context\\n\u0026#34;); return -1; } // 打开解码器 if (avcodec_open2(pCodecCtx, pCodec, NULL) \u0026lt; 0) { printf(\u0026#34;Could not open codec.\\n\u0026#34;); return -1; } pFrame = av_frame_alloc(); pFrameYUV = av_frame_alloc(); out_buffer = (unsigned char *)av_malloc( av_image_get_buffer_size(AV_PIX_FMT_YUV420P, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, 1)); av_image_fill_arrays(pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize, out_buffer, AV_PIX_FMT_YUV420P, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, 1); packet = av_packet_alloc(); // 输出文件信息 printf(\u0026#34;--------------- File Information ----------------\\n\u0026#34;); av_dump_format(pFormatCtx, 0, filepath, 0); printf(\u0026#34;-------------------------------------------------\\n\u0026#34;); img_convert_ctx = sws_getContext(pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, pCodecCtx-\u0026gt;pix_fmt, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, AV_PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL); //==================SDL================== // 初始化 SDL 库 if (SDL_Init(SDL_INIT_VIDEO)) { printf(\u0026#34;Could not initialize SDL - %s\\n\u0026#34;, SDL_GetError()); return -1; } // 创建一个窗口 SDL_Window *screen; // SDL 2.0 Support for multiple windows screen_w = pCodecCtx-\u0026gt;width; screen_h = pCodecCtx-\u0026gt;height; screen = SDL_CreateWindow(\u0026#34;Simplest Video Play SDL2\u0026#34;, SDL_WINDOWPOS_CENTERED, SDL_WINDOWPOS_CENTERED, screen_w, screen_h, SDL_WINDOW_OPENGL | SDL_WINDOW_RESIZABLE); if (!screen) { printf(\u0026#34;SDL: could not create window - exiting:%s\\n\u0026#34;, SDL_GetError()); return -1; } // 创建一个渲染器，将窗口与渲染器关联 SDL_Renderer *sdlRenderer = SDL_CreateRenderer(screen, -1, 0); Uint32 pixformat = 0; // IYUV: Y + U + V (3 planes) // YV12: Y + V + U (3 planes) // 设置像素格式 // SDL_PIXELFORMAT_IYUV 表示使用 YUV420 pixformat = SDL_PIXELFORMAT_IYUV; // 创建纹理，用于存储视频数据 SDL_Texture *sdlTexture = SDL_CreateTexture(sdlRenderer, pixformat, SDL_TEXTUREACCESS_STREAMING, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height); SDL_Rect sdlRect; // 创建一个子线程，用于定时触发视频刷新事件 // 第一个参数是函数指针 SDL_Thread *refresh_thread = SDL_CreateThread(refresh_video, NULL, NULL); SDL_Event event; while (1) { SDL_WaitEvent(\u0026amp;event); if (event.type == REFRESH_EVENT) { while (1) { if ((av_read_frame(pFormatCtx, packet) \u0026lt; 0)) thread_exit = 1; if (packet-\u0026gt;stream_index == videoindex) break; } ret = avcodec_send_packet(pCodecCtx, packet); if (ret \u0026lt; 0) { printf(\u0026#34;Error sending a packet for decoding\\n\u0026#34;); return -1; } while (ret \u0026gt;= 0) { ret = avcodec_receive_frame(pCodecCtx, pFrame); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break; else if (ret \u0026lt; 0) { printf(\u0026#34;Error during decoding\\n\u0026#34;); return -1; } sws_scale(img_convert_ctx, (const unsigned char *const *)pFrame-\u0026gt;data, pFrame-\u0026gt;linesize, 0, pCodecCtx-\u0026gt;height, pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize); int y_size = pCodecCtx-\u0026gt;width * pCodecCtx-\u0026gt;height; // U V 是分量，宽高各压缩一半，所以大小是 Y 的 1/4 SDL_UpdateTexture(sdlTexture, NULL, pFrameYUV-\u0026gt;data[0], pFrameYUV-\u0026gt;linesize[0]); // FIX: If window is resize sdlRect.x = 0; sdlRect.y = 0; sdlRect.w = screen_w; sdlRect.h = screen_h; SDL_RenderClear(sdlRenderer); SDL_RenderCopy(sdlRenderer, sdlTexture, NULL, \u0026amp;sdlRect); SDL_RenderPresent(sdlRenderer); printf(\u0026#34;Succeed to decode 1 frame!\\n\u0026#34;); } av_packet_unref(packet); } // SDL_WINDOWEVENT 当窗口大小改变时，更新屏幕宽度和高度 else if (event.type == SDL_WINDOWEVENT) { // window SDL_GetWindowSize(screen, \u0026amp;screen_w, \u0026amp;screen_h); } // 当用户关闭窗口时，设置退出标志使子线程退出 else if (event.type == SDL_QUIT) { thread_exit = 1; } // 当接收到退出事件时，退出主循环并释放资源 // 这个退出事件由子线程提供 else if (event.type == BREAK_EVENT) { break; } else if (event.type == SDL_KEYDOWN) { if (event.key.keysym.sym == SDLK_SPACE) { pause = !pause; } if (event.key.keysym.sym == SDLK_ESCAPE) { thread_exit = 1; } } } // 刷新解码器 avcodec_send_packet(pCodecCtx, NULL); while (ret \u0026gt;= 0) { ret = avcodec_receive_frame(pCodecCtx, pFrame); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break; else if (ret \u0026lt; 0) { printf(\u0026#34;Error during decoding\\n\u0026#34;); return -1; } sws_scale(img_convert_ctx, (const unsigned char *const *)pFrame-\u0026gt;data, pFrame-\u0026gt;linesize, 0, pCodecCtx-\u0026gt;height, pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize); int y_size = pCodecCtx-\u0026gt;width * pCodecCtx-\u0026gt;height; fwrite(pFrameYUV-\u0026gt;data[0], 1, y_size, fp_yuv); // Y fwrite(pFrameYUV-\u0026gt;data[1], 1, y_size / 4, fp_yuv); // U fwrite(pFrameYUV-\u0026gt;data[2], 1, y_size / 4, fp_yuv); // V printf(\u0026#34;Flush Decoder: Succeed to decode 1 frame!\\n\u0026#34;); } sws_freeContext(img_convert_ctx); fclose(fp_yuv); av_frame_free(\u0026amp;pFrameYUV); av_frame_free(\u0026amp;pFrame); av_packet_free(\u0026amp;packet); avcodec_free_context(\u0026amp;pCodecCtx); avformat_close_input(\u0026amp;pFormatCtx); return 0; } 指令：\n1 ./main [视频文件] 断点的时候可以在 launch.json 加入预输入指令\n1 \u0026#34;args\u0026#34;: [\u0026#34;arg1\u0026#34;, \u0026#34;arg2\u0026#34;, \u0026#34;arg3\u0026#34;] ","date":"2025-03-03T00:00:00Z","image":"https://serennan.github.io/post/leixiaohua-note-5/cover.jpg","permalink":"https://serennan.github.io/post/leixiaohua-note-5/","title":"【雷霄骅课程笔记】5 FFmpeg + SDL 视频播放器进阶"},{"content":"FFmpeg 和 SDL 整合实现视频播放器 视频链接 整合方式 FFmpeg 解码器实现了：视频文件 -\u0026gt; YUV SDL 视频显示实现了：YUV -\u0026gt; 屏幕 整合：FFmpeg + SDL = 视频文件 -\u0026gt; 屏幕 代码运行 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 extern \u0026#34;C\u0026#34; { #include \u0026lt;SDL2/SDL.h\u0026gt; #include \u0026lt;libavcodec/avcodec.h\u0026gt; #include \u0026lt;libavformat/avformat.h\u0026gt; #include \u0026lt;libavutil/imgutils.h\u0026gt; #include \u0026lt;libswscale/swscale.h\u0026gt; } const int bpp = 12; int screen_w = 500, screen_h = 500; const int pixel_w = 320, pixel_h = 180; unsigned char buffer[pixel_w * pixel_h * bpp / 8]; // SDL_USEREVENT是SDL库中预定义的一个用户事件起始值 // 刷新事件 #define REFRESH_EVENT (SDL_USEREVENT + 1) // 中断事件 #define BREAK_EVENT (SDL_USEREVENT + 2) // 线程退出标志 int thread_exit = 0; int refresh_video(void *opaque) { thread_exit = 0; while (!thread_exit) { SDL_Event event; event.type = REFRESH_EVENT; SDL_PushEvent(\u0026amp;event); SDL_Delay(40); } thread_exit = 0; // 推送一个退出主线程的事件 SDL_Event event; event.type = BREAK_EVENT; SDL_PushEvent(\u0026amp;event); return 0; } int main(int argc, char *argv[]) { AVFormatContext *pFormatCtx = NULL; int videoindex = -1; AVCodecContext *pCodecCtx = NULL; const AVCodec *pCodec = NULL; AVFrame *pFrame = NULL, *pFrameYUV = NULL; unsigned char *out_buffer = NULL; AVPacket *packet = NULL; int ret = 0; struct SwsContext *img_convert_ctx = NULL; char filepath[] = \u0026#34;../video/Titanic.ts\u0026#34;; FILE *fp_yuv = fopen(\u0026#34;output.yuv\u0026#34;, \u0026#34;wb+\u0026#34;); // 初始化FFmpeg库 avformat_network_init(); // 打开输入文件 if (avformat_open_input(\u0026amp;pFormatCtx, filepath, NULL, NULL) != 0) { printf(\u0026#34;Couldn\u0026#39;t open input stream.\\n\u0026#34;); return -1; } // 获取流信息 if (avformat_find_stream_info(pFormatCtx, NULL) \u0026lt; 0) { printf(\u0026#34;Couldn\u0026#39;t find stream information.\\n\u0026#34;); return -1; } printf(\u0026#34;时长：%ld\\n\u0026#34;, pFormatCtx-\u0026gt;duration); // 查找视频流 for (int i = 0; i \u0026lt; pFormatCtx-\u0026gt;nb_streams; i++) { if (pFormatCtx-\u0026gt;streams[i]-\u0026gt;codecpar-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO) { videoindex = i; break; } } if (videoindex == -1) { printf(\u0026#34;Didn\u0026#39;t find a video stream.\\n\u0026#34;); return -1; } // 获取解码器 pCodec = avcodec_find_decoder(pFormatCtx-\u0026gt;streams[videoindex]-\u0026gt;codecpar-\u0026gt;codec_id); if (pCodec == NULL) { printf(\u0026#34;Codec not found.\\n\u0026#34;); return -1; } // 创建解码器上下文 pCodecCtx = avcodec_alloc_context3(pCodec); if (!pCodecCtx) { printf(\u0026#34;Could not allocate video codec context\\n\u0026#34;); return -1; } // 复制流参数到解码器上下文 if (avcodec_parameters_to_context(pCodecCtx, pFormatCtx-\u0026gt;streams[videoindex]-\u0026gt;codecpar) \u0026lt; 0) { printf(\u0026#34;Could not copy codec parameters to context\\n\u0026#34;); return -1; } // 打开解码器 if (avcodec_open2(pCodecCtx, pCodec, NULL) \u0026lt; 0) { printf(\u0026#34;Could not open codec.\\n\u0026#34;); return -1; } pFrame = av_frame_alloc(); pFrameYUV = av_frame_alloc(); out_buffer = (unsigned char *)av_malloc( av_image_get_buffer_size(AV_PIX_FMT_YUV420P, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, 1)); av_image_fill_arrays(pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize, out_buffer, AV_PIX_FMT_YUV420P, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, 1); packet = av_packet_alloc(); // 输出文件信息 printf(\u0026#34;--------------- File Information ----------------\\n\u0026#34;); av_dump_format(pFormatCtx, 0, filepath, 0); printf(\u0026#34;-------------------------------------------------\\n\u0026#34;); img_convert_ctx = sws_getContext(pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, pCodecCtx-\u0026gt;pix_fmt, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, AV_PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL); //==================SDL================== // 初始化 SDL 库 if (SDL_Init(SDL_INIT_VIDEO)) { printf(\u0026#34;Could not initialize SDL - %s\\n\u0026#34;, SDL_GetError()); return -1; } // 创建一个窗口 SDL_Window *screen; // SDL 2.0 Support for multiple windows screen_w = pCodecCtx-\u0026gt;width; screen_h = pCodecCtx-\u0026gt;height; screen = SDL_CreateWindow(\u0026#34;Simplest Video Play SDL2\u0026#34;, SDL_WINDOWPOS_CENTERED, SDL_WINDOWPOS_CENTERED, screen_w, screen_h, SDL_WINDOW_OPENGL | SDL_WINDOW_RESIZABLE); if (!screen) { printf(\u0026#34;SDL: could not create window - exiting:%s\\n\u0026#34;, SDL_GetError()); return -1; } // 创建一个渲染器，将窗口与渲染器关联 SDL_Renderer *sdlRenderer = SDL_CreateRenderer(screen, -1, 0); Uint32 pixformat = 0; // IYUV: Y + U + V (3 planes) // YV12: Y + V + U (3 planes) // 设置像素格式 // SDL_PIXELFORMAT_IYUV 表示使用 YUV420 pixformat = SDL_PIXELFORMAT_IYUV; // 创建纹理，用于存储视频数据 SDL_Texture *sdlTexture = SDL_CreateTexture(sdlRenderer, pixformat, SDL_TEXTUREACCESS_STREAMING, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height); SDL_Rect sdlRect; // 创建一个子线程，用于定时触发视频刷新事件 // 第一个参数是函数指针 SDL_Thread *refresh_thread = SDL_CreateThread(refresh_video, NULL, NULL); SDL_Event event; while (1) { SDL_WaitEvent(\u0026amp;event); if (event.type == REFRESH_EVENT) { while (1) { if ((av_read_frame(pFormatCtx, packet) \u0026lt; 0)) thread_exit = 1; if (packet-\u0026gt;stream_index == videoindex) break; } ret = avcodec_send_packet(pCodecCtx, packet); if (ret \u0026lt; 0) { printf(\u0026#34;Error sending a packet for decoding\\n\u0026#34;); return -1; } while (ret \u0026gt;= 0) { ret = avcodec_receive_frame(pCodecCtx, pFrame); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break; else if (ret \u0026lt; 0) { printf(\u0026#34;Error during decoding\\n\u0026#34;); return -1; } sws_scale(img_convert_ctx, (const unsigned char *const *)pFrame-\u0026gt;data, pFrame-\u0026gt;linesize, 0, pCodecCtx-\u0026gt;height, pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize); int y_size = pCodecCtx-\u0026gt;width * pCodecCtx-\u0026gt;height; // U V 是分量，宽高各压缩一半，所以大小是 Y 的 1/4 SDL_UpdateTexture(sdlTexture, NULL, pFrameYUV-\u0026gt;data[0], pFrameYUV-\u0026gt;linesize[0]); // FIX: If window is resize sdlRect.x = 0; sdlRect.y = 0; sdlRect.w = screen_w; sdlRect.h = screen_h; SDL_RenderClear(sdlRenderer); SDL_RenderCopy(sdlRenderer, sdlTexture, NULL, \u0026amp;sdlRect); SDL_RenderPresent(sdlRenderer); printf(\u0026#34;Succeed to decode 1 frame!\\n\u0026#34;); } av_packet_unref(packet); } // SDL_WINDOWEVENT 当窗口大小改变时，更新屏幕宽度和高度 else if (event.type == SDL_WINDOWEVENT) { // window SDL_GetWindowSize(screen, \u0026amp;screen_w, \u0026amp;screen_h); } // 当用户关闭窗口时，设置退出标志使子线程退出 else if (event.type == SDL_QUIT) { thread_exit = 1; } // 当接收到退出事件时，退出主循环并释放资源 // 这个退出事件由子线程提供 else if (event.type == BREAK_EVENT) { break; } } // 刷新解码器 avcodec_send_packet(pCodecCtx, NULL); while (ret \u0026gt;= 0) { ret = avcodec_receive_frame(pCodecCtx, pFrame); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break; else if (ret \u0026lt; 0) { printf(\u0026#34;Error during decoding\\n\u0026#34;); return -1; } sws_scale(img_convert_ctx, (const unsigned char *const *)pFrame-\u0026gt;data, pFrame-\u0026gt;linesize, 0, pCodecCtx-\u0026gt;height, pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize); int y_size = pCodecCtx-\u0026gt;width * pCodecCtx-\u0026gt;height; fwrite(pFrameYUV-\u0026gt;data[0], 1, y_size, fp_yuv); // Y fwrite(pFrameYUV-\u0026gt;data[1], 1, y_size / 4, fp_yuv); // U fwrite(pFrameYUV-\u0026gt;data[2], 1, y_size / 4, fp_yuv); // V printf(\u0026#34;Flush Decoder: Succeed to decode 1 frame!\\n\u0026#34;); } sws_freeContext(img_convert_ctx); fclose(fp_yuv); av_frame_free(\u0026amp;pFrameYUV); av_frame_free(\u0026amp;pFrame); av_packet_free(\u0026amp;packet); avcodec_free_context(\u0026amp;pCodecCtx); avformat_close_input(\u0026amp;pFormatCtx); return 0; } CMakeLists.txt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 cmake_minimum_required(VERSION 3.10) project(MyProject VERSION 1.0) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_BUILD_TYPE DEBUG) set(CMAKE_EXPORT_COMPILE_COMMANDS ON) # 添加头文件路径 include_directories(${PROJECT_SOURCE_DIR}/include) # 添加库文件路径 link_directories(${PROJECT_SOURCE_DIR}/lib) # 添加可执行文件 add_executable(main src/testPlayer.cpp) # 链接 FFmpeg 库 target_link_libraries(main avutil avcodec avformat swscale ) # 链接 SDL 库 target_link_libraries(main SDL2 SDL2main ) 代码分析 这段代码主要是整合我们前面所写的解码器和 SDL 视频播放器\n主要注意下面的几点\n1. 纹理数据 在创建纹理和更新纹理时，要给视频的数据，换成前面解码出来的视频数据就行\n1 2 3 4 5 6 // 创建纹理，用于存储视频数据 SDL_Texture *sdlTexture = SDL_CreateTexture(sdlRenderer, pixformat, SDL_TEXTUREACCESS_STREAMING, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height); // 更新纹理 SDL_UpdateTexture(sdlTexture, NULL, pFrameYUV-\u0026gt;data[0], pFrameYUV-\u0026gt;linesize[0]); 2. 循环读取一帧数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 while (1) { SDL_WaitEvent(\u0026amp;event); if (event.type == REFRESH_EVENT) { while (1) { if ((av_read_frame(pFormatCtx, packet) \u0026lt; 0)) thread_exit = 1; if (packet-\u0026gt;stream_index == videoindex) break; } ... } ... } 外层循环如果使用 while(av_read_frame(pFormatCtx, packet) \u0026gt;= 0) 可能导致的问题：\n解码流程混乱： 原代码采用事件驱动模型，由独立线程定时触发刷新事件，保证按正确帧率解码和渲染。\n修改后的外层 while (av_read_frame(...)) 循环破坏了原有同步机制，导致：\n过快读取 Packet ：可能连续发送多个 Packet 到解码器，未等待 SDL 渲染完成 未处理 B 帧依赖：H.264 的 B 帧需要前后参考帧，若解码顺序错误，导致参考帧丢失（reference picture missing） SDL事件处理冲突： 外层循环强制不断读取 Packet ，可能覆盖正在处理的数据，导致多线程竞争 SDL_WaitEvent 在内层阻塞时，外层循环可能持续读取，导致 Packet 堆积或处理顺序错乱 代码也可以改成这样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 while (1) { SDL_WaitEvent(\u0026amp;event); if (event.type == REFRESH_EVENT) { while (av_read_frame(pFormatCtx, packet) \u0026gt;= 0) { if (packet-\u0026gt;stream_index == videoindex) { ... } ... } ... } ... } 可能更清楚一点\n","date":"2025-03-02T00:00:00Z","image":"https://serennan.github.io/post/leixiaohua-note-4/cover.jpg","permalink":"https://serennan.github.io/post/leixiaohua-note-4/","title":"【雷霄骅课程笔记】4 FFmpeg + SDL 视频播放器"},{"content":"Const 用法 本博客参照：CPlusPlusThings\n加上了一些自己的理解。\n1. const 含义 常类型是指使用类型修饰符 const 说明的类型，常类型的变量或对象的值是不能被更新的。\n2. const 作用 定义常量\n1 const int a = 100; 类型检查\nconst 常量支持所有类型 其他情况下它只是一个 const 限定的变量，不要将与常量混淆。 防止修改，起保护作用，增加程序健壮性\n1 2 3 void f(const int i) { i++; // error! } 节省空间，避免不必要的内存分配\nconst 定义常量从汇编的角度来看，只是给出了对应的内存地址，而不是像 #define 一样给出的是立即数 const 定义的常量在程序运行过程中只有一份拷贝，而 #define 定义的常量在内存中有若干个拷贝 3. const 对象默认为文件局部变量 非 const 变量默认为 extern。要使 const 变量能够在其他文件中访问，必须在文件中显式地指定它为 extern\n未被 const 修饰的变量在不同文件的访问 1 2 // file1.cpp int ext; 1 2 3 4 5 6 7 // file2.cpp #include\u0026lt;iostream\u0026gt; extern int ext; int main() { std::cout \u0026lt;\u0026lt; (ext + 10) \u0026lt;\u0026lt; std::endl; } const 常量在不同文件的访问 1 2 // extern_file1.cpp extern const int ext = 12; // 定义时要显示声明为 extern ，且要初始化 1 2 3 4 5 6 // extern_file2.cpp #include\u0026lt;iostream\u0026gt; extern const int ext; int main() { std::cout \u0026lt;\u0026lt; ext \u0026lt;\u0026lt; std::endl; } 小结：\n可以发现未被 const 修饰的变量不需要 extern 显式声明。而 const 常量需要显式声明 extern，并且需要做初始化。因为常量在定义后就不能被修改，所以定义时必须初始化\n4. 定义常量 1 2 3 4 const int b = 10; b = 0; // error: assignment of read-only variable ‘b’ const std::string s = \u0026#34;helloworld\u0026#34;; const int i, j = 0; // error: uninitialized const ‘i’ 上述有两个错误:\nb 为常量，不可更改 i 为常量，必须进行初始化。（因为常量在定义后就不能被修改，所以定义时必须初始化） 5. 指针与 const 与指针相关的 const 有四种:\n1 2 3 4 const char *a; // 指向 const 对象的指针 char const *a; // 同上 char *const a; // 指向类型对象的 const 指针 const char *const a; // 指向 const 对象的 const 指针 小结：\n如果 const 位于 * 的左侧，则 const 是用来修饰指针所指向的变量，即指针指向为常量；\n如果 const 位于 * 的右侧，const 就是修饰指针本身，即指针本身是常量\n另一种解读方式\n利用英文从右边往左边读，并以 to 为分界，to 之前为描述指针的特性，to 之后为描述目标的特性\n1 2 3 4 const char *p; // p is a pointer to const char char const *p; // 同上 char *const p; // p is a const pointer to char const char *const p; // p is a const pointer to const char 当指针被加上 const 特性，则指针不可改变指向的地址；\n当指向的目标特性为 char，则内容可以通过指针被修改，如: *char = 'y';\n当指向的目标特性为 const char，则内容不可通过指针修改。\n（1） 指向常量的指针 1 2 const int *ptr; *ptr = 10; // error ptr 是一个指向 int 类型 const 对象的指针，const 定义的是 int 类型，也就是 ptr 所指向的对象类型，而不是 ptr 本身，所以 ptr 可以不用赋初始值。但是不能通过 ptr 去修改所指对象的值。\n除此之外，也不能使用 void* 指针保存 const 对象的地址，必须使用 const void* 类型的指针保存 const 对象的地址。\n1 2 3 const int p = 10; const void *vp = \u0026amp;p; void *vp = \u0026amp;p; // error 另外一个重点是：允许把非 const 对象的地址赋给指向 const 对象的指针\n将非 const 对象的地址赋给 const 对象的指针:\n1 2 3 4 const int *ptr; int val = 3; ptr = \u0026amp;val; // ok *ptr = 1; // error 我们不能通过 ptr 指针来修改 val 的值，即使它指向的是非 const 对象\n我们不能使用指向 const 对象的指针修改基础对象，然而如果该指针指向了非 const 对象，可用其他方式修改其所指的对象。可以修改 const 指针所指向的值的，但是不能通过 const 对象指针来进行而已。如下修改：\n1 2 3 4 int *ptr1 = \u0026amp;val; int val = 3; *ptr1 = 4; cout \u0026lt;\u0026lt; *ptr \u0026lt;\u0026lt; endl; 小结：\n对于指向常量的指针，不能通过指针来修改对象的值\n不能使用 void* 指针保存 const 对象的地址，必须使用 const void* 类型的指针保存const对象的地址\n允许把非const对象的地址赋值给const对象的指针，如果要修改指针所指向的对象值，必须通过其他方式修改，不能直接通过当前指针直接修改 （2） 常指针 const指针必须进行初始化，且const指针指向的值能修改，但指向不能修改。\n1 2 3 4 5 6 7 8 9 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { int num = 0, num1 = 1; int *const ptr = \u0026amp;num; // const指针必须初始化 且const指针的指向不能修改 ptr = \u0026amp;num1; // error const指针不能修改指向 cout \u0026lt;\u0026lt; *ptr \u0026lt;\u0026lt; endl; } 代码出现编译错误：const指针不能修改指向\n1 2 3 4 5 6 7 8 9 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { int num = 0, num1 = 1; int *const ptr = \u0026amp;num; // const指针必须初始化 且const指针的指向不能修改 *ptr = 1; // ok 修改指向的值 cout \u0026lt;\u0026lt; *ptr \u0026lt;\u0026lt; endl; } 代码无事发生，正常输出1\n最后，当把一个const常量的地址赋值给ptr时候，由于ptr指向的是一个变量，而不是const常量，所以会报错，出现：const int* -\u0026gt; int *的错误：\n1 2 3 4 5 6 7 8 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { const int num = 0; int *const ptr = \u0026amp;num; // error! const int* -\u0026gt; int* cout \u0026lt;\u0026lt; *ptr \u0026lt;\u0026lt; endl; } 上述若改为 const int *ptr或者改为const int *const ptr都可以：\n1 2 3 4 5 6 7 8 9 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { const int num = 10; const int *const ptr = \u0026amp;num; // const int *ptr = \u0026amp;num; cout \u0026lt;\u0026lt; *ptr \u0026lt;\u0026lt; endl; } 小结：\nconst 指针必须初始化，且指向的值能修改，指向不能修改 const 指针能指向非 const 对象，但是 const 对象必须用 const 指针 （3）指向常量的常指针 理解完前两种情况，下面这个情况就比较好理解了：\n1 2 const int p = 3; const int * const ptr = \u0026amp;p; ptr是一个const指针，然后指向了一个int 类型的const对象\n6.函数中使用const const修饰函数返回值 这个跟const修饰普通变量以及指针的含义基本相同：\n（1）const int\n1 const int func1(); 这个本身无意义，因为参数返回本身就是赋值给其他的变量。\n（2）const int*\n1 const int* func2(); 指针指向的内容不变。\n（3）int *const\n1 int *const func3(); 指针本身不可变。\nconst修饰函数参数 （1）传递过来的参数及指针本身在函数内不可变，无意义\n1 2 void func(const int var); // 传递过来的参数不可变 void func(int *const var); // 指针本身不可变 表明参数在函数体内不能被修改，但此处没有太多意义，var本身就是形参，加const只是保证在函数内不会改变。包括传入的形参是指针也是一样，加不加 const 对函数外效果都一样。\n输入参数采用“值传递”，由于函数将自动产生临时变量用于复制该参数，该输入参数本来就无需保护，所以不要加const 修饰。\n（2）参数指针所指内容为常量不可变\n1 void StringCopy(char *dst, const char *src); 其中src 是输入参数，dst 是输出参数。给src加上const修饰后，如果函数体内的语句试图改动src的内容，编译器将指出错误。这就是加了const的作用之一。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u0026lt;iostream\u0026gt; using namespace std; void change(int *dst, const int *src) { *dst = 2; // *src = 2; // error } int main() { int a = 1; int b = 1; int *ptr1 = \u0026amp;a; int *ptr2 = \u0026amp;b; change(ptr1, ptr2); cout \u0026lt;\u0026lt; \u0026#34;ptr1 -\u0026gt; \u0026#34; \u0026lt;\u0026lt; *ptr1 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;ptr2 -\u0026gt; \u0026#34; \u0026lt;\u0026lt; *ptr2 \u0026lt;\u0026lt; endl; } （3）参数为引用，为了增加效率同时防止修改。\n1 void func(const A \u0026amp;a) 对于非内部数据类型的参数而言，像void func(A a) 这样声明的函数注定效率比较低。因为函数体内将产生A 类型的临时对象用于复制参数a，而临时对象的构造、复制、析构过程都将消耗时间。\n为了提高效率，可以将函数声明改为void func(A \u0026amp;a)，因为“引用传递”仅借用一下参数的别名而已，不需要产生临时对象。\n但是函数void func(A \u0026amp;a) 存在一个缺点：\n“引用传递”有可能改变参数a，这是我们不期望的。解决这个问题很容易，加const修饰即可，因此函数最终成为 void func(const A \u0026amp;a)。\n以此类推，是否应将void func(int x) 改写为void func(const int \u0026amp;x)，以便提高效率？完全没有必要，因为内部数据类型的参数不存在构造、析构的过程，而复制也非常快，“值传递”和“引用传递”的效率几乎相当。\n小结：\n对于非内部数据类型的输入参数，应该将“值传递”的方式改为“const 引用传递”，目的是提高效率。例如将void func(A a) 改为void func(const A \u0026amp;a)\n对于内部数据类型的输入参数，不要将“值传递”的方式改为“const 引用传递”。否则既达不到提高效率的目的，又降低了函数的可理解性。例如void func(int x) 不应该改为void func(const int \u0026amp;x) 以上解决了两个面试问题：\n如果函数需要传入一个指针，是否需要为该指针加上const，把const加在指针不同的位置有什么区别； 如果写的函数需要传入的参数是一个复杂类型的实例，传入值参数或者引用参数有什么区别，什么时候需要为传入的引用参数加上const。 7.类中使用const 在一个类中，任何不会修改数据成员的函数都应该声明为const类型。如果在编写const成员函数时，不慎修改数据成员，或者调用了其它非const成员函数，编译器将指出错误，这无疑会提高程序的健壮性。\n使用const关键字进行说明的成员函数，称为常成员函数。只有常成员函数才有资格操作常量或常对象，没有使用const关键字进行说明的成员函数不能用来操作常对象。\n初始化 对于类中的const成员变量必须通过初始化列表进行初始化，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 class Apple{ private: int people[100]; public: Apple(int i); const int apple_number; }; Apple::Apple(int i):apple_number(i) { } 访问 const对象只能访问const成员函数,而非const对象可以访问任意的成员函数,包括const成员函数。\n例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #include \u0026lt;iostream\u0026gt; using namespace std; class Apple { private: int num; public: Apple(int i); const int apple_number; int add(int num); int take() const; }; Apple::Apple(int i) : apple_number(i) {} int Apple::add(int num) { add(num); return 0; } int Apple::take() const { add(1); // error return this-\u0026gt;num; } int main() { Apple a(2); a.add(10); a.take(); cout \u0026lt;\u0026lt; a.take() \u0026lt;\u0026lt; endl; const Apple b(3); b.add(100); // error b.take(); return 0; } 代码有两个错误：\nconst成员函数只能访问const成员函数\n此时报错，上面 take() 方法中调用了一个add()方法，而add()方法并非const修饰，所以运行报错\nconst 对象只能访问 const 成员函数\n对象 a 能访问 add() 和 take()。而对象 b 用const修饰，无法访问add()方法，只能访问take() 其他初始化方法 我们除了上述的初始化const常量用初始化列表方式外，也可以通过下面方法：\n第一：将常量定义与static结合：\n1 static const int apple_number 第二：在外面初始化：\n1 const int Apple::apple_number = 10; 当然，如果你使用c++11进行编译，直接可以在定义出初始化，可以直接写成：\n1 2 3 static const int apple_number = 10; // 或者 const int apple_number = 10; 这两种都在c++11中支持\n编译的时候加上-std=c++11即可\n这里提到了static，下面简单的说一下：\n在C++中，非const的static静态成员变量不能在类的内部初始化。在类的内部只是声明，定义必须在类定义体的外部，通常在类的实现文件中初始化。\n在类中声明：\n1 static int ap; 在类实现文件中使用：\n1 int Apple :: ap = 666 对于此项，c++11不能进行声明并初始化，也就是上述使用方法。\n练习 常成员函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 #include \u0026lt;iostream\u0026gt; using namespace std; class R { public: R(int r1, int r2) { R1 = r1; R2 = r2; } // const区分成员重载函数 void print(); void print() const; private: int R1, R2; }; /* 常成员函数说明格式：类型说明符 函数名（参数表）const; 这里，const是函数类型的一个组成部分，因此在实现部分也要带const关键字。 const关键字可以被用于参与对重载函数的区分 通过常对象只能调用它的常成员函数 */ void R::print() { cout \u0026lt;\u0026lt; \u0026#34;普通调用\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; R1 \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; R2 \u0026lt;\u0026lt; endl; } // 实例化也需要带上 void R::print() const { cout \u0026lt;\u0026lt; \u0026#34;常对象调用\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; R1 \u0026lt;\u0026lt; \u0026#34;;\u0026#34; \u0026lt;\u0026lt; R2 \u0026lt;\u0026lt; endl; } int main() { R a(5, 4); a.print(); // 调用void print() // 通过常对象只能调用它的常成员函数 const R b(20, 52); b.print(); // 调用void print() const return 0; } 常对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #include \u0026lt;iostream\u0026gt; using namespace std; void display(const double \u0026amp;r); class A { public: A(int i, int j) { x = i; y = j; } private: int x, y; }; int main() { double d(9.5); display(d); A const a(3, 4); // a 是常对象，不能被更新 return 0; } void display(const double \u0026amp;r) // 常引用做形参，在函数中不能更新 r 所引用的对象。 { cout \u0026lt;\u0026lt; r \u0026lt;\u0026lt; endl; } ","date":"2025-02-28T00:00:00Z","image":"https://serennan.github.io/post/cpp_const/cover.png","permalink":"https://serennan.github.io/post/cpp_const/","title":"【C++ 基础进阶】 Const"},{"content":"\n介绍Mermaid并分享优化配置的博客内容：\nMermaid 流程图优化配置指南 Mermaid 是一个强大的流程图绘制工具，支持多种图表类型，包括流程图、类图、状态图等。但在实际使用中，官方默认配置可能存在一些问题，比如节点文字过长导致显示不整齐、图表放大后文字模糊等。\n经过反复研究和优化，我整理出一套 Mermaid 的优化解决方案，完美解决这些痛点问题。以下是主要的优化功能：\n自动调整节点宽度：根据文字内容自动调整节点宽度，避免文字截断 文字自动换行：支持长文字自动换行显示 字体大小适配：不同的场景自动调整字体大小 流程图缩放：支持鼠标滚轮缩放，随时切换显示比例 偏移滚动：放大后支持拖拽查看图表任意区域 拖拽放大：点击进入放大模式，双击或 ESC 退出 移动端优化：自动适配手机和平板等移动设备 功能展示 flowchart TD A[\"程序启动\"] A --\u003e B[\"主线程\"] A --\u003e C[\"刷新线程 (refresh_video)\"] 节点自动调整\n节点宽度根据内容自动调整，避免文字溢出或过于 crowed\n文字换行支持\n长文字自动换行，保持内容清晰易读\n平滑缩放\n支持滚轮缩放（Ctrl + 滚轮），放大后仍然保持清晰\n拖拽查看\n放大后可以拖拽查看任意区域，操作流畅\n快捷操作\n单击：进入放大模式 滚轮：缩放图表 拖拽：平移视角 双击/ESC：退出放大模式 配置指南 我使用的是 stack 主题，不同主题文件结构可能不同\n创建 layouts/_default/_markup/render-codeblock-mermaid.html ： 1 2 3 4 5 \u0026lt;div class=\u0026#34;mermaid-container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;mermaid\u0026#34;\u0026gt; {{ .Inner | safeHTML }} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; 修改 layouts/_default/baseof.html ： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;{{ .Site.LanguageCode }}\u0026#34; dir=\u0026#34;{{ default `ltr` .Language.LanguageDirection }}\u0026#34;\u0026gt; \u0026lt;head\u0026gt; {{- partial \u0026#34;head/head.html\u0026#34; . -}} {{- block \u0026#34;head\u0026#34; . -}}{{ end }} \u0026lt;/head\u0026gt; \u0026lt;body class=\u0026#34;{{ block `body-class` . }}{{ end }}\u0026#34;\u0026gt; {{- partial \u0026#34;head/colorScheme\u0026#34; . -}} {{/* The container is wider when there\u0026#39;s any activated widget */}} {{- $hasWidget := false -}} {{- range .Site.Params.widgets -}} {{- if gt (len .) 0 -}} {{- $hasWidget = true -}} {{- end -}} {{- end -}} \u0026lt;div class=\u0026#34;container main-container flex on-phone--column {{ if $hasWidget }}extended{{ else }}compact{{ end }}\u0026#34;\u0026gt; {{- block \u0026#34;left-sidebar\u0026#34; . -}} {{ partial \u0026#34;sidebar/left.html\u0026#34; . }} {{- end -}} {{- block \u0026#34;right-sidebar\u0026#34; . -}}{{ end }} \u0026lt;main class=\u0026#34;main full-width\u0026#34;\u0026gt; {{- block \u0026#34;main\u0026#34; . }}{{- end }} \u0026lt;/main\u0026gt; \u0026lt;/div\u0026gt; {{ partial \u0026#34;footer/include.html\u0026#34; . }} {{ partial \u0026#34;article/components/mermaid.html\u0026#34; . }} \u0026lt;!-- 新增这一行 --\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 具体的路径主要看你放在哪，我就放在文章文件夹下了\n3. 创建 layouts/partials/article/components/mermaid.html，：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 {{- if .Page.Params.mermaid -}} \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{{ \u0026#34;css/mermaid.css\u0026#34; | relURL }}\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; mermaid.initialize({ startOnLoad: true, flowchart: { htmlLabels: false, useMaxWidth: false, nodeSpacing: 50, rankSpacing: 50, defaultRenderer: \u0026#39;svg\u0026#39; }, theme: \u0026#39;default\u0026#39;, securityLevel: \u0026#39;loose\u0026#39;, themeVariables: { nodeBorder: \u0026#39;#000\u0026#39;, mainBkg: \u0026#39;#fff\u0026#39;, nodeTextColor: \u0026#39;#000\u0026#39;, fontSize: \u0026#39;14px\u0026#39; } }); \u0026lt;/script\u0026gt; \u0026lt;!-- 遮罩层 --\u0026gt; \u0026lt;div class=\u0026#34;mermaid-overlay\u0026#34; id=\u0026#34;mermaidOverlay\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; document.addEventListener(\u0026#39;DOMContentLoaded\u0026#39;, () =\u0026gt; { // 自动调整节点尺寸 const adjustNodeSize = () =\u0026gt; { document.querySelectorAll(\u0026#39;.mermaid .node\u0026#39;).forEach(node =\u0026gt; { const rect = node.querySelector(\u0026#39;rect\u0026#39;); const text = node.querySelector(\u0026#39;text\u0026#39;); if (rect \u0026amp;\u0026amp; text) { const bbox = text.getBBox(); const padding = 16; const minWidth = parseFloat(rect.getAttribute(\u0026#39;width\u0026#39;)) || 160; const newWidth = Math.max(bbox.width + padding, minWidth); rect.setAttribute(\u0026#39;width\u0026#39;, newWidth); } }); }; // 初始化调整 adjustNodeSize(); window.addEventListener(\u0026#39;resize\u0026#39;, adjustNodeSize); // 为每个mermaid图表创建独立控制器 document.querySelectorAll(\u0026#39;.mermaid-container\u0026#39;).forEach(container =\u0026gt; { let currentScale = 1; let initialClickX = null, initialClickY = null; let dragOffsetX = 0, dragOffsetY = 0; let isDragging = false; let dragStartX = 0, dragStartY = 0; let isZoomed = false; const mermaidElement = container.querySelector(\u0026#39;.mermaid\u0026#39;); const overlay = document.getElementById(\u0026#39;mermaidOverlay\u0026#39;); const originalParent = container.parentElement; const originalNextSibling = container.nextElementSibling; // 应用变换 const applyScale = () =\u0026gt; { if (isZoomed \u0026amp;\u0026amp; initialClickX !== null \u0026amp;\u0026amp; initialClickY !== null) { const containerRect = container.getBoundingClientRect(); const centerX = containerRect.width / 2; const centerY = containerRect.height / 2; const baseTranslateX = centerX - initialClickX * currentScale; const baseTranslateY = centerY - initialClickY * currentScale; const translateX = baseTranslateX + dragOffsetX; const translateY = baseTranslateY + dragOffsetY; mermaidElement.style.transform = `translate(${translateX}px, ${translateY}px) scale(${currentScale})`; } else { mermaidElement.style.transform = `scale(${currentScale})`; } }; // 进入放大模式 const handleContainerClick = (e) =\u0026gt; { if (!isZoomed) { isZoomed = true; container.classList.add(\u0026#39;zoomed\u0026#39;); overlay.style.display = \u0026#39;flex\u0026#39;; overlay.appendChild(container); const containerRect = container.getBoundingClientRect(); initialClickX = e.clientX - containerRect.left; initialClickY = e.clientY - containerRect.top; dragOffsetX = 0; dragOffsetY = 0; const scaleX = window.innerWidth / containerRect.width; const scaleY = window.innerHeight / containerRect.height; currentScale = Math.min(scaleX, scaleY, 5); applyScale(); } }; // 退出放大模式 const exitZoom = () =\u0026gt; { if (isZoomed) { isZoomed = false; container.classList.remove(\u0026#39;zoomed\u0026#39;); overlay.style.display = \u0026#39;none\u0026#39;; if (originalNextSibling) { originalParent.insertBefore(container, originalNextSibling); } else { originalParent.appendChild(container); } currentScale = 1; initialClickX = null; initialClickY = null; dragOffsetX = 0; dragOffsetY = 0; applyScale(); } }; // 滚轮事件处理 const handleWheel = (e) =\u0026gt; { if (isZoomed) { e.preventDefault(); const sensitivity = 0.0006; const delta = e.deltaY || e.wheelDelta; const scaleDelta = 1 + (-delta * sensitivity); currentScale = Math.min(Math.max(0.3, currentScale * scaleDelta), 5); applyScale(); } else if (e.ctrlKey) { e.preventDefault(); const sensitivity = 0.0006; const delta = e.deltaY || e.wheelDelta; const scaleDelta = 1 + (-delta * sensitivity); currentScale = Math.min(Math.max(0.3, currentScale * scaleDelta), 5); applyScale(); } }; // 事件绑定 container.addEventListener(\u0026#39;click\u0026#39;, (e) =\u0026gt; { if (!isZoomed) handleContainerClick(e); }); container.addEventListener(\u0026#39;dblclick\u0026#39;, exitZoom); container.addEventListener(\u0026#39;wheel\u0026#39;, handleWheel); // 拖拽处理 container.addEventListener(\u0026#39;mousedown\u0026#39;, (e) =\u0026gt; { if (isZoomed) { isDragging = true; dragStartX = e.clientX; dragStartY = e.clientY; container.style.cursor = \u0026#39;grabbing\u0026#39;; } }); const handleMouseMove = (e) =\u0026gt; { if (isDragging) { const deltaX = e.clientX - dragStartX; const deltaY = e.clientY - dragStartY; dragOffsetX += deltaX; dragOffsetY += deltaY; dragStartX = e.clientX; dragStartY = e.clientY; applyScale(); } }; const handleMouseUp = () =\u0026gt; { isDragging = false; container.style.cursor = \u0026#39;grab\u0026#39;; }; document.addEventListener(\u0026#39;mousemove\u0026#39;, handleMouseMove); document.addEventListener(\u0026#39;mouseup\u0026#39;, handleMouseUp); }); // 全局ESC按键监听 document.addEventListener(\u0026#39;keydown\u0026#39;, (e) =\u0026gt; { if (e.key === \u0026#39;Escape\u0026#39;) { document.querySelectorAll(\u0026#39;.mermaid-container\u0026#39;).forEach(container =\u0026gt; { if (container.classList.contains(\u0026#39;zoomed\u0026#39;)) { container.dispatchEvent(new Event(\u0026#39;dblclick\u0026#39;)); } }); } }); }); \u0026lt;/script\u0026gt; {{- end -}} 修改 assets/scss/style.scss： 1 @import \u0026#34;partials/mermaid.scss\u0026#34;; 具体还是看你把 css 文件放在哪\n5. 创建 assets/scss/partials/mermaid.scss：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 /* 核心容器 */ .mermaid-container { position: relative; margin: 2rem 0; border-radius: 12px; overflow: auto; padding: 1.5rem; transition: transform 0.3s cubic-bezier(0.22, 0.61, 0.36, 1); user-select: none; } /* Mermaid 图表样式 */ .mermaid { transition: transform 0.25s cubic-bezier(0.22, 0.61, 0.36, 1); will-change: transform; backface-visibility: hidden; transform-origin: top left; text-align: center; line-height: 1.5; } /* 节点样式增强 */ .mermaid .node rect { rx: 8px; ry: 8px; filter: drop-shadow(2px 2px 4px rgba(0, 0, 0, 0.1)); min-width: 160px !important; /* 强制最小宽度 */ min-height: 60px !important; /* 强制最小高度 */ } .mermaid .node text { pointer-events: none; alignment-baseline: middle; text-anchor: middle; white-space: pre-wrap !important; /* 允许换行 */ word-wrap: break-word !important; overflow: visible !important; font-size: 14px !important; max-width: 150px !important; /* 限制文字最大宽度 */ padding: 8px !important; /* 添加内边距 */ } /* 边标签样式 */ .mermaid .edgeLabels foreignObject { background: var(--card, #fff); border-radius: 4px; padding: 2px 8px; display: block; text-align: center; min-width: 80px !important; white-space: pre-wrap !important; word-wrap: break-word !important; } /* 移动端优化 */ @media (max-width: 768px) { .mermaid-container { margin: 1rem -1rem; border-radius: 0; } .mermaid .node rect { min-width: 120px !important; min-height: 40px !important; } .mermaid .node text { font-size: 12px !important; max-width: 100px !important; } } /* 遮罩层 */ .mermaid-overlay { position: fixed; top: 0; left: 0; right: 0; bottom: 0; background: rgba(69, 71, 71, 0.5); backdrop-filter: blur(4px); z-index: 1000; display: none; justify-content: center; align-items: center; cursor: zoom-out; } /* 放大状态下的容器 */ .mermaid-container.zoomed { position: absolute; top: 50%; left: 50%; width: 100vw; height: 100vh; margin: 0; padding: 1.5rem; transform: translate(-50%, -50%); cursor: grab; transition: transform 0.3s cubic-bezier(0.22, 0.61, 0.36, 1); z-index: 1001; } .mermaid-container.zoomed:active { cursor: grabbing; } .mermaid-container.zoomed .mermaid { transform-origin: center center; cursor: default; overflow: visible; } ","date":"2025-02-27T00:00:00Z","image":"https://serennan.github.io/post/hugo-mermaid/cover.jpg","permalink":"https://serennan.github.io/post/hugo-mermaid/","title":"【Hugo】引入mermaid"},{"content":"SDL 视频播放器-进阶 视频链接 SDL 中事件和多线程 SDL 多线程 多个函数同时运行\n函数\nSDL_CreateThread()：创建一个线程 数据结构\nSDL_Thread：线程的句柄 SDL 事件 在SDL中，事件是用于处理用户输入和系统通知的机制\n函数\nSDL_WaitEvent()：等待一个事件\nSDL_PushEvent()：发送一个事件 数据结构 SDL_Event：代表一个事件 流程图 flowchart TD A[主线程] --\u003e B[初始化] B --\u003e C[创建子线程] C --\u003e D[进入主事件循环] subgraph 子线程 C --\u003e E[进入循环] E --\u003e F{检查退出标志} F -- 否 --\u003e G[推送REFRESH_EVENT] G --\u003e H[延时40ms] H --\u003e F F -- 是 --\u003e I[推送BREAK_EVENT] end D --\u003e J{等待事件} J --\u003e|REFRESH_EVENT| K[读取YUV数据] K --\u003e L[更新纹理] L --\u003e M[渲染到窗口] J --\u003e|SDL_WINDOWEVENT| N[更新窗口尺寸] J --\u003e|SDL_QUIT| O[设置退出标志] J --\u003e|BREAK_EVENT| P[退出循环] O --\u003e|通知子线程| F I --\u003e|触发| P 主线程：负责处理所有 SDL 事件（窗口关闭，窗口大小改变，视频刷新等）\n函数介绍 SDL_CreateThread()：创建一个线程\nSDL_WaitEvent()：等待事件 SDL_GetWindowSize()：获取窗口大小\n这里第一个参数 screen 是播放的窗口大小, 第二第三个参数 screen_w 和 screen_h 是获得的宽高，这里获得了宽高能直接赋值给前面的刷新事件使用，用来渲染新的窗口 代码运行 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 #include \u0026lt;stdio.h\u0026gt; extern \u0026#34;C\u0026#34; { #include \u0026#34;SDL2/SDL.h\u0026#34; }; const int bpp = 12; int screen_w = 500, screen_h = 500; const int pixel_w = 320, pixel_h = 180; unsigned char buffer[pixel_w * pixel_h * bpp / 8]; // SDL_USEREVENT是SDL库中预定义的一个用户事件起始值 // 刷新事件 #define REFRESH_EVENT (SDL_USEREVENT + 1) // 中断事件 #define BREAK_EVENT (SDL_USEREVENT + 2) // 线程退出标志 int thread_exit = 0; int refresh_video(void *opaque) { thread_exit = 0; while (!thread_exit) { SDL_Event event; event.type = REFRESH_EVENT; SDL_PushEvent(\u0026amp;event); SDL_Delay(40); } thread_exit = 0; // 推送一个退出主线程的事件 SDL_Event event; event.type = BREAK_EVENT; SDL_PushEvent(\u0026amp;event); return 0; } int main(int argc, char *argv[]) { // 初始化 SDL 库 if (SDL_Init(SDL_INIT_VIDEO)) { printf(\u0026#34;Could not initialize SDL - %s\\n\u0026#34;, SDL_GetError()); return -1; } // 创建一个窗口 SDL_Window *screen; // SDL 2.0 Support for multiple windows screen = SDL_CreateWindow(\u0026#34;Simplest Video Play SDL2\u0026#34;, SDL_WINDOWPOS_CENTERED, SDL_WINDOWPOS_CENTERED, screen_w, screen_h, SDL_WINDOW_OPENGL | SDL_WINDOW_RESIZABLE); if (!screen) { printf(\u0026#34;SDL: could not create window - exiting:%s\\n\u0026#34;, SDL_GetError()); return -1; } // 创建一个渲染器，将窗口与渲染器关联 SDL_Renderer *sdlRenderer = SDL_CreateRenderer(screen, -1, 0); Uint32 pixformat = 0; // IYUV: Y + U + V (3 planes) // YV12: Y + V + U (3 planes) // 设置像素格式 // SDL_PIXELFORMAT_IYUV 表示使用 YUV420 pixformat = SDL_PIXELFORMAT_IYUV; // 创建纹理，用于存储视频数据 SDL_Texture *sdlTexture = SDL_CreateTexture(sdlRenderer, pixformat, SDL_TEXTUREACCESS_STREAMING, pixel_w, pixel_h); // 打开 YUV 文件 FILE *fp = NULL; fp = fopen(\u0026#34;../video/test_yuv420p_320x180.yuv\u0026#34;, \u0026#34;rb+\u0026#34;); if (fp == NULL) { printf(\u0026#34;cannot open this file\\n\u0026#34;); return -1; } SDL_Rect sdlRect; // 创建一个子线程，用于定时触发视频刷新事件 // 第一个参数是函数指针 SDL_Thread *refresh_thread = SDL_CreateThread(refresh_video, NULL, NULL); SDL_Event event; while (1) { // 等待事件 SDL_WaitEvent(\u0026amp;event); if (event.type == REFRESH_EVENT) { if (fread(buffer, 1, pixel_w * pixel_h * bpp / 8, fp) != pixel_w * pixel_h * bpp / 8) { // Loop fseek(fp, 0, SEEK_SET); fread(buffer, 1, pixel_w * pixel_h * bpp / 8, fp); } SDL_UpdateTexture(sdlTexture, NULL, buffer, pixel_w); // FIX: If window is resize sdlRect.x = 0; sdlRect.y = 0; sdlRect.w = screen_w/2; sdlRect.h = screen_h/2; SDL_RenderClear(sdlRenderer); SDL_RenderCopy(sdlRenderer, sdlTexture, NULL, \u0026amp;sdlRect); SDL_RenderPresent(sdlRenderer); } // SDL_WINDOWEVENT 当窗口大小改变时，更新屏幕宽度和高度 else if (event.type == SDL_WINDOWEVENT) { // window SDL_GetWindowSize(screen, \u0026amp;screen_w, \u0026amp;screen_h); } // 当用户关闭窗口时，设置退出标志使子线程退出 else if (event.type == SDL_QUIT) { thread_exit = 1; } // 当接收到退出事件时，退出主循环并释放资源 // 这个退出事件由子线程提供 else if (event.type == BREAK_EVENT) { break; } } SDL_Quit(); return 0; } CMakeLists.txt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 指定 CMake 的最低版本要求 cmake_minimum_required(VERSION 3.10) # 设置项目名称和版本 project(MyProject VERSION 1.0) # 设置 C++ 标准 set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_BUILD_TYPE Debug) # 依赖 compile_commands.json 文件来理解项目的编译环境 set(CMAKE_EXPORT_COMPILE_COMMANDS ON) # 添加头文件路径 include_directories(${PROJECT_SOURCE_DIR}/include) # 添加库文件路径 link_directories(${PROJECT_SOURCE_DIR}/lib) # 添加可执行文件 add_executable(main src/videoPlayer.cpp) # 链接 FFmpeg 库 target_link_libraries(main avcodec avformat avutil) # 链接 SDL2 库· target_link_libraries(main SDL2 SDL2main) 练习 空格暂停功能 这里还添加了加速功能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 #include \u0026#34;SDL2/SDL_events.h\u0026#34; #include \u0026#34;SDL2/SDL_keycode.h\u0026#34; #include \u0026lt;stdio.h\u0026gt; extern \u0026#34;C\u0026#34; { #include \u0026#34;SDL2/SDL.h\u0026#34; }; const int bpp = 12; int screen_w = 500, screen_h = 500; const int pixel_w = 320, pixel_h = 180; unsigned char buffer[pixel_w * pixel_h * bpp / 8]; // SDL_USEREVENT是SDL库中预定义的一个用户事件起始值 // 刷新事件 #define REFRESH_EVENT (SDL_USEREVENT + 1) // 中断事件 #define BREAK_EVENT (SDL_USEREVENT + 2) // 暂停事件 #define PAUSE_EVENT (SDL_USEREVENT + 3) // 线程退出标志 int thread_exit = 0; // 暂停标志 bool video_paused = false; bool video_fast = false; int refresh_video(void *opaque) { thread_exit = 0; while (!thread_exit) { SDL_Event event; if (!video_fast \u0026amp;\u0026amp; !video_paused) { event.type = REFRESH_EVENT; SDL_PushEvent(\u0026amp;event); SDL_Delay(40); } else if(video_paused) { event.type = PAUSE_EVENT; SDL_PushEvent(\u0026amp;event); } else if (video_fast) { event.type = REFRESH_EVENT; SDL_PushEvent(\u0026amp;event); SDL_Delay(1); } } // 确保线程成功退出 thread_exit = 0; // 推送一个退出主线程的事件 SDL_Event event; event.type = BREAK_EVENT; SDL_PushEvent(\u0026amp;event); return 0; } int main(int argc, char *argv[]) { // 初始化 SDL 库 if (SDL_Init(SDL_INIT_VIDEO)) { printf(\u0026#34;Could not initialize SDL - %s\\n\u0026#34;, SDL_GetError()); return -1; } // 创建一个窗口 SDL_Window *screen; // SDL 2.0 Support for multiple windows screen = SDL_CreateWindow(\u0026#34;Simplest Video Play SDL2\u0026#34;, SDL_WINDOWPOS_CENTERED, SDL_WINDOWPOS_CENTERED, screen_w, screen_h, SDL_WINDOW_OPENGL | SDL_WINDOW_RESIZABLE); if (!screen) { printf(\u0026#34;SDL: could not create window - exiting:%s\\n\u0026#34;, SDL_GetError()); return -1; } // 创建一个渲染器，将窗口与渲染器关联 SDL_Renderer *sdlRenderer = SDL_CreateRenderer(screen, -1, 0); Uint32 pixformat = 0; // IYUV: Y + U + V (3 planes) // YV12: Y + V + U (3 planes) // 设置像素格式 // SDL_PIXELFORMAT_IYUV 表示使用 YUV420 pixformat = SDL_PIXELFORMAT_IYUV; // 创建纹理，用于存储视频数据 SDL_Texture *sdlTexture = SDL_CreateTexture(sdlRenderer, pixformat, SDL_TEXTUREACCESS_STREAMING, pixel_w, pixel_h); // 打开 YUV 文件 FILE *fp = NULL; fp = fopen(\u0026#34;../video/test_yuv420p_320x180.yuv\u0026#34;, \u0026#34;rb+\u0026#34;); if (fp == NULL) { printf(\u0026#34;cannot open this file\\n\u0026#34;); return -1; } SDL_Rect sdlRect; // 创建一个子线程，用于定时触发视频刷新事件 // 第一个参数是函数指针 SDL_Thread *refresh_thread = SDL_CreateThread(refresh_video, NULL, NULL); SDL_Event event; while (1) { // 等待事件 SDL_WaitEvent(\u0026amp;event); if (event.type == REFRESH_EVENT) { if (fread(buffer, 1, pixel_w * pixel_h * bpp / 8, fp) != pixel_w * pixel_h * bpp / 8) { // Loop fseek(fp, 0, SEEK_SET); fread(buffer, 1, pixel_w * pixel_h * bpp / 8, fp); } SDL_UpdateTexture(sdlTexture, NULL, buffer, pixel_w); // FIX: If window is resize sdlRect.x = 0; sdlRect.y = 0; sdlRect.w = screen_w; sdlRect.h = screen_h; SDL_RenderClear(sdlRenderer); SDL_RenderCopy(sdlRenderer, sdlTexture, NULL, \u0026amp;sdlRect); SDL_RenderPresent(sdlRenderer); } // SDL_WINDOWEVENT 当窗口大小改变时，更新屏幕宽度和高度 else if (event.type == SDL_WINDOWEVENT) { // window SDL_GetWindowSize(screen, \u0026amp;screen_w, \u0026amp;screen_h); } // 当用户关闭窗口时，设置退出标志使子线程退出 else if (event.type == SDL_QUIT) { thread_exit = 1; } // 当接收到退出事件时，退出主循环并释放资源 // 这个退出事件由子线程提供 else if (event.type == BREAK_EVENT) { break; } else if (event.type == PAUSE_EVENT) { // 什么都不做，等待响应 } else if (event.type == SDL_KEYDOWN) { if (event.key.keysym.sym == SDLK_SPACE) { video_paused = !video_paused; } if (event.key.keysym.sym == SDLK_ESCAPE) { thread_exit = 1; } if (event.key.keysym.sym == SDLK_BACKSPACE) { video_fast = !video_fast; } } } SDL_Quit(); return 0; } 黑白显示 在调用SDL_UpdateTexture之前，我添加代码来修改 U 和 V 分量\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 if (fread(buffer, 1, pixel_w * pixel_h * bpp / 8, fp) != pixel_w * pixel_h * bpp / 8) { // Loop fseek(fp, 0, SEEK_SET); fread(buffer, 1, pixel_w * pixel_h * bpp / 8, fp); } // 修改UV分量为中性值（128）以实现黑白效果 int y_size = pixel_w * pixel_h; unsigned char* u_plane = buffer + y_size; unsigned char* v_plane = buffer + y_size + (y_size / 4); // IYUV格式下U和V各占1/4 // 将所有U分量设置为128 memset(u_plane, 0x80, y_size / 4); // 将所有V分量设置为128 memset(v_plane, 0x80, y_size / 4); y_size 是 Y 的大小 u_plane 是 U 的起始位置（加上 Y 的大小） v_plane 是 V 的起始位置（加上 Y 和 U 的大小） memset 用于将一块内存区域填充成指定的字符，原型：\n1 void *memset(void *str, int c, size_t n); str: 要填充的内存地址 c: 填充的字符 n: 要填充的字符数量 在 YUV 颜色空间中，通过将 U 和 V 分量设置为中性值（通常是128，即0x80）来实现黑白显示，是基于以下原理：\nYUV 含义: Y (Luminance) : 表示图像的亮度信息 U (Chrominance) : 表示颜色的蓝色偏移 V (Chrominance) : 表示颜色的红色偏移 中性值： 在大多数 YUV 格式中， U 和 V 的中性值是 128（十六进制 0x80 ）。当 U = 128 且 V = 128 时，表示没有蓝色或红色的偏移，即纯灰度信号 YUV 到 RGB 的转换过程：\n1 2 3 R = Y + V - 128 G = Y - (U/2 + V/2) + 128 B = Y + U - 128 当 U = 128 且 V = 128 时：\n1 2 3 R = Y + 0 G = Y + 0 B = Y + 0 因此，R = G = B = Y ，生成灰度图像\n","date":"2025-02-25T00:00:00Z","image":"https://serennan.github.io/post/leixiaohua-note-3/cover.jpg","permalink":"https://serennan.github.io/post/leixiaohua-note-3/","title":"【雷霄骅课程笔记】3 SDL 视频播放器-进阶"},{"content":"SDL 视频播放 视频链接 SDL 介绍 SDL 视频显示流程 流程图 函数介绍 函数名 功能描述 SDL_Init() 初始化SDL系统 SDL_CreateWindow() 创建窗口 SDL_Window SDL_CreateRenderer() 创建渲染器 SDL_Renderer SDL_CreateTexture() 创建纹理 SDL_Texture SDL_UpdateTexture() 设置纹理的数据 SDL_RenderCopy() 将纹理的数据拷贝给渲染器 SDL_RenderPresent() 显示 SDL_Delay() 工具函数，用于延时 SDL_Quit() 退出SDL系统 SDL 视频显示的数据结构 解释：\nSDL_Texture：纹理，一个纹理对应一个 YUV 一个窗口不一定只有一个纹理，可以放很多个 SDL_Rect ： SDL 中的一个结构体，用于描述一个矩形的位置和尺寸 SDL_Renderer：渲染器，把纹理的数据给窗口 SDL_Window：窗口 代码运行 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 #include \u0026lt;stdio.h\u0026gt; extern \u0026#34;C\u0026#34; { #include \u0026#34;SDL2/SDL.h\u0026#34; }; const int bpp = 12; // 窗口的宽度和高度 int screen_w = 1000, screen_h = 1000; // 视频像素的宽度和高度 const int pixel_w = 320, pixel_h = 180; // 用于存储一帧 YUV 数据的缓冲区 unsigned char buffer[pixel_w * pixel_h * bpp / 8]; int main(int argc, char *argv[]) { // 初始化 SDL 库 if (SDL_Init(SDL_INIT_VIDEO)) { printf(\u0026#34;Could not initialize SDL - %s\\n\u0026#34;, SDL_GetError()); return -1; } // 创建窗口 SDL_Window *screen; // SDL 2.0 Support for multiple windows // title 窗口标题，x y 窗口位置，w h 窗口大小 // flags 标志包括允许改变窗口大小（SDL_WINDOW_RESIZABLE）和使用OpenGL（SDL_WINDOW_OPENGL screen = SDL_CreateWindow(\u0026#34;Simplest Video Play SDL2\u0026#34;, SDL_WINDOWPOS_CENTERED, SDL_WINDOWPOS_UNDEFINED, screen_w, screen_h, SDL_WINDOW_OPENGL | SDL_WINDOW_RESIZABLE); if (!screen) { printf(\u0026#34;SDL: could not create window - exiting:%s\\n\u0026#34;, SDL_GetError()); return -1; } // 创建渲染器，将窗口与渲染器关联 // index 使用默认的渲染驱动，flags 标志为 0 （不使用加速功能） SDL_Renderer *sdlRenderer = SDL_CreateRenderer(screen, -1, 0); Uint32 pixformat = 0; // IYUV: Y + U + V (3 planes) // YV12: Y + V + U (3 planes) // 设置像素格式 // SDL_PIXELFORMAT_IYUV 表示使用 YUV420 pixformat = SDL_PIXELFORMAT_IYUV; // 创建纹理，用于存储视频数据 // pixformat 使用之前设置的像素格式 IYUV，access 纹理访问模式为流式访问（适合频繁更新纹理数据） // w h 纹理宽度和高度 SDL_Texture *sdlTexture = SDL_CreateTexture(sdlRenderer, pixformat, SDL_TEXTUREACCESS_STREAMING, pixel_w, pixel_h); FILE *fp = NULL; fp = fopen(\u0026#34;../video/test_yuv420p_320x180.yuv\u0026#34;, \u0026#34;rb+\u0026#34;); if (fp == NULL) { printf(\u0026#34;cannot open this file\\n\u0026#34;); return -1; } SDL_Rect sdlRect; while (1) { // 从文件中读取一帧 YUV 数据到 buffer 中 if (fread(buffer, 1, pixel_w * pixel_h * bpp / 8, fp) != pixel_w * pixel_h * bpp / 8) { // 重新定位文件指针实现循环播放 fseek(fp, 0, SEEK_SET); fread(buffer, 1, pixel_w * pixel_h * bpp / 8, fp); } // 更新纹理中的数据，将 buffer 中的内容传递给纹理 // pitch 每行像素占用的字节数 SDL_UpdateTexture(sdlTexture, NULL, buffer, pixel_w); // 设置渲染区域 // 这表示这个矩形从屏幕的左上角(0, 0)开始，宽度和高度与屏幕相同，即覆盖整个屏幕 sdlRect.x = 10; sdlRect.y = 10; sdlRect.w = screen_w - 20; sdlRect.h = screen_h - 20; // 清楚渲染器 SDL_RenderClear(sdlRenderer); // 复制纹理到渲染器 SDL_RenderCopy(sdlRenderer, sdlTexture, NULL, \u0026amp;sdlRect); // 呈现渲染结果 // 将渲染器中的后缓冲区内容呈现到前缓冲区，即更新屏幕显示内容 SDL_RenderPresent(sdlRenderer); // 延迟以控制帧率 SDL_Delay(40); } SDL_Quit(); return 0; } 这里讲一下循环中读取数据到 buffer\n1 if (fread(buffer, 1, pixel_w * pixel_h * bpp / 8, fp) != pixel_w 第二个参数是每个元素的字节数，第三个参数是要读取的元素数量\n成功读取的话是返回读取的元素数量\n元素数量是视频宽度 * 视频高度 * 每像素占用的位数（bpp） bpp （Bits Per Pixel）的计算如下：\nY（亮度）平面：每个像素占8位。 U（色度）平面：每个像素占8位，但水平和垂直方向各下采样一倍，因此每个宏像素的 U 和 V 各占4位。 V（色度）平面：同上。 所以总共有：\nY 平面：width × height × 8 位 U 平面：(width/2) × (height/2) × 8 位 V 平面：(width/2) × (height/2) × 8 位 总位数为：\nwidth × height × 8 + (width/2) × (height/2) × 8 × 2 = width × height × (8 + 2 + 2) = width × height × 12 位\n因此，每个像素平均占用12位。\nCMakeLists.txt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 指定 CMake 的最低版本要求 cmake_minimum_required(VERSION 3.10) # 设置项目名称和版本 project(MyProject VERSION 1.0) # 设置 C++ 标准 set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_BUILD_TYPE Debug) # 依赖 compile_commands.json 文件来理解项目的编译环境 set(CMAKE_EXPORT_COMPILE_COMMANDS ON) # 添加头文件路径 include_directories(${PROJECT_SOURCE_DIR}/include) # 添加库文件路径 link_directories(${PROJECT_SOURCE_DIR}/lib) # 添加可执行文件 add_executable(main src/videoPlayer.cpp) # 链接 FFmpeg 库 target_link_libraries(main avcodec avformat avutil) # 链接 SDL2 库· target_link_libraries(main SDL2 SDL2main) ","date":"2025-02-24T00:00:00Z","image":"https://serennan.github.io/post/leixiaohua-note-2/cover.jpg","permalink":"https://serennan.github.io/post/leixiaohua-note-2/","title":"【雷霄骅课程笔记】2 SDL 视频播放器"},{"content":"视频解码器 视频链接 FFmpeg 介绍 FFmpeg 库 FFmpeg 一共包含 8 个库：\navcodec: 编解码（最重要的库）* avformat: 封装格式处理 * avfilter: 滤镜特效处理 avdevice: 各种设备的输入输出 avutil: 工具库（大部分库都需要这个库的支持）* postproc: 后加工 swresample: 音频采样数据格式转换 swscale: 视频像素数据格式转换 * 其中 * 表示本次课程中会涉及到的库\nFFmpeg 解码流程 流程图 函数介绍 函数名 功能描述 avformat_open_input 打开输入文件并创建 AVFormatContext avformat_find_stream_info 获取流信息 avcodec_find_decoder 查找解码器 avcodec_alloc_context3 分配解码器上下文 avcodec_parameters_to_context 复制编解码器参数 avcodec_open2 打开解码器 av_read_frame 读取数据包 avcodec_send_packet 发送数据包到解码器 avcodec_receive_frame 接收解码后的帧 sws_scale 像素格式转换 fwrite 写入转换后的帧数据 av_packet_unref 释放数据包 avcodec_free_context 释放解码器上下文 avformat_close_input 关闭输入流 FFmpeg 解码的数据结构 AV 表示 Audio Video\nAVFormatContext: 用于处理封装格式的上下文，包含视频最外层的信息\nAVInputFormat: 输入格式\nAVStream: 是一个数组，包含多个流，但是一般就包含视频流和音频流，第 0 个是视频流，第 1 个是音频流\nAVCodecContext: 编解码器上下文\nAVCodec: 编解码器，指明编码器的类型（h.264之类的）\nAVPacket: 压缩编码后的数据包 AVFrame: 解码后的数据包\nAVPacket 解码完为 AVFrame\nAVFormatContext 用于处理封装格式的上下文，包含视频最外层的信息\niformat: 输入视频的 AVInputFormat nb_streams: 输入视频的 AVStream 个数 streams: 输入视频的 AVStream 数组 duration: 输入视频的时长（以微秒为单位） bit_rate: 输入视频的码率 AVInputFormat 输入格式\nname: 输入视频的格式名称 long_name: 输入视频格式的长名称 extensions: 输入视频格式的扩展名 id: 输入视频格式的 ID 一些封装格式处理的接口函数 AVStream 是一个数组，包含多个流，但是一般就包含视频流和音频流，第 0 个是视频流，第 1 个是音频流\nid: 输入视频流的 ID codecpar: 输入视频流的 AVCodecContext time_base: 输入视频流的时间基 r_frame_rate: 输入视频流的帧率 time_base 是一个分数，表示时间基，用于将时间戳转换为实际时间。 r_frame_rate 是一个分数，表示帧率，用于计算帧间隔时间。\nAVCodecContext 编解码器上下文\ncodec：编解码器的 AVCodec width, height: 图像的宽高 pix_fmt: 图像的像素格式 sample_rate: 音频的采样率 channels: 音频的声道数 sample_fmt: 音频的采样格式 AVCodec 编解码器，指明编码器的类型（h.264之类的）\nname: 编解码器的名称 long_name: 编解码器的全称 type: 编解码器的类型（视频、音频等） id: 编解码器的 ID 一些编解码的接口函数 AVPacket 压缩编码后的数据包，理解成装 h264 数据的盒子\npts: 显示时间戳 dts: 解码时间戳 data: 压缩编码的数据 size: 数据的大小 stream_index: 所属的 AVStream （音频流还是视频流） AVFrame 解码后的数据包，理解成装 yuv 数据的盒子\ndata: 解码后的图像数据（音频采样数据） linesize: 对视频来说是图像中的一行像素的大小；对音频来说是整个音频帧的大小 width, height: 视频帧的宽和高 key_frame: 是否是关键帧 pict_type: 帧类型（I, B, P 帧） 补充小知识 解码后的数据为什么要经过 sws_scale 转换？ 解码后 YUV 数据格式的视频像素数据保存在 AVFrame 的 data[0]，data[1]，data[2]，但是这些像素值并不是连续存储的，每行有效像素之后存储的是无效像素。 以亮度 Y 数据为例，data[0] 中一共包含了 linesize[0] * height 个数据。但是出于优化等方面考虑，linesize[0] 可能大于 width 。因此需要使用 sws_scale 进行转换。\n转换后去除了无效数据，width 和 linesize[0] 就相等了。\n代码运行 雷神给的这些代码，在资源释放上有些问题（资源的释放都集中在最后，如果程序提前终止，那就导致资源没有释放），但这里先不考虑这些。\n代码 头文件 lib 和库文件 include 的配置在前面博客说到，可以复制到这个项目中（上一个博客我讲的是放在 usr/local/ffmpeg ） 这里代码和雷神视频中的代码略有不同，修改了很多：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 #include \u0026lt;stdio.h\u0026gt; #define __STDC_CONSTANT_MACROS #ifdef _WIN32 // Windows extern \u0026#34;C\u0026#34; { #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; #include \u0026#34;libavutil/imgutils.h\u0026#34; #include \u0026#34;libswscale/swscale.h\u0026#34; }; #else // Linux... #ifdef __cplusplus extern \u0026#34;C\u0026#34; { #endif #include \u0026lt;libavcodec/avcodec.h\u0026gt; #include \u0026lt;libavformat/avformat.h\u0026gt; #include \u0026lt;libavutil/imgutils.h\u0026gt; #include \u0026lt;libswscale/swscale.h\u0026gt; #ifdef __cplusplus }; #endif #endif int main(int argc, char *argv[]) { AVFormatContext *pFormatCtx = NULL; int videoindex = -1; AVCodecContext *pCodecCtx = NULL; const AVCodec *pCodec = NULL; AVFrame *pFrame = NULL, *pFrameYUV = NULL; unsigned char *out_buffer = NULL; AVPacket *packet = NULL; int ret = 0; struct SwsContext *img_convert_ctx = NULL; char filepath[] = \u0026#34;../video/input.mkv\u0026#34;; FILE *fp_yuv = fopen(\u0026#34;output.yuv\u0026#34;, \u0026#34;wb+\u0026#34;); // 初始化FFmpeg库 avformat_network_init(); // 打开输入文件 if (avformat_open_input(\u0026amp;pFormatCtx, filepath, NULL, NULL) != 0) { printf(\u0026#34;Couldn\u0026#39;t open input stream.\\n\u0026#34;); return -1; } // 获取流信息 if (avformat_find_stream_info(pFormatCtx, NULL) \u0026lt; 0) { printf(\u0026#34;Couldn\u0026#39;t find stream information.\\n\u0026#34;); return -1; } printf(\u0026#34;时长：%ld\\n\u0026#34;, pFormatCtx-\u0026gt;duration); // 查找视频流 for (int i = 0; i \u0026lt; pFormatCtx-\u0026gt;nb_streams; i++) { if (pFormatCtx-\u0026gt;streams[i]-\u0026gt;codecpar-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO) { videoindex = i; break; } } if (videoindex == -1) { printf(\u0026#34;Didn\u0026#39;t find a video stream.\\n\u0026#34;); return -1; } // 获取解码器 pCodec = avcodec_find_decoder(pFormatCtx-\u0026gt;streams[videoindex]-\u0026gt;codecpar-\u0026gt;codec_id); if (pCodec == NULL) { printf(\u0026#34;Codec not found.\\n\u0026#34;); return -1; } // 创建解码器上下文 pCodecCtx = avcodec_alloc_context3(pCodec); if (!pCodecCtx) { printf(\u0026#34;Could not allocate video codec context\\n\u0026#34;); return -1; } // 复制流参数到解码器上下文 if (avcodec_parameters_to_context(pCodecCtx, pFormatCtx-\u0026gt;streams[videoindex]-\u0026gt;codecpar) \u0026lt; 0) { printf(\u0026#34;Could not copy codec parameters to context\\n\u0026#34;); return -1; } // 打开解码器 if (avcodec_open2(pCodecCtx, pCodec, NULL) \u0026lt; 0) { printf(\u0026#34;Could not open codec.\\n\u0026#34;); return -1; } pFrame = av_frame_alloc(); pFrameYUV = av_frame_alloc(); out_buffer = (unsigned char *)av_malloc( av_image_get_buffer_size(AV_PIX_FMT_YUV420P, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, 1)); av_image_fill_arrays(pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize, out_buffer, AV_PIX_FMT_YUV420P, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, 1); packet = av_packet_alloc(); // 输出文件信息 printf(\u0026#34;--------------- File Information ----------------\\n\u0026#34;); av_dump_format(pFormatCtx, 0, filepath, 0); printf(\u0026#34;-------------------------------------------------\\n\u0026#34;); img_convert_ctx = sws_getContext(pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, pCodecCtx-\u0026gt;pix_fmt, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, AV_PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL); while (av_read_frame(pFormatCtx, packet) \u0026gt;= 0) { if (packet-\u0026gt;stream_index == videoindex) { ret = avcodec_send_packet(pCodecCtx, packet); if (ret \u0026lt; 0) { printf(\u0026#34;Error sending a packet for decoding\\n\u0026#34;); return -1; } while (ret \u0026gt;= 0) { ret = avcodec_receive_frame(pCodecCtx, pFrame); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break; else if (ret \u0026lt; 0) { printf(\u0026#34;Error during decoding\\n\u0026#34;); return -1; } sws_scale(img_convert_ctx, (const unsigned char *const *)pFrame-\u0026gt;data, pFrame-\u0026gt;linesize, 0, pCodecCtx-\u0026gt;height, pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize); int y_size = pCodecCtx-\u0026gt;width * pCodecCtx-\u0026gt;height; // U V 是分量，宽高各压缩一半，所以大小是 Y 的 1/4 fwrite(pFrameYUV-\u0026gt;data[0], 1, y_size, fp_yuv); // Y fwrite(pFrameYUV-\u0026gt;data[1], 1, y_size / 4, fp_yuv); // U fwrite(pFrameYUV-\u0026gt;data[2], 1, y_size / 4, fp_yuv); // V printf(\u0026#34;Succeed to decode 1 frame!\\n\u0026#34;); } } av_packet_unref(packet); } // 刷新解码器 avcodec_send_packet(pCodecCtx, NULL); while (ret \u0026gt;= 0) { ret = avcodec_receive_frame(pCodecCtx, pFrame); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break; else if (ret \u0026lt; 0) { printf(\u0026#34;Error during decoding\\n\u0026#34;); return -1; } sws_scale(img_convert_ctx, (const unsigned char *const *)pFrame-\u0026gt;data, pFrame-\u0026gt;linesize, 0, pCodecCtx-\u0026gt;height, pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize); int y_size = pCodecCtx-\u0026gt;width * pCodecCtx-\u0026gt;height; fwrite(pFrameYUV-\u0026gt;data[0], 1, y_size, fp_yuv); // Y fwrite(pFrameYUV-\u0026gt;data[1], 1, y_size / 4, fp_yuv); // U fwrite(pFrameYUV-\u0026gt;data[2], 1, y_size / 4, fp_yuv); // V printf(\u0026#34;Flush Decoder: Succeed to decode 1 frame!\\n\u0026#34;); } sws_freeContext(img_convert_ctx); fclose(fp_yuv); av_frame_free(\u0026amp;pFrameYUV); av_frame_free(\u0026amp;pFrame); av_packet_free(\u0026amp;packet); avcodec_free_context(\u0026amp;pCodecCtx); avformat_close_input(\u0026amp;pFormatCtx); return 0; } CMakeLists.txt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 cmake_minimum_required(VERSION 3.10) project(MyProject VERSION 1.0) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_BUILD_TYPE DEBUG) set(CMAKE_EXPORT_COMPILE_COMMANDS ON) # 添加头文件路径 include_directories(${PROJECT_SOURCE_DIR}/include) # 添加库文件路径 link_directories(${PROJECT_SOURCE_DIR}/lib) # 添加可执行文件 add_executable(main src/decoder.cpp) # 链接 FFmpeg 库 target_link_libraries(main avcodec avformat avutil swscale ) 手动编译一遍：\n1 2 3 4 5 mkdir build cd build cmake .. make ./main 如果成功输出，则说明配置成功\n没成功的话要注意看一下源码的路径和播放视频的路径是否正确\n我这里源码放在 src/decoder.cpp，播放视频放在video/input.mkv\n调试 在左侧工具栏找到运行和调试工具\n点击创建 launch.json 文件，选择C++(GDB/LLDB)\n在launch.json文件中添加以下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 { \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;(gdb) Launch\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${workspaceFolder}/build/main\u0026#34;, \u0026#34;args\u0026#34;: [], \u0026#34;stopAtEntry\u0026#34;: false, \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceFolder}/build\u0026#34;, \u0026#34;externalConsole\u0026#34;: false, \u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;, \u0026#34;setupCommands\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Enable pretty-printing for gdb\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;-enable-pretty-printing\u0026#34;, \u0026#34;ignoreFailures\u0026#34;: true } ], \u0026#34;preLaunchTask\u0026#34;: \u0026#34;cmake-build-debug\u0026#34; } ] } 按下 f5 即可调试\n这里可能会遇到两个问题：\n在源码位置按下 f5 后，会提示找不到找不到你链接的库\n这里可能原因是没执行你的 CMakeLists.txt 文件，换成点击左侧工具栏的启动按键就行\n提示找不到输入文件，可以试试去掉 json 中 cwd 字段的 /build：\n1 \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceFolder}\u0026#34; 后续博客就不讲调试的文件书写了，基本都差不多\n练习 获取解码前的 h264 文件 注意这里只获取 MPEG-TS ，AVI 格式的文件，如果是别的文件，无法直接获取\n这样重新编码后，就可以获取到解码前的 h264 文件了。\n代码分析 打开文件 1 FILE *fp_h264 = fopen(\u0026#34;test264.h264\u0026#34;, \u0026#34;wb+\u0026#34;); 循环从媒体文件中读取一帧数据，并将其存储在 AVPacket 结构体中。 1 while (av_read_frame(pFormatCtx, packet) \u0026gt;= 0) 这个函数会读取下一个可用的数据包，无论是音频、视频还是其他类型的流 判断是否为视频帧 1 if (packet-\u0026gt;stream_index == videoindex) 获取数据 1 fwrite(packet-\u0026gt;data, 1, packet-\u0026gt;size, fp_h264); 关闭文件，释放资源 注意事项 输入文件一定要是 ts 或 avi 格式！\n因为 mp4 和 flv 格式需要解析 moov 结构，而 ts 和 avi 格式可以直接解析 h264 数据\n我就是一开始没注意，导致浪费了很多时间\n获取完数据记得释放资源和关闭文件\n获取解码后的 yuv 文件 打开文件 1 FILE *fp_yuv = fopen(\u0026#34;testyuv.yuv\u0026#34;, \u0026#34;wb+\u0026#34;); 循环从媒体文件中读取一帧数据，并将其存储在 AVPacket 结构体中。 1 while (av_read_frame(pFormatCtx, packet) \u0026gt;= 0) 判断当前帧是否为视频流 1 if (packet-\u0026gt;stream_index == video_index) 解码一帧视频数据 1 avcodec_send_packet(pCodecCtx, packet); 这个函数会将 AVPacket 中的压缩数据发送给解码器进行解码 接收解码后的数据 1 2 ret == avcodec_receive_frame(pCodecCtx, pFrame); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break; 这个函数会从解码器中接收解码后的原始数据，并存储在 AVFrame 结构体中 AVERROR(EAGAIN) 是FFmpeg库中的一个错误码，表示当前没有足够的数据可供解码，需要等待更多数据到来才能继续解码。这种情况通常发生在数据流尚未准备好或缓冲区为空时 AVERROR_EOF 表示已经到达数据流的末尾（End of File），没有更多的数据可供解码 处理解码后的数据 1 2 3 4 5 6 7 img_convert_ctx = sws_getContext(pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, pCodecCtx-\u0026gt;pix_fmt, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, AV_PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL); sws_scale(img_convert_ctx, (const unsigned char *const *)pFrame-\u0026gt;data, pFrame-\u0026gt;linesize, 0, pCodecCtx-\u0026gt;height, pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize); 前面补充知识有提到，解码后的数据格式的视频像素值不是连续存储，而是按行存储的，会多出一些无效像素，导致像素的 width 和 linesize 不一致，要用 sws_scale 函数进行转换\nsws_getContext 函数\n用途：创建图像转换上下文 (SwsContext) 参数说明： pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height：原始视频帧的宽度和高度 pCodecCtx-\u0026gt;pix_fmt：原始视频帧的像素格式 AV_PIX_FMT_YUV420P：目标像素格式，此处为 YUV420P SWS_BICUBIC：缩放算法，使用双三次插值 sws_scale 函数\n用途：执行实际的图像格式转换 参数说明： img_convert_ctx：之前创建的图像转换上下文 (const unsigned char *const *)pFrame-\u0026gt;data：原始视频帧的数据 pFrame-\u0026gt;linesize：原始视频帧的每行字节数 0：从原始帧的第 0 行开始转换 pCodecCtx-\u0026gt;height：原始视频帧的高度 pFrameYUV-\u0026gt;data：目标帧的数据缓冲区，用于存储转换后的 YUV420P 数据 pFrameYUV-\u0026gt;linesize：目标帧的每行字节数 保存 YUV 数据到文件 1 2 3 4 5 int y_size = pCodecCtx-\u0026gt;width * pCodecCtx-\u0026gt;height; fwrite(pFrameYUV-\u0026gt;data[0], 1, y_size, fp_yuv); // Y // U V 是分量，宽高各压缩一半，所以大小是 Y 的 1/4 fwrite(pFrameYUV-\u0026gt;data[1], 1, y_size / 4, fp_yuv); // U fwrite(pFrameYUV-\u0026gt;data[2], 1, y_size / 4, fp_yuv); // V 关闭文件，释放资源 完整代码 代码优化了一些，也把一些要求输出的信息写在里面了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 #include \u0026lt;stdio.h\u0026gt; #define __STDC_CONSTANT_MACROS #ifdef __cplusplus extern \u0026#34;C\u0026#34; { #endif #include \u0026lt;libavcodec/avcodec.h\u0026gt; #include \u0026lt;libavcodec/bsf.h\u0026gt; #include \u0026lt;libavformat/avformat.h\u0026gt; #include \u0026lt;libavutil/imgutils.h\u0026gt; #include \u0026lt;libswscale/swscale.h\u0026gt; #ifdef __cplusplus } #endif int main(int argc, char *argv[]) { AVFormatContext *pFormatCtx = NULL; int videoindex = -1; AVCodecContext *pCodecCtx = NULL; const AVCodec *pCodec = NULL; AVFrame *pFrame = NULL, *pFrameYUV = NULL; unsigned char *out_buffer = NULL; AVPacket *packet = NULL; int ret = 0; struct SwsContext *img_convert_ctx = NULL; char filepath[] = \u0026#34;../video/Titanic.ts\u0026#34;; // 初始化FFmpeg库 avformat_network_init(); // 打开输入文件 if (avformat_open_input(\u0026amp;pFormatCtx, filepath, NULL, NULL) != 0) { printf(\u0026#34;Couldn\u0026#39;t open input stream.\\n\u0026#34;); return -1; } // 获取流信息 if (avformat_find_stream_info(pFormatCtx, NULL) \u0026lt; 0) { printf(\u0026#34;Couldn\u0026#39;t find stream information.\\n\u0026#34;); return -1; } // 输出封装格式参数 FILE *fp = fopen(\u0026#34;output.txt\u0026#34;, \u0026#34;wb+\u0026#34;); fprintf(fp, \u0026#34;封装格式参数：\\n\u0026#34;); fprintf(fp, \u0026#34; 封装格式：%s\\n 比特率：%ld\\n 时长：%ld\\n\u0026#34;, pFormatCtx-\u0026gt;iformat-\u0026gt;name, pFormatCtx-\u0026gt;bit_rate, pFormatCtx-\u0026gt;duration); // 查找视频流 for (int i = 0; i \u0026lt; pFormatCtx-\u0026gt;nb_streams; i++) { if (pFormatCtx-\u0026gt;streams[i]-\u0026gt;codecpar-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO) { videoindex = i; break; } } if (videoindex == -1) { printf(\u0026#34;Didn\u0026#39;t find a video stream.\\n\u0026#34;); return -1; } // 输出视频编码参数 fprintf(fp, \u0026#34;视频编码参数：\\n\u0026#34;); fprintf(fp,\u0026#34; 编码方式：%s\\n 宽*高：%d * %d\\n\u0026#34;, avcodec_get_name(pFormatCtx-\u0026gt;streams[videoindex]-\u0026gt;codecpar-\u0026gt;codec_id),pFormatCtx-\u0026gt;streams[videoindex]-\u0026gt;codecpar-\u0026gt;width,pFormatCtx-\u0026gt;streams[videoindex]-\u0026gt;codecpar-\u0026gt;height); // 获取解码器 pCodec = avcodec_find_decoder(pFormatCtx-\u0026gt;streams[videoindex]-\u0026gt;codecpar-\u0026gt;codec_id); if (pCodec == NULL) { printf(\u0026#34;Codec not found.\\n\u0026#34;); return -1; } // 创建解码器上下文 pCodecCtx = avcodec_alloc_context3(pCodec); if (!pCodecCtx) { printf(\u0026#34;Could not allocate video codec context\\n\u0026#34;); return -1; } // 复制流参数到解码器上下文 if (avcodec_parameters_to_context(pCodecCtx, pFormatCtx-\u0026gt;streams[videoindex]-\u0026gt;codecpar) \u0026lt; 0) { printf(\u0026#34;Could not copy codec parameters to context\\n\u0026#34;); return -1; } // 打开解码器 if (avcodec_open2(pCodecCtx, pCodec, NULL) \u0026lt; 0) { printf(\u0026#34;Could not open codec.\\n\u0026#34;); return -1; } pFrame = av_frame_alloc(); pFrameYUV = av_frame_alloc(); out_buffer = (unsigned char *)av_malloc( av_image_get_buffer_size(AV_PIX_FMT_YUV420P, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, 1)); av_image_fill_arrays(pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize, out_buffer, AV_PIX_FMT_YUV420P, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, 1); packet = av_packet_alloc(); // 输出文件信息 printf(\u0026#34;--------------- File Information ----------------\\n\u0026#34;); av_dump_format(pFormatCtx, 0, filepath, 0); printf(\u0026#34;-------------------------------------------------\\n\u0026#34;); img_convert_ctx = sws_getContext(pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, pCodecCtx-\u0026gt;pix_fmt, pCodecCtx-\u0026gt;width, pCodecCtx-\u0026gt;height, AV_PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL); FILE *fp_h264 = fopen(\u0026#34;1test264.h264\u0026#34;, \u0026#34;wb+\u0026#34;); FILE *fp_yuv = fopen(\u0026#34;1testyuv.yuv\u0026#34;, \u0026#34;wb+\u0026#34;); fprintf(fp, \u0026#34;--------每一个解码前视频帧大小和解码后帧类型：-------------\\n\u0026#34;); while (av_read_frame(pFormatCtx, packet) \u0026gt;= 0) { if (packet-\u0026gt;stream_index == videoindex) { // 获取解码前的 H.264 码流数据 fwrite(packet-\u0026gt;data, 1, packet-\u0026gt;size, fp_h264); // 获取解码前视频帧参数 fprintf(fp, \u0026#34;帧大小:%d\\n\u0026#34;,packet-\u0026gt;size); ret = avcodec_send_packet(pCodecCtx, packet); if (ret \u0026lt; 0) { printf(\u0026#34;Error sending a packet for decoding\\n\u0026#34;); return -1; } while (ret \u0026gt;= 0) { ret = avcodec_receive_frame(pCodecCtx, pFrame); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break; else if (ret \u0026lt; 0) { printf(\u0026#34;Error during decoding\\n\u0026#34;); return -1; } sws_scale(img_convert_ctx, (const unsigned char *const *)pFrame-\u0026gt;data, pFrame-\u0026gt;linesize, 0, pCodecCtx-\u0026gt;height, pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize); int y_size = pCodecCtx-\u0026gt;width * pCodecCtx-\u0026gt;height; fwrite(pFrameYUV-\u0026gt;data[0], 1, y_size, fp_yuv); // Y // U V 是分量，所以大小是 Y 的 1/4 fwrite(pFrameYUV-\u0026gt;data[1], 1, y_size / 4, fp_yuv); // U fwrite(pFrameYUV-\u0026gt;data[2], 1, y_size / 4, fp_yuv); // V printf(\u0026#34;Succeed to decode 1 frame!\\n\u0026#34;); if (pFrame-\u0026gt;pict_type == AV_PICTURE_TYPE_I) { fprintf(fp, \u0026#34;帧类型：I帧\\n\u0026#34;); } else if (pFrame-\u0026gt;pict_type == AV_PICTURE_TYPE_P) { fprintf(fp, \u0026#34;帧类型：P帧\\n\u0026#34;); } else if (pFrame-\u0026gt;pict_type == AV_PICTURE_TYPE_B) { fprintf(fp, \u0026#34;帧类型：B帧\\n\u0026#34;); } else { fprintf(fp, \u0026#34;帧类型：未知帧\\n\u0026#34;); } } } av_packet_unref(packet); } fclose(fp); fclose(fp_h264); fclose(fp_yuv); // 刷新解码器 avcodec_send_packet(pCodecCtx, NULL); while (ret \u0026gt;= 0) { ret = avcodec_receive_frame(pCodecCtx, pFrame); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) break; else if (ret \u0026lt; 0) { printf(\u0026#34;Error during decoding\\n\u0026#34;); return -1; } sws_scale(img_convert_ctx, (const unsigned char *const *)pFrame-\u0026gt;data, pFrame-\u0026gt;linesize, 0, pCodecCtx-\u0026gt;height, pFrameYUV-\u0026gt;data, pFrameYUV-\u0026gt;linesize); int y_size = pCodecCtx-\u0026gt;width * pCodecCtx-\u0026gt;height; fwrite(pFrameYUV-\u0026gt;data[0], 1, y_size, fp_yuv); // Y fwrite(pFrameYUV-\u0026gt;data[1], 1, y_size / 4, fp_yuv); // U fwrite(pFrameYUV-\u0026gt;data[2], 1, y_size / 4, fp_yuv); // V printf(\u0026#34;Flush Decoder: Succeed to decode 1 frame!\\n\u0026#34;); } sws_freeContext(img_convert_ctx); // 这里的释放顺序要注意，先释放AVFrame，再释放AVPacket，最后释放AVCodecContext和AVFormatContext av_frame_free(\u0026amp;pFrameYUV); av_frame_free(\u0026amp;pFrame); av_packet_free(\u0026amp;packet); avcodec_free_context(\u0026amp;pCodecCtx); avformat_close_input(\u0026amp;pFormatCtx); return 0; } 资源释放问题后面会再出博客写，因为涉及到各种细节\n","date":"2025-02-18T00:00:00Z","image":"https://serennan.github.io/post/leixiaohua-note-1/cover.jpg","permalink":"https://serennan.github.io/post/leixiaohua-note-1/","title":"【雷霄骅课程笔记】1 FFmpeg 视频解码器"},{"content":"图片加载问题 问题描述 有时会遇到在本地图片能成功加载，但部署到服务器上却不能成功显示。\n我在弄代码折叠图片时遇到了这个问题\n在 html 文件上加载图片的代码语句是\n1 img.src = \u0026#39;{{ (resources.Get \u0026#34;img/codeMore.png\u0026#34;).Permalink }}\u0026#39;; 在本地成功加载\n但是到发布到服务端就不行了\n根本问题是服务端的图片加载路径出错\n按 f12 调出开发者工具查看（或者右键对应位置，点击检查，能快速跳转），会发现图片加载路径不是图片相对路径\n解决方案 将加载图片的代码语句改成\n1 img.src = \u0026#39;{{ (resources.Get \u0026#34;img/codeMore.png\u0026#34;).RelPermalink }}\u0026#39;; 把最后的 Permalink 改成 RelPermalink\n重新加载，会发现服务端正确显示\n重新用开发者工具检查加载路径\n正确显示图片相对位置\n","date":"2025-02-10T00:00:00Z","image":"https://serennan.github.io/post/hugo-problem/cover.jpg","permalink":"https://serennan.github.io/post/hugo-problem/","title":"【Hugo】常见问题"},{"content":"vscode 配置 FFmpeg 视频链接 这里的配置教程是另一处的，不是雷神的\n课程简介 雷神的课程主要使用 Visual Studio 进行演示，但由于我个人不太习惯使用 VS，因此我选择了在 WSL 环境下使用 VSCode 和 CMake 来进行学习和实践\nwindows 环境总是出现各种不必要的麻烦，而且其实 linux 环境对音视频开发者更友好\n配置过程些许复杂，但只要按照步骤来，不会有太大问题，有问题可以留言，我会尽力解答\n我使用的资料都是比较新的（2025年2月），所以博客的一些代码和流程什么的可能和雷神介绍的有些不同\nFFmpeg 配置 前提准备 安装好 Ubuntu 和 VSCode, 并且配置好 WSL 和 VSCode 的连接\n这里网上很多教程，就不多说了\n编译安装 创建安装目录：\n1 sudo mkdir -p /usr/local/ffmpeg 下载 FFmpeg 源码： 我这里都是用最新的 FFmpeg 源码\n点击链接：下载地址\n目前最新版是 7.1 ，而且我是 ubuntu 环境\n下载压缩包之后进行解压：（具体解压指令可以问问 ai ）\n1 tar -xv ffmpeg-7.1.tar.xz 解压完之后要进入目录：\n1 cd ffmpeg-7.1 然后进行配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ./configure \\ 0 (20.192s) \u0026lt; 14:23:34 --prefix=\u0026#39;/usr/local/ffmpeg\u0026#39; \\ --enable-gpl \\ --enable-nonfree \\ --enable-ffplay \\ --enable-libfdk-aac \\ --enable-libmp3lame \\ --enable-libx264 \\ --enable-libx265 \\ --enable-filter=delogo \\ --enable-debug \\ --disable-optimizations \\ --enable-libspeex \\ --enable-shared \\ --enable-pthreads \\ --enable-version3 \\ --enable-hardcoded-tables \\ --extra-cflags=\u0026#34;-I/usr/local/ffmpeg/include\u0026#34; \\ --extra-ldflags=\u0026#34;-L/usr/local/ffmpeg/lib\u0026#34; 这里可能会不断报错，显示缺各种库，那根据提示去安装对应库就行\n下载：\n1 2 3 4 sudo apt-get install libasound2-dev sudo apt-get install libpulse-dev sudo apt-get install libx11-dev sudo apt-get install xorg-dev 配置：\n1 ./configure --prefix=/usr/local/ffmpeg --enable-shared --enable-video-x11 --enable-x11-shared --enable-video-x11-vm ffplay 一直无法播放视频的话（因为我是用的wsl2），尝试在终端配置文件加上 SDL_RENDER_DRIVER=software\n在 fish 终端配置文件加\n1 set -x SDL_RENDER_DRIVER software 具体怎么加可以问问 ai\nCMake配置 安装 CMake 安装插件 CMake Tools\n书写 CMakeLists.txt 在 CMakeLists.txt 下写入以下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 指定 CMake 的最低版本要求 cmake_minimum_required(VERSION 3.10) # 设置项目名称和版本 project(MyProject VERSION 1.0) # 设置 C++ 标准 set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED ON) # 依赖 compile_commands.json 文件来理解项目的编译环境 set(CMAKE_EXPORT_COMPILE_COMMANDS ON) # 设置 FFmpeg 库的路径 set(FFmpeg_DIR /usr/local/ffmpeg) # 添加项目中的头文件目录 include_directories(${FFmpeg_DIR}/include) # 添加库文件目录 link_directories(${FFmpeg_DIR}/lib) # 添加可执行文件（就是源码的位置） add_executable(main src/testffmpeg.cpp) # 链接 FFmpeg 库 target_link_libraries(main avcodec avformat avutil) 测试代码 1 2 3 4 5 6 7 8 9 10 11 12 #define __STDC_CONSTANT_MACROS extern \u0026#34;C\u0026#34; { #include \u0026#34;libavcodec/avcodec.h\u0026#34; }; int main(int argc, char *argv[]) { printf(\u0026#34;%s\u0026#34;, avcodec_configuration()); return 0; } 编译 输入指令\n1 2 3 4 cd build cmake .. make ./main 如果成功输出，说明配置成功\n常见问题 解释器 如果成功输出了发现源文件仍然显示找不到头文件，可能是没安装好解释器，我使用的是 clangd，linux 环境安装很简单，问一下 ai 就行\n安装完成之后，clangd 会依赖 compile_commands.json 文件来理解项目的编译环境\n","date":"2025-02-10T00:00:00Z","image":"https://serennan.github.io/post/leixiaohua-note-0/cover.jpg","permalink":"https://serennan.github.io/post/leixiaohua-note-0/","title":"【雷霄骅课程笔记】0 配置"},{"content":"哈希表 map map是 C++ 标准库中的一个关联容器，用于存储键值对，键是唯一的，且按键的升序排列。\nm[key] = value：将键 key 对应的值设置为 value。 m.insert({key, value})：将键值对 {key, value} 插入到 map 中。 m.erase(key)：从 map 中删除键为 key 的元素。 m.count(key)：返回 map 中键为 key 的元素个数。 m.find(key)：返回指向 map 中键为 key 的元素的迭代器，如果 key 不存在则返回 m.end()。 m.lower_bound(key)：返回指向 map 中第一个不小于 key 的元素的迭代器。 m.upper_bound(key)：返回指向 map 中第一个大于 key 的元素的迭代器。 unordered_map unordered_map 是 C++ 标准库中的一个关联容器，用于存储键值对，键是唯一的。\numap[key] = value：将键 key 对应的值设置为 value。 umap.insert({key, value})：将键值对 {key, value} 插入到 unordered_map 中。 umap.erase(key)：从 unordered_map 中删除键为 key 的元素。 umap.count(key)：返回 unordered_map 中键为 key 的元素个数。 umap.find(key)：返回指向 unordered_map 中键为 key 的元素的迭代器，如果 key 不存在则返回 umap.end()。 umap.size()：返回 unordered_map 中元素的个数。 set set 是 C++ 标准库中的一个关联容器，用于存储唯一的元素。\n1 set\u0026lt;int\u0026gt; nums; nums.insert(x)：将元素 x 插入到集合 nums 中。 nums.erase(x)：从集合 nums 中删除元素 x。 nums.count(x)：返回集合 nums 中元素 x 的个数。 nums.find(x)：返回指向集合 nums 中元素 x 的迭代器，如果 x 不存在则返回 nums.end()。 nums.lower_bound(x)：返回指向集合 nums 中第一个不小于 x 的元素的迭代器。 emplace_back emplace_back 是 C++ 标准库中 std::vector、std::deque、std::list 等容器的一个成员函数，用于在容器的末尾直接构造一个元素，而不是先创建一个临时对象再插入。这样可以避免不必要的拷贝或移动操作，提高效率。\nqueue queue 是 C++ 标准库中的一个容器适配器，用于实现先进先出（FIFO）的队列。\n1 queue\u0026lt;int\u0026gt; q; q.push(x)：将元素 x 入队。 q.pop()：将队首元素出队。 q.front()：返回队首元素的引用。 q.back()：返回队尾元素的引用。 q.empty()：检查队列是否为空，返回布尔值。 q.size()：返回队列中元素的个数。 priority_queue priority_queue 是 C++ 标准库中的一个容器适配器，用于实现优先队列。\n1 priority_queue\u0026lt;int\u0026gt; pq; pq.push(x)：将元素 x 入队，并按优先级排序。 pq.pop()：将优先级最高的元素出队。 pq.top()：返回优先级最高的元素的引用。 pq.empty()：检查优先队列是否为空，返回布尔值。 pq.size()：返回优先队列中元素的个数。 stack stack 是 C++ 标准库中的一个容器适配器，用于实现后进先出（LIFO）的栈。\n1 stack\u0026lt;int\u0026gt; s; s.push(x)：将元素 x 压入栈顶。 s.pop()：弹出栈顶元素。 s.top()：返回栈顶元素的引用。 s.empty()：检查栈是否为空，返回布尔值。 s.size()：返回栈中元素的个数。 ","date":"2025-01-10T00:00:00Z","image":"https://serennan.github.io/post/leetcode-function/function.jpg","permalink":"https://serennan.github.io/post/leetcode-function/","title":"常用函数"},{"content":"前缀和 前缀和的定义： 给定数组 nums，我们可以定义前缀和数组 prefix_sum，使得 prefix_sum[i] = nums[0] + nums[1] + ... + nums[i-1]。 这样，对于任何子数组 [l, r]，其和可以通过以下公式计算：\n1 sum(l, r) = prefix_sum[r + 1] - prefix_sum[l] 典型题 437. 路径总和 III\n560. 和为 K 的子数组\n滑动窗口 滑动窗口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /* 滑动窗口算法框架 */ void slidingWindow(string s, string t) { unordered_map\u0026lt;char, int\u0026gt; need, window; for (char c : t) need[c]++; int left = 0, right = 0; int valid = 0; while (right \u0026lt; s.size()) { // c 是将移入窗口的字符 char c = s[right]; // 右移窗口 right++; // 进行窗口内数据的一系列更新 ... /*** debug 输出的位置 ***/ printf(\u0026#34;window: [%d, %d)\\n\u0026#34;, left, right); /********************/ // 判断左侧窗口是否要收缩 while (window needs shrink) { // d 是将移出窗口的字符 char d = s[left]; // 左移窗口 left++; // 进行窗口内数据的一系列更新 ... } } } 其中两处 \u0026hellip; 表示的更新窗口数据的地方。\n而且，这两个 \u0026hellip; 处的操作分别是右移和左移窗口更新操作，它们操作是完全对称的。\n套模板要思考下面的问题：\n1、当移动 right 扩大窗口，即加入字符时，应该更新哪些数据？\n2、什么条件下，窗口应该暂停扩大，开始移动 left 缩小窗口？\n3、当移动 left 缩小窗口，即移出字符时，应该更新哪些数据？\n4、我们要的结果应该在扩大窗口时还是缩小窗口时进行更新？\n典型题 3. 无重复字符的最长子串\n76. 最小覆盖子串\n递归 视频链接:递归\n如何编写递归函数 第一步：确定问题\n阶乘：求n的阶乘\n1 2 3 int factorial(int n) { } 斐波那契问题：求第n个斐波那契数\n1 2 3 int fibonacci(int n) { } 汉诺塔问题：将n个盘子从A移动到C\n1 2 3 void hanoi(int n, char A, char B, char C) { } 第二步：解决基准问题（边界条件）\n阶乘：当n为0或1时，阶乘为1\n1 2 3 4 5 int factorial(int n) { if (n == 1) { return 1; } } 斐波那契：当n小于等于2时，答案是1\n1 2 3 4 5 int fibonacci(int n) { if (n \u0026lt;= 2) { return 1; } } 汉诺塔：当n为1时，直接从A移动到C\n1 2 3 4 5 6 void hanoi(int n, char A, char B, char C) { if (n == 1) { cout \u0026lt;\u0026lt; \u0026#34;Move disk 1 from \u0026#34; \u0026lt;\u0026lt; A \u0026lt;\u0026lt; \u0026#34; to \u0026#34; \u0026lt;\u0026lt; C \u0026lt;\u0026lt; endl; return; } } 第三步：拆解问题\n阶乘：n的阶乘等于n乘以(n-1)的阶乘\n1 2 3 4 5 6 int factorial(int n) { if (n == 1) { return 1; } return n * factorial(n - 1); } 斐波那契：第n个斐波那契数等于第n-1和第n-2个斐波那契数之和\n1 2 3 4 5 6 int fibonacci(int n) { if (n \u0026lt;= 2) { return 1; } return fibonacci(n - 1) + fibonacci(n - 2); } 汉诺塔：将n-1个盘子从A移动到B，将第n个盘子从A移动到C，再将n-1个盘子从B移动到C\n1 2 3 4 5 6 7 8 9 void hanoi(int n, char A, char B, char C) { if (n == 1) { cout \u0026lt;\u0026lt; \u0026#34;Move disk 1 from \u0026#34; \u0026lt;\u0026lt; A \u0026lt;\u0026lt; \u0026#34; to \u0026#34; \u0026lt;\u0026lt; C \u0026lt;\u0026lt; endl; return; } hanoi(n - 1, A, C, B); cout \u0026lt;\u0026lt; \u0026#34;Move disk \u0026#34; \u0026lt;\u0026lt; n \u0026lt;\u0026lt; \u0026#34; from \u0026#34; \u0026lt;\u0026lt; A \u0026lt;\u0026lt; \u0026#34; to \u0026#34; \u0026lt;\u0026lt; C \u0026lt;\u0026lt; endl; hanoi(n - 1, B, A, C); } 思维小技巧 在编写函数时，可以当系统库中有一个同名函数，能实现你所需要的功能，直接调用即可。\n典型题 138. 随机链表的复制\n哈希表 更多是起到一个辅助\n典型题 1. 两数之和\n236. 二叉树的最近公共祖先\n","date":"2025-01-10T00:00:00Z","image":"https://serennan.github.io/post/algorithm/algorithm.jpg","permalink":"https://serennan.github.io/post/algorithm/","title":"算法思路"},{"content":"语音生成与感知模型 发音与感知模型 声门 声带之间的间隙称为声门。\n主要功能：产生激励。\n声道 声道指声门至嘴唇的所有发音器官，包括咽喉、口腔和鼻腔。\n主要功能：传输并调制声波。\n声道的形状变化由舌、软腭、唇、牙决定。\n语音生成动作 语音生成可分为两种功能：\n激励：由声门产生的基本声波。 调制：通过声道形状的变化改变声波的频率特性。 语音生成框图 声门 (激励) ➔ 声道 (调制) ➔ 嘴唇 (辐射语音)\n基音频率 由声带张开闭合的周期决定。\n男性：50-250Hz 女性：100-500Hz 浊音与清音 浊音：由声带振动产生，包括所有元音和部分辅音。 清音：不通过声带振动产生，包括另一部分辅音。 语音生成过程 空气从肺部排出形成气流。 冲击声带： 声带紧绷：形成准周期性脉冲空气流，产生浊音。 声带舒展：形成摩擦音或爆破音。 空气流经过声道调制后从口或鼻腔辐射，形成语音。 共振峰 声道是谐振腔，有许多谐振频率，称为共振峰。 共振峰是声道的重要声学特征。\n听觉掩蔽效应 人耳听觉频率范围：20Hz-20kHz。 语音感知强度范围：0-130dB声压级。 掩蔽效应：一个声音的听觉感受性受到同时存在的另一个声音的影响。 语音信号数字模型的组成 语音信号数字模型：激励模型，声道模型，辐射模型 声道模型：声管模型，共振峰模型 共振峰模型：分为级联型，并联型和混合型 数字语音处理 语音信号基本特性 语音信号频率范围：300-3400Hz。 常用采样率：8kHz。 语音预处理 预处理 包括：预加重，端点检测，加窗分帧\n预加重 目的：增强高频分辨率，减少口唇辐射影响。\n短时处理 加窗：窗长一般选取100-200ms。 窗宽较大：平滑作用明显，反映能量变化较小。 窗宽较小：反映细节快变，包络变化不明显。 短时平均能量 用途：\n区分清音与浊音。 区分有声与无声。 语音识别的辅助参数。 短时自相关函数 浊音：具有明显周期性。 清音：无周期性，类似噪声。 倒谱分析 实现：解卷（卷积关系变换为求和关系）\n将语音信号的声门激励信息与声道响应信息分离。 用于提取声道共振特征和基音周期。 倒谱：频谱(Spectrum)的前四个字母倒过来。 共振峰 语音的主要频率成分，携带声音的辨识属性 提取共振峰：共振峰的位置和转变过程 语音端点检测 端点检测法 指从包含语音的一段信息中确定出语音的起始点和结束点。\n双门限比较法 第一级判决： 根据短时能量选较高门限T1，粗判定语音段。 根据背景噪声平均能量确定较低门限T2，精确定位语音段。 第二级判决： 用短时平均过零率，进一步搜索语音段的起止点。 门限T3由背景噪声平均过零率确定。 语音特性与噪声 语音特性 语音是时变、非平稳的随机信号，同时具有短时平稳性。 语音分为清音与浊音。 语音信号可用统计分析描述。 噪声特性 加性噪声：直接叠加在语音信号上。 非加性噪声：需通过变换处理成加性噪声。 噪声分类 周期性噪声：如机械噪声，用功率谱与滤波去除。 冲激噪声（脉冲噪声）：通过幅度阈值检测并消除。 宽带噪声：难以去除，用白化处理或其他方法。 语音干扰噪声：如“鸡尾酒会效应”，通过语音增强算法处理。 语音增强算法分类 根据是否建立模型： 模型算法： 参数方法 统计方法 非模型算法 根据麦克风数量： 单通道语音增强算法 多通道语音增强算法 根据处理域： 时域 频域 巴克域 子空间域 小波域 谱减法优缺点 优点： 无需使用端点检测方法区分语音段和无声段。 算法简单，易于实现。 缺点： 频谱直接相减会导致增强后的语音产生“音乐噪声”。 适用的信噪比范围较窄。 在低信噪比时对语音可懂度损伤较大。 语音识别系统 系统组成 流程图： 预处理：包括预加重、端点检测。 特征提取：获取语音信号特征参数。 训练识别网络：建立模板和模型。 识别方法 基于声道模型与语音知识。 模式匹配方法：如VQ、DTW。 统计模型方法：如HMM。 人工神经网络方法：如深度学习。 语音识别过程 训练过程\n预处理：输入语音经过预处理。 特征提取：提取语音信号的特征。 模板建立：基于提取的特征建立语音模板。 识别过程\n特征比较：将输入语音特征与现有语音模板进行比较。 最优匹配：找出一系列最优匹配的模板。 结果输出：通过查表给出计算机的识别结果。 隐马尔可夫模型 (HMM) 是一个统计模型\n双重随机过程： 短时平稳段统计特征。 段间动态转变特性。 在语音识别的应用 语音识别的困难：对语音的发音速率和声学变化建立模型 HMM通过以下方式解决上述问题：\n状态转移概率：模拟发音速率的变化，反映大脑根据语法和言语需求调整音素参数的过程。 观察输出概率：模拟声学变化，通过依赖状态的输出概率来描述可观测的语音时变序列。 步骤： 信号预处理。 特征提取。 训练HMM。 测试集识别。 参数 N：模型的状态数目 M：观测符号数 A：状态转移概率分布 B：状态的观测符号概率分布 π：初始状态分布 题目 判断题 声门的主要功能是传输并调制声波。 答案：错误 解析： 声门的主要功能是产生激励，而传输并调制声波是声道的功能。 基音频率由声带张开闭合的周期决定，男性的基音频率范围通常为50-250Hz。 答案：正确 解析： 基音频率确实由声带振动周期决定，男性的基音频率范围通常为50-250Hz。 清音是通过声带振动产生的。 答案：错误 解析： 清音不通过声带振动产生，浊音才是通过声带振动产生的。 共振峰是声道的重要声学特征，反映了声道的谐振频率。 答案：正确 解析： 共振峰是声道的谐振频率，是语音的重要声学特征。 预加重的目的是增强低频分辨率。 答案：错误 解析： 预加重的目的是增强高频分辨率，减少口唇辐射的影响。 单选题 声道的形状变化主要由哪些器官决定？ A. 声带 B. 舌、软腭、唇、牙 C. 肺部 D. 鼻腔 答案：B 解析： 声道的形状变化由舌、软腭、唇、牙决定。 以下哪个频率范围是语音信号的常用频率范围？ A. 20Hz-20kHz B. 300-3400Hz C. 50-250Hz D. 100-500Hz 答案：B 解析： 语音信号的常用频率范围是300-3400Hz。 以下哪种噪声属于周期性噪声？ A. 冲激噪声 B. 宽带噪声 C. 机械噪声 D. 语音干扰噪声 答案：C 解析： 周期性噪声如机械噪声，可以通过功率谱与滤波去除。 在语音识别系统中，以下哪一步骤不属于预处理阶段？ A. 预加重 B. 端点检测 C. 特征提取 D. 加窗 答案：C 解析： 特征提取属于特征提取阶段，而不是预处理阶段。 以下哪种方法属于语音识别的统计模型方法？ A. VQ（矢量量化） B. DTW（动态时间规整） C. HMM（隐马尔可夫模型） D. 深度学习 答案：C\n解析： HMM（隐马尔可夫模型）是一种统计模型方法。 简述题 简述语音生成的过程。 答案： 空气从肺部排出形成气流。 气流冲击声带，声带振动产生基本声波（激励）。 声波经过声道（包括咽喉、口腔和鼻腔）的调制，声道的形状变化由舌、软腭、唇、牙等器官决定。 调制后的声波从口或鼻腔辐射出去，形成语音。 什么是听觉掩蔽效应？ 答案： 听觉掩蔽效应是指一个声音的听觉感受性受到同时存在的另一个声音的影响。具体来说，当一个声音（掩蔽声）存在时，另一个声音（被掩蔽声）的听觉阈值会升高，导致被掩蔽声难以被感知。 简述短时处理中加窗的作用。 答案： 加窗的作用是将语音信号分割成短时段进行处理，以便分析语音的短时特性。窗长一般选取100-200ms，窗宽较大时平滑作用明显，反映能量变化较小；窗宽较小时反映细节快变，包络变化不明显。 什么是倒谱分析？它的主要用途是什么？ 答案： 倒谱分析是将语音信号的声门激励信息与声道响应信息分离的一种方法。它的主要用途是提取声道的共振特征和基音周期，从而帮助分析语音的声学特性。 简述语音识别系统的基本组成。 答案： 预处理：包括预加重、端点检测等。 特征提取：获取语音信号的特征参数。 训练识别网络：建立模板和模型。 识别：通过模式匹配、统计模型或人工神经网络等方法进行语音识别。 综合题 请详细描述语音生成与感知模型中的声道和声门的作用，并结合语音生成框图解释语音生成的过程。 答案： 在语音生成与感知模型中，声门和声道是两个关键部分。 声门： 声门是声带之间的间隙，主要功能是产生激励。当空气从肺部排出时，气流通过声门，声带振动产生基本声波，这个声波是语音生成的起点。 声道： 声道指从声门到嘴唇的所有发音器官，包括咽喉、口腔和鼻腔。声道的主要功能是传输并调制声波。声道的形状变化由舌、软腭、唇、牙等器官决定，这些变化会改变声波的频率特性，从而形成不同的语音。 语音生成框图： 声门（激励）：声带振动产生基本声波。 声道（调制）：声波经过声道的调制，声道的形状变化改变声波的频率特性。 嘴唇（辐射语音）：调制后的声波从嘴唇或鼻腔辐射出去，形成最终的语音。 请结合语音信号的短时处理，解释短时平均能量和短时自相关函数在语音分析中的作用。 答案： 短时平均能量： 短时平均能量是语音信号在短时段内的能量平均值。它的主要用途包括： 区分清音与浊音：浊音的能量通常较高，而清音的能量较低。 区分有声与无声：有声段（如元音）的能量较高，而无声段（如停顿）的能量较低。 作为语音识别的辅助参数：短时平均能量可以帮助识别语音的起始和结束点。 短时自相关函数： 短时自相关函数用于分析语音信号的周期性。它的主要用途包括： 区分浊音与清音：浊音具有明显的周期性，自相关函数会显示出周期性的峰值；而清音无周期性，自相关函数类似噪声。 提取基音周期：通过自相关函数的峰值间隔，可以估计浊音的基音周期。 请详细描述语音识别系统中的隐马尔可夫模型（HMM）的基本原理及其在语音识别中的应用。 答案： 隐马尔可夫模型（HMM）的基本原理： HMM是一种统计模型，用于描述由隐藏的马尔可夫链随机生成的观测序列。HMM包含两个随机过程： 隐藏状态序列：表示系统的内部状态，状态之间的转移遵循马尔可夫性质，即当前状态只依赖于前一个状态。 观测序列：每个隐藏状态生成一个观测值，观测值依赖于当前状态。 HMM在语音识别中的应用： 信号预处理：对语音信号进行预加重、加窗等处理。 特征提取：提取语音信号的特征参数，如MFCC（梅尔频率倒谱系数）。 训练HMM：使用训练数据对HMM进行训练，建立语音模板和模型。 测试集识别：使用训练好的HMM对测试语音进行识别，通过计算观测序列的概率来确定最可能的语音类别。 HMM在语音识别中广泛应用，因为它能够很好地处理语音信号的时变性和短时平稳性，并且能够通过统计方法有效地建模语音的动态特性。 ","date":"2025-01-06T00:00:00Z","image":"https://serennan.github.io/post/speech-signal/image-2.png","permalink":"https://serennan.github.io/post/speech-signal/","title":"语音信号期末复习"},{"content":"我是直接把这些动画效果全放一个css文件了\n创建一个hover-animation.css文件(可自定义)，然后记得在assets/scss/style.scss下添加@import \u0026quot;hover-animation\u0026quot;; 然后在创建的css文件添加以下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 /* 主页博客卡片 */ .article-list article { transition: transform 0.6s ease; -webkit-font-smoothing: antialiased; will-change: transform; transform-origin: center; \u0026amp;:hover { transform: scale(1.02, 1.02); } } /* 左侧栏选项 */ #main-menu { overflow: visible; li { a { -webkit-font-smoothing: antialiased; will-change: transform; transition: transform 0.6s ease; \u0026amp;:hover { transform: scale(1.1, 1.1); will-change: transform; } } } } /* 归档和链接卡片 */ .article-list--compact { overflow: visible; } .article-list--compact article { transition: transform 0.6s ease; -webkit-font-smoothing: antialiased; will-change: transform; \u0026amp;:hover { transform: scale(1.05,1.05); z-index: 4; } } /* 分类页面 */ .article-list--tile article { transition: 0.6s ease; } .article-list--tile article:hover { transform: scale(1.05, 1.05); will-change: transform; } /* 右侧导航栏 */ // 搜索 .search-form.widget { transition: transform 0.6s ease; } .search-form.widget:hover { transform: scale(1.1, 1.1); will-change: transform; -webkit-font-smoothing: antialiased; } //归档 .widget.archives .widget-archive--list { transition: transform .3s ease; will-change: transform; } .widget.archives .widget-archive--list:hover { transform: scale(1.05, 1.05); } // 标签 .tagCloud .tagCloud-tags a { border-radius: 10px; font-size: 1.4rem; transition: transform .3s ease; } .tagCloud .tagCloud-tags a:hover { transform: scale(1.1, 1.1); will-change: transform; -webkit-font-smoothing: antialiased; } 参数简单介绍:\n1 2 3 4 5 6 7 8 9 10 11 12 // 动画时间 transition: 0.6s ease; // 放大 transform: scale(1.1, 1.1); // 允许超出边框 overflow: visible; // 这个是为了放大别出现字体抖动（但好像没什么效果） will-change: transform; -webkit-font-smoothing: antialiased; ","date":"2025-01-05T00:00:00Z","image":"https://serennan.github.io/post/hugo-animation/word.jpg","permalink":"https://serennan.github.io/post/hugo-animation/","title":"【Hugo】动画"},{"content":"这个表盘的设计可能还是有些局限，后续会优化一下\nHTML部分 在\u0026rsquo;layouts/partials/widget/\u0026lsquo;文件夹下创建clock.html文件，并添加以下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;时钟表盘\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;styles.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;section class=\u0026#34;widget clock\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;widget--clock\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;clock-face\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;digital-clock\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;hand hour-hand\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;hand minute-hand\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;hand second-hand\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;center-dot\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;script\u0026gt; const clockFace = document.querySelector(\u0026#39;.clock-face\u0026#39;); const radius = 83; // 刻度圆半径 const center = 88; // 刻度圆中心 for (let i = 0; i \u0026lt; 60; i++) { const angle = i * 6; const radians = (angle * Math.PI) / 180; const x = center + radius * Math.sin(radians); const y = center - radius * Math.cos(radians); const mark = document.createElement(\u0026#39;div\u0026#39;); mark.className = \u0026#39;mark\u0026#39;; mark.style.left = `${x}px`; mark.style.top = `${y}px`; mark.style.transform = `translate(-50%, -50%) rotate(${angle}deg)`; if (i % 15 === 0) { mark.classList.add(\u0026#39;long-mark\u0026#39;); const numberRadius = radius - 15; const numberX = center + numberRadius * Math.sin(radians); const numberY = center - numberRadius * Math.cos(radians); const number = document.createElement(\u0026#39;div\u0026#39;); number.textContent = (i / 5) || 12; number.className = \u0026#39;clock-number\u0026#39;; number.style.left = `${numberX}px`; number.style.top = `${numberY}px`; number.style.transform = `translate(-50%, -50%)`; clockFace.appendChild(number); } else if (i % 5 === 0) { mark.classList.add(\u0026#39;middle-mark\u0026#39;); } else { mark.classList.add(\u0026#39;short-mark\u0026#39;); } clockFace.appendChild(mark); } function updateClock() { const now = new Date(); const hour = now.getHours(); const minute = now.getMinutes(); const second = now.getSeconds(); const hourHand = document.querySelector(\u0026#39;.hour-hand\u0026#39;); const minuteHand = document.querySelector(\u0026#39;.minute-hand\u0026#39;); const secondHand = document.querySelector(\u0026#39;.second-hand\u0026#39;); const hourDeg = (hour % 12) * 30 + (minute / 60) * 30; const minuteDeg = minute * 6 + (second / 60) * 6; const secondDeg = second * 6; hourHand.style.transform = `rotate(${hourDeg}deg)`; minuteHand.style.transform = `rotate(${minuteDeg}deg)`; secondHand.style.transition = second === 0 ? \u0026#39;none\u0026#39; : \u0026#39;transform 0.5s linear\u0026#39;; secondHand.style.transform = `rotate(${secondDeg}deg)`; const digitalClock = document.querySelector(\u0026#39;.digital-clock\u0026#39;); const timeString = `${hour}:${minute.toString().padStart(2, \u0026#39;0\u0026#39;)}`; digitalClock.textContent = timeString; setTimeout(updateClock, 1000); } updateClock(); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; css部分 然后在assets/scss文件夹下创建clock.scss文件，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 /* 时钟容器样式 */ .widget.clock { margin-top: 50px; } /* 时钟表盘样式 */ .clock-face { position: relative; width: 200px; height: 200px; border: 12px solid #858b8b; /* 表盘边框颜色 */ border-radius: 50%; margin: 0 auto; background: var(--card-background); /* 动态背景 */ box-shadow: 0 8px 15px rgba(0, 0, 0, 0.2), inset 0 0 8px rgba(255, 255, 255, 0.8); } /* 刻度线通用样式 */ .mark { position: absolute; width: 2px; background: #535656; border-radius: 2px; transform-origin: center center; } /* 长刻度（小时刻度）样式 */ .long-mark { top: 5px; height: 18px; background: #65656c; /* 长刻度颜色稍深 */ box-shadow: 0 2px 5px rgba(0, 0, 0, 0.3); } /* 数字样式 */ .clock-number { position: absolute; font-size: 12px; /* 字体大小 */ color: #797F7F !important; /* 强制覆盖其他样式 */ text-align: center; font-weight: bold; } /* 中刻度（分钟刻度）样式 */ .middle-mark { height: 10px; background: #7f8686; /* 中刻度颜色稍浅 */ box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2); } /* 短刻度（秒刻度）样式 */ .short-mark { height: 5px; background: #c0baba; /* 短刻度颜色稍浅 */ box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2); } /* 指针通用样式 */ .hand { position: absolute; top: 50%; left: 50%; transform-origin: 50% 100%; /* 旋转中心在底部 */ background: #444444; border-radius: 2px; transition: transform 0.5s cubic-bezier(0.4, 2.3, 0.6, 1); } /* 时针样式 */ .hour-hand { width: 6px; height: 40px; background: #6A4C9C; /* 紫色 */ z-index: 3; box-shadow: 0 2px 5px rgba(0, 0, 0, 0.4); top: calc(50% - 40px); left: calc(50% - 3px); } /* 分针样式 */ .minute-hand { width: 4px; height: 60px; background: #B497BD; /* 浅紫色 */ z-index: 2; box-shadow: 0 2px 5px rgba(0, 0, 0, 0.4); top: calc(50% - 60px); left: calc(50% - 2px); } /* 秒针样式 */ .second-hand { width: 2px; height: 70px; background: #FF69B4; /* 亮粉色 */ z-index: 1; box-shadow: 0 2px 8px rgba(255, 99, 71, 0.6); top: calc(50% - 70px); left: calc(50% - 1px); } /* 中心点样式 */ .center-dot { position: absolute; width: 12px; height: 12px; background: #845EC2; border-radius: 50%; top: 50%; left: 50%; transform: translate(-50%, -50%); box-shadow: 0 2px 5px rgba(0, 0, 0, 0.5), inset 0 0 5px rgba(255, 255, 255, 0.8); z-index: 4; } .digital-clock { position: absolute; /* 绝对定位 */ top: 50%; /* 垂直居中 */ left: 50%; /* 水平居中 */ transform: translate(-50%, -50%); /* 精确居中 */ font-size: 24px; /* 字体大小 */ font-family: Arial, sans-serif; /* 字体 */ color: #7C8181; /* 字体颜色 */ opacity: 0; /* 默认隐藏 */ transition: opacity 0.3s ease; /* 添加过渡效果 */ z-index: 5; } .clock:hover .digital-clock { opacity: 1; /* 鼠标悬停时显示 */ } .clock-face { cursor: pointer; /* 鼠标悬停时显示手型指针 */ } 问题 如果时钟刻度有些错位，就修改html文件的\n1 2 const radius = 83; // 刻度圆半径 const center = 88; // 刻度圆中心 ","date":"2025-01-05T00:00:00Z","image":"https://serennan.github.io/post/hugo-clock/clock.jpg","permalink":"https://serennan.github.io/post/hugo-clock/","title":"【Hugo】时钟"},{"content":"字体 字体文件放在assets/fonts下，然后在layouts/partials/footer/costom.html(没有就创建)中引入,格式如下\n1 2 3 4 5 6 7 8 9 10 11 \u0026lt;style\u0026gt; @font-face { font-family: \u0026#39;MapleMono2\u0026#39;; src: url(\u0026#39;{{ (resources.Get \u0026#34;font/MapleMono2.ttf\u0026#34;).Permalink }}\u0026#39;) format(\u0026#39;truetype\u0026#39;); } :root { --base-font-family: \u0026#39;MapleMono2\u0026#39;; --code-font-family: \u0026#39;MapleMono2\u0026#39;; } \u0026lt;/style\u0026gt; 注意: 字体文件路径src要有后缀\n自定义分类页面样式 我不喜欢原本默认的归档页面，想把归档和分类分成两个页面，具体操作写在了我的Hugo配置博客Hugo配置(stack主题)\n后续想添加对应的页面样式，就在 layouts 添加对应的 html 文件，比如 layouts/page/category.html ，然后在 contents/page/category.md 中添加 layout: \u0026quot;category\u0026quot; ，这样就会使用 layouts/page/category.html 的样式了\n评论功能 这里使用的giscus配置\n先在 github page 上打开 discussion 功能 点击setting，向下滑找到discussion，勾选discussion\n下载 giscus giscus app\n选择仓库地址 配置 hugo 进入giscus官网 giscus\n按照步骤配置，最后复制代码 五个重要参数：\ndata-repo data-repo-id data-category data-category-id data-mapping 添加到配置文件中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 comments: enabled: true provider: giscus giscus: repo: serenNan/serenNan.github.io repoID: category: Announcements categoryID: mapping: pathname lightTheme: light darkTheme: dark reactionsEnabled: 1 emitMetadata: 0 inputPosition: bottom lang: zh-CN 博客背景 我这里用的是particles动态粒子背景\n配置：\n进入网站自定义配置：particles 唯一需要注意的是有个选项改成window\n配置好后下载文件 将particles.min.js 和 particlesjs-config.json放在assets/background文件夹下\n在layouts/partials/footer/custom.html中添加以下代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;div id=\u0026#34;particles-js\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;{{ (resources.Get \u0026#34;background/particles.min.js\u0026#34;).RelPermalink }}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; particlesJS.load(\u0026#39;particles-js\u0026#39;, \u0026#39;{{ (resources.Get \u0026#34;background/particlesjs-config.json\u0026#34;).RelPermalink }}\u0026#39;, function() { console.log(\u0026#39;particles.js loaded - callback\u0026#39;); }); \u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; #particles-js { position: fixed; top: 0; left: 0; width: 100%; height: 100%; z-index: -1; } \u0026lt;/style\u0026gt; ","date":"2025-01-02T00:00:00Z","image":"https://serennan.github.io/post/hugo-beautify/blog2.jpg","permalink":"https://serennan.github.io/post/hugo-beautify/","title":"【Hugo】美化\u0026优化(stack主题)"},{"content":"拷贝构造函数 参考文章 csdn：C++拷贝构造函数\n概述 拷贝构造函数，又称复制构造函数，是一种特殊的构造函数，它由编译器调用来完成一些基于同一类的其他对象的构造及初始化。\n其唯一的形参必须是引用，但并不限制为const，一般普遍的会加上const限制。\n调用拷贝构造函数的情形 一个对象作为函数参数，以值传递的方式传入函数体（函数传参，类类型的值传递） 1 2 3 4 5 6 7 8 9 10 11 12 class Complex { }; void Fun(Complex c1) { } int main() { Complex c1(1,2); Fun(c1); // 这里就调用了默认的拷贝构造函数 } 一个对象作为函数返回值，以值传递的方式从函数返回;（函数的返回类型是类，从局部对象到临时对象的拷贝构造） 1 2 3 4 5 Complex Fun() { Complex c(10,20); return c; // 这里会调用 } 一个对象用于给另外一个对象进行初始化(常称为赋值初始化);（用已有对象去初始化本类的其他对象） 1 2 3 4 5 6 int main() { Complex c1(1,2); Complex c2(c1); // 此处 Complex c3=c1; // 此处 } 浅拷贝与深拷贝 当对象的成员变量中存在指针变量时，用存在的对象初始化新建对象时指针变量一同初始化，但这时调用一般拷贝构造函数（浅拷贝）会使新对象中的指针指向和初始化对象指针指向一致，那么当用来初始化的对象在释放内存时会释放掉指针指向的内存，而当新创建的对象释放时会出现程序错误，以为这个指针指向的内存被释放了两次。因此我们需要手动提供另一种拷贝构造函数（深拷贝）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class MyClass { public: int* data; MyClass(int d) { data = new int(d); // 动态分配内存 } ~MyClass() { delete data; // 释放内存 } MyClass(const MyClass\u0026amp; other) { data = new int(*other.data); // 深拷贝：分配新内存并复制内容 } }; int main() { MyClass original(10); MyClass copy(original); // 调用深拷贝构造函数 return 0; } 虚析构函数 总的来说虚析构函数是为了避免内存泄露，而且是当子类中会有指针成员变量时才会使用得到的。也就说虚析构函数使得在删除指向子类对象的基类指针时可以调用子类的析构函数达到释放子类中堆内存的目的，而防止内存泄露的.\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 #include \u0026lt;iostream\u0026gt; using namespace std; class Fish { public: Fish() { cout \u0026lt;\u0026lt; \u0026#34;Constructed Fish\u0026#34; \u0026lt;\u0026lt; endl; } // 如果这里不是虚析构函数，那么delete pFish时只会调用基类的析构函数，而不会调用子类的析构函数 virtual ~Fish() // virtual destructor! { cout \u0026lt;\u0026lt; \u0026#34;Destroyed Fish\u0026#34; \u0026lt;\u0026lt; endl; } }; class Tuna : public Fish { public: Tuna() { cout \u0026lt;\u0026lt; \u0026#34;Constructed Tuna\u0026#34; \u0026lt;\u0026lt; endl; } ~Tuna() { cout \u0026lt;\u0026lt; \u0026#34;Destroyed Tuna\u0026#34; \u0026lt;\u0026lt; endl; } }; void DeleteFishMemory(Fish *pFish) { delete pFish; } int main() { cout \u0026lt;\u0026lt; \u0026#34;Allocating a Tuna on the free store:\u0026#34; \u0026lt;\u0026lt; endl; Tuna *pTuna = new Tuna; cout \u0026lt;\u0026lt; \u0026#34;Deleting the Tuna: \u0026#34; \u0026lt;\u0026lt; endl; DeleteFishMemory(pTuna); cout \u0026lt;\u0026lt; \u0026#34;Instantiating a Tuna on the stack:\u0026#34; \u0026lt;\u0026lt; endl; Tuna myDinner; cout \u0026lt;\u0026lt; \u0026#34;Automatic destruction as it goes out of scope: \u0026#34; \u0026lt;\u0026lt; endl; return 0; } 常量成员函数 常量对象和非常量对象 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #include \u0026lt;iostream\u0026gt; using namespace std; class MyClass { private: int x; public: MyClass(int n) { x = n; } void setX(int n) // 非常量成员函数 { x = n; } int getX() const // 常量成员函数 { return x; } }; int main() { MyClass obj1(10); // 非常量对象 const MyClass obj2(20); // 常量对象 obj1.setX(30); // 可以修改obj1的数据成员 cout \u0026lt;\u0026lt; \u0026#34;obj1.x = \u0026#34; \u0026lt;\u0026lt; obj1.getX() \u0026lt;\u0026lt; endl; // obj1.x = 30 // obj2.setX(40); // 编译错误，不能修改obj2的数据成员（常量对象不能调用非常量成员函数） cout \u0026lt;\u0026lt; \u0026#34;obj2.x = \u0026#34; \u0026lt;\u0026lt; obj2.getX() \u0026lt;\u0026lt; endl; // obj1.x = 20 return 0; } 常量成员函数 常量成员函数的特点 常量成员函数不会修改类的成员函数，即它们是只读的。因此，常量成员函数不能修改类的数据成员，也不能调用非常量成员函数,因为非常量成员函数可能会修改类的数据成员。 常量成员函数可以被常量对象和非常量对象调用。如果一个对象是常量对象，则只能调用该对象的常量成员函数，而不能调用非常量成员函数。 常量成员函数可以访问类的所有成员变量和常量成员函数。 常量成员函数的作用是保证类的数据成员不被修改，从而提高程序的安全性和可靠性。 常量成员函数通常用于访问类的数据成员，而不是修改它们。 例如：可以使用常量成员函数来实现类的数据成员的读取操作，而使用非常量成员函数来实现类的数据成员的写入操作。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #include \u0026lt;iostream\u0026gt; using namespace std; class Person { private: string name; int age; public: Person(string n, int a) { name = n; age = a; } string getName() const { return name; } int getAge() const { return age; } void show() const { cout \u0026lt;\u0026lt; \u0026#34;Name: \u0026#34; \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34;, Age: \u0026#34; \u0026lt;\u0026lt; age \u0026lt;\u0026lt; endl; } }; int main() { Person p(\u0026#34;Alice\u0026#34;, 20); p.show(); return 0; } 左值和右值 参考文章 csdn：C++ 左值和右值\n左值和右值的定义 左值（loactor value）:存储在内存中、可寻址的数据\n右值（read value）:可以提供数据值的数据（不一定可寻址，例如存储在寄存器中的数据）\n右值引用 左值引用无法引用右值； 常量左值引用可以操作右值，但是无法对右值进行修改； 右值引用可以对右值进行修改； 常量右值引用：引用一个右值，并且不可更改。可以常量左值引用代替。 1 2 3 4 5 6 7 int a = 10; int \u0026amp;b = a; // 左值引用 // int \u0026amp;c = 10; // 错误，左值引用无法操作右值 b = 20; const int \u0026amp;d = 10; // 常量左值引用可以操作右值 int \u0026amp;\u0026amp;e = 20; // 右值引用 e = 25; // 修改右值 因此c++11中引入右值引用\u0026amp;\u0026amp;。\n右值引用使用场景 拷贝构造函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #include \u0026lt;iostream\u0026gt; using namespace std; class demo { public: // 构造函数 demo() : num(new int(0)) { cout \u0026lt;\u0026lt; \u0026#34;construct!\u0026#34; \u0026lt;\u0026lt; endl; } // 拷贝构造函数（深拷贝） demo(const demo \u0026amp;d) : num(new int(*d.num)) { cout \u0026lt;\u0026lt; \u0026#34;copy construct!\u0026#34; \u0026lt;\u0026lt; endl; } ~demo() { cout \u0026lt;\u0026lt; \u0026#34;class destruct!\u0026#34; \u0026lt;\u0026lt; endl; } private: int *num; }; demo get_demo() { return demo(); // 返回一个demo对象，是一个右值 } int main() { demo a (get_demo()); // 拷贝构造 return 0; } 输出：\nconstruct! copy construct! copy construct! class destruct! class destruct! 有些编译器可能会优化，只输出一次拷贝构造函数。\n如上所示，demo 类自定义了一个拷贝构造函数。该函数在拷贝 d.num 指针成员时，必须采用深拷贝的方式，即拷贝该指针成员本身的同时，还要拷贝指针指向的内存资源。否则一旦多个对象中的指针成员指向同一块堆空间，这些对象析构时就会对该空间释放多次，这是不允许的。\ndemo a (get_demo()) 的流程：\n执行 get_demo() 函数，demo()调用构造函数生成一个匿名对象 执行 return demo() ，调用拷贝构造函数拷贝匿名对象，作为函数get_demo()的返回值（get_demo()执行完毕，匿名对象会被销毁） 执行 a(get_demo()), 调用拷贝构造函数(此行代码执行完毕，get_demo()的返回值会被析构) 程序结束前，a被析构。 在这个过程中，底层执行了2次深拷贝。如果指针指向的堆空间较大，会大大降低执行的效率。通过移动构造函数可以解决这个问题。\n何时调用拷贝构造函数？（详见：拷贝构造函数）\n移动构造函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #include \u0026lt;iostream\u0026gt; using namespace std; class demo { public: // 构造函数 demo() : num(new int(0)) { cout \u0026lt;\u0026lt; \u0026#34;construct!\u0026#34; \u0026lt;\u0026lt; endl; } // 拷贝构造函数（深拷贝） demo(const demo \u0026amp;d) : num(new int(*d.num)) { cout \u0026lt;\u0026lt; \u0026#34;copy construct!\u0026#34; \u0026lt;\u0026lt; endl; } // 移动构造函数 demo(demo \u0026amp;\u0026amp;d) : num(d.num) { d.num = nullptr; cout \u0026lt;\u0026lt; \u0026#34;move construct!\u0026#34; \u0026lt;\u0026lt; endl; } ~demo() { cout \u0026lt;\u0026lt; \u0026#34;class destruct!\u0026#34; \u0026lt;\u0026lt; endl; } private: int *num; }; demo get_demo() { demo temp; // 创建一个局部对象 return temp; // 返回局部对象 } int main() { demo a(get_demo()); // 调用移动构造函数 return 0; } 输出：\nconstruct! move construct! class destruct! class destruct! 使用右值引用类型的参数，指针浅拷贝，右值对象指针置为nullptr, 从而，避免拷贝堆空间，完成初始化。\n当类中同时包含拷贝构造函数和移动构造函数时，如果使用临时对象初始化当前类的对象，编译器会优先调用移动构造函数来完成此操作。只有当类中没有合适的移动构造函数时，编译器才会退而求其次，调用拷贝构造函数。\nstd::move()可以将左值转换为右值，从而使用移动构造。\n1 2 3 4 5 demo get_demo() { demo temp; // 创建一个局部对象 return std::move(temp); // 使用 std::move 触发移动构造函数 } 输出是一样的\nmove函数 参考文章 csdn：C++11中的move函数\n智能指针 参考文章 csdn：C++智能指针\n智能指针概述 是原始指针的封装，会自动分配内存，不需要担心潜在的内存泄露。\n为什么使用智能指针 一句话带过：智能指针就是帮我们C++程序员管理动态分配的内存的，它会帮助我们自动释放new出来的内存，从而避免内存泄漏。\n下面的内存泄露的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;memory\u0026gt; using namespace std; // 动态分配内存，没有释放就return void memoryLeak1() { string *str = new string(\u0026#34;动态分配内存！\u0026#34;); return; } // 动态分配内存，虽然有些释放内存的代码，但是被半路截胡return了 int memoryLeak2() { string *str = new string(\u0026#34;内存泄露！\u0026#34;); // ...此处省略一万行代码 // 发生某些异常，需要结束函数 if (1) { return -1; } / // 另外，使用try、catch结束函数，也会造成内存泄漏！ / delete str;\t// 虽然写了释放内存的代码，但是遭到函数中段返回，使得指针没有得到释放 return 1; } int main(void) { memoryLeak1(); memoryLeak2(); return 0; } memoryLeak1函数中，new了一个字符串指针，但是没有delete就已经return结束函数了，导致内存没有被释放，内存泄露！ memoryLeak2函数中，new了一个字符串指针，虽然在函数末尾有些释放内存的代码delete str，但是在delete之前就已经return了，所以内存也没有被释放，内存泄露！\n使用指针，我们没有释放，就会造成内存泄露。但是我们使用普通对象却不会。\n而智能指针本质是对一个普通指针的封装，利用有生命周期的对象自动释放的特性，来实现内存的自动管理。\nauto_ptr auto_ptr 是c++ 98定义的智能指针模板，其定义了管理指针的对象，可以将new获得（直接或间接）的地址赋给这种对象。当对象过期时，其析构函数将使用delete来释放内存！\n用法： 头文件：#include \u0026lt;memory\u0026gt; 用法： auto_ptr\u0026lt;类型\u0026gt; 变量名(new 类型)\n例如：\n1 2 3 auto_ptr\u0026lt; string \u0026gt; str(new string(“我要成为大牛~ 变得很牛逼！”)); auto_ptr\u0026lt;vector\u0026lt; int \u0026gt;\u0026gt; av(new vector\u0026lt; int \u0026gt;()); auto_ptr\u0026lt; int \u0026gt; array(new int[10]); 下面的代码使用new创建一个对象，但是不使用delete，就会发生内存泄露。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #include \u0026#34;iostream\u0026#34; using namespace std; class Test { public: Test() { cout \u0026lt;\u0026lt; \u0026#34;Test的构造函数...\u0026#34; \u0026lt;\u0026lt; endl; } ~Test() { cout \u0026lt;\u0026lt; \u0026#34;Test的析构函数...\u0026#34; \u0026lt;\u0026lt; endl; } int getDebug() { return this-\u0026gt;debug; } private: int debug = 20; }; int main(void) { Test *test = new Test; cout \u0026lt;\u0026lt; test-\u0026gt;getDebug() \u0026lt;\u0026lt; endl; // delete test; return 0; } 输出：\nTest的构造函数... 要释放内存，就得手动delete，或者使用智能指针\n使用智能指针：\n1 2 3 4 5 6 7 8 9 10 11 int main(void) { // Test *test = new Test; auto_ptr\u0026lt;Test\u0026gt; test(new Test); cout \u0026lt;\u0026lt; \u0026#34;test-\u0026gt;debug：\u0026#34; \u0026lt;\u0026lt; test-\u0026gt;getDebug() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;(*test).debug：\u0026#34; \u0026lt;\u0026lt; (*test).getDebug() \u0026lt;\u0026lt; endl; return 0; } 输出：\nTest的构造函数... test-\u0026gt;debug：20 (*test).debug：20 Test的析构函数... 智能指针可以像普通指针一样使用，并且会自动释放内存\n智能指针有三个常用函数：\nget()：获取智能指针管理的指针\n1 2 3 4 5 // 定义智能指针 auto_ptr\u0026lt;Test\u0026gt; test(new Test); Test *tmp = test.get();\t// 获取指针返回 cout \u0026lt;\u0026lt; \u0026#34;tmp-\u0026gt;debug：\u0026#34; \u0026lt;\u0026lt; tmp-\u0026gt;getDebug() \u0026lt;\u0026lt; endl; 但一般不这么使用，因为可以直接使用智能指针操作\nrelease()：释放智能指针管理的指针\n1 2 3 4 5 // 定义智能指针 auto_ptr\u0026lt;Test\u0026gt; test(new Test); Test *tmp2 = test.release();\t// 取消智能指针对动态内存的托管 delete tmp2;\t// 之前分配的内存需要自己手动释放 reset()：重置智能指针管理的指针\n1 2 3 4 5 6 // 定义智能指针 auto_ptr\u0026lt;Test\u0026gt; test(new Test); test.reset();\t// 释放掉智能指针托管的指针内存，并将其置NULL test.reset(new Test());\t// 释放掉智能指针托管的指针内存，并将参数指针取代之 unique_ptr c++11使用unique_ptr替代auto_ptr\nunique_ptr特性：\n基于排他所有权模式：两个指针不能指向同一个资源 无法进行左值unique_ptr复制构造，也无法进行左值复制赋值操作，但允许临时右值赋值构造和赋值 保存指向某个对象的指针，当它本身离开作用域时会自动释放它指向的对象。 在容器中保存指针是安全的 ","date":"2024-12-30T00:00:00Z","image":"https://serennan.github.io/post/cpp_study/cpp.jpg","permalink":"https://serennan.github.io/post/cpp_study/","title":"C++语法"},{"content":"yaml参数 主框架 1 2 3 4 5 6 baseurl: https://example.com/ languageCode: en-us theme: hugo-theme-stack paginate: 10 title: 个人博客 copyright: serenNan baseurl: 目前是github pages的地址 my-blog\nlanguageCode: 语言代码\ntheme: 主题名称\npaginate: 每页显示的文章数量\ntitle: 网站标题（目前没使用）\ncopyright: 网页最下方显示\n语言 1 2 3 # Theme i18n support # Available values: ar, bn, ca, de, el, en, es, fr, hu, id, it, ja, ko, nl, pt-br, th, uk, zh-cn, zh-hk, zh-tw DefaultContentLanguage: zh-cn DefaultContentLanguage: 默认语言\n网页图标 1 favicon: # e.g.: favicon placed in `static/favicon.ico` of your site folder, then set this field to `/favicon.ico` (`/` is necessary) favicon: 网站图标(将 favicon 放置在站点文件夹的 static/favicon.ico 中，然后将此字段设置为 /favicon.ico（/ 是必需的）。)\n页脚 1 2 3 footer: since: 2024 customText: footer: 页脚\nsince: 年份\ncustomText: 自定义文本\n头像 1 2 3 4 5 6 7 sidebar: emoji: 🐈‍⬛ subtitle: 欢迎来到我的个人博客 avatar: enabled: true local: true src: img/avatar.png sidebar: 侧边栏\navatar: 头像\nsrc: 头像路径\n头像是在 assets/img/avatar.png 中\n文章信息 1 2 3 4 5 6 7 article: math: false toc: true readingTime: true license: enabled: true default: Licensed under CC BY-NC-SA 4.0 article: 文章\nmath: 数学公式\ntoc: 目录\nreadingTime: 阅读时间\nlicense: 许可证\nenabled: 是否启用\ndefault: 默认许可证\n右侧侧边栏 1 2 3 4 5 6 7 8 9 10 11 12 13 14 widgets: homepage: - type: search - type: archives params: limit: 5 - type: categories params: limit: 10 - type: tag-cloud params: limit: 10 page: - type: toc widgets: 小工具 (右边侧边栏)\nsearch: 搜索\narchives: 归档\ncategories: 分类\ntag-cloud: 标签云\ntoc: 目录\n头像下方图标 1 2 3 4 5 6 7 8 9 10 11 12 social: - identifier: github name: GitHub url: https://github.com/CaiJimmy/hugo-theme-stack params: icon: github-2 - identifier: bilibili name: Bilibili url: https://space.bilibili.com/450940909 params: icon: bilibili 头像下方的链接，icon图标放在assets/icons文件夹下，svg后缀。\n左侧侧边栏导航 在content/page文件夹下\nlink链接 在content/page/links.md下 格式:\n1 2 3 4 5 6 7 8 9 links: - title: GitHub description: GitHub is the world\u0026#39;s largest software development platform. website: https://github.com image: https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png - title: TypeScript description: TypeScript is a typed superset of JavaScript that compiles to plain JavaScript. website: https://www.typescriptlang.org image: ts-logo-128.jpg 自定义分类页面 我这里是自定义的分类页面，将归档和分类分开\n在content/categories.md下，每有一个分类就创建一个文件夹，文件夹下放_index.md文件，格式如下：\n注意：是_index.md要加个_\n1 2 3 4 5 6 7 8 title: \u0026#34;文档\u0026#34; date: 2020-03-14T15:40:24+06:00 description : \u0026#34;文档分类\u0026#34; slug: \u0026#34;document\u0026#34; image: 猫.png style: background: \u0026#34;#2a9d8f\u0026#34; color: \u0026#34;#fff\u0026#34; 如果想完善页面，可以在layouts/page/categories.html添加下面的内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 {{ define \u0026#34;body-class\u0026#34; }}template-categories{{ end }} {{ define \u0026#34;main\u0026#34; }} \u0026lt;header\u0026gt; {{- $taxonomy := $.Site.GetPage \u0026#34;taxonomyTerm\u0026#34; \u0026#34;categories\u0026#34; -}} {{- $terms := $taxonomy.Pages -}} {{ if $terms }} \u0026lt;h1 class=\u0026#34;section-title\u0026#34;\u0026gt;分类\u0026lt;/h1\u0026gt; \u0026lt;!-- 这里是标题 --\u0026gt; \u0026lt;div class=\u0026#34;subsection-list\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;article-list--tile\u0026#34; style=\u0026#34;display: flex; flex-direction: column;\u0026#34;\u0026gt; {{ range $terms }} \u0026lt;div class=\u0026#34;category-group\u0026#34; style=\u0026#34;flex: 1 1 auto; margin: 10px;\u0026#34;\u0026gt; \u0026lt;h3 class=\u0026#34;category-title\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt; \u0026lt;/h3\u0026gt; \u0026lt;div class=\u0026#34;article-list--horizontal\u0026#34; style=\u0026#34;display: flex; overflow-x: auto;\u0026#34;\u0026gt; {{ $articles := where .Site.RegularPages \u0026#34;Params.categories\u0026#34; \u0026#34;intersect\u0026#34; (slice .Title) }} {{ range $articles }} \u0026lt;div class=\u0026#34;article-tile\u0026#34; style=\u0026#34;flex: 0 0 auto; margin: 5px;\u0026#34;\u0026gt; {{ partial \u0026#34;article-list/tile\u0026#34; (dict \u0026#34;context\u0026#34; . \u0026#34;size\u0026#34; \u0026#34;250x150\u0026#34; \u0026#34;Type\u0026#34; \u0026#34;taxonomy\u0026#34;) }} \u0026lt;/div\u0026gt; {{ end }} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {{ end }} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {{ end }} \u0026lt;/header\u0026gt; {{ partialCached \u0026#34;footer/footer\u0026#34; . }} {{ end }} 文章 在content/post文件夹下，正文就用markdown格式\n主页blog显示 1 2 3 4 5 6 7 8 title: Chinese Test description: 这是一个副标题 date: 2020-09-09 slug: test-chinese # url显示 image: helena-hertz-wWZzXlDpMog-unsplash.jpg categories: - Test - 测试 创建时间\u0026amp;更新时间 1 2 3 4 5 6 7 8 # 更新时间：优先读取git时间 -\u0026gt; git时间不存在，就读取本地文件修改时间 frontmatter: lastmod: - :git - :fileModTime # 允许获取Git信息\tenableGitInfo: true 在部署文件.github/workflows/deploy.yaml 添加：\n1 2 3 4 5 6 - name: Git Configuration run: | git config --global core.quotePath false git config --global core.autocrlf false git config --global core.safecrlf true git config --global core.ignorecase false 注意缩进要对\nstack默认显示在文章最后面，如果想在主页面的博客文章显示，在layouts/partials/article/components/details.html添加：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \u0026lt;!-- 创建时间\u0026amp;阅读时长 --\u0026gt; \u0026lt;footer class=\u0026#34;article-time\u0026#34;\u0026gt; {{ if $showDate }} \u0026lt;div\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;date\u0026#34; }} \u0026lt;time class=\u0026#34;article-time--published\u0026#34;\u0026gt; {{- .Date | time.Format (or .Site.Params.dateFormat.published \u0026#34;Jan 02, 2006\u0026#34;) -}} \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{ end }} {{ if $showReadingTime }} \u0026lt;div\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;clock\u0026#34; }} \u0026lt;time class=\u0026#34;article-time--reading\u0026#34;\u0026gt; {{ T \u0026#34;article.readingTime\u0026#34; .ReadingTime }} \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{ end }} {{ if and $showDate (ne .Lastmod .Date) }} \u0026lt;span class=\u0026#34;time-divider\u0026#34;\u0026gt;|\u0026lt;/span\u0026gt; {{ end }} {{- if ne .Lastmod .Date -}} \u0026lt;div class=\u0026#34;article-time--lastmod\u0026#34;\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;clock\u0026#34; }} \u0026lt;time\u0026gt; {{ .Lastmod.Format ( or .Site.Params.dateFormat.lastUpdated \u0026#34;Jan 02, 2006 15:04 MST\u0026#34; ) }} \u0026lt;/time\u0026gt; \u0026lt;/div\u0026gt; {{- end -}} 自带的有阅读时长，我没开启\n文章末尾也会显示最后修改时间，想删除就去layouts/partials/article/components/footer.html删掉：\n1 2 3 4 5 6 7 8 {{- if ne .Lastmod .Date -}} \u0026lt;section class=\u0026#34;article-lastmod\u0026#34;\u0026gt; {{ partial \u0026#34;helper/icon\u0026#34; \u0026#34;clock\u0026#34; }} \u0026lt;span\u0026gt; {{ T \u0026#34;article.lastUpdatedOn\u0026#34; }} {{ .Lastmod | time.Format ( or .Site.Params.dateFormat.lastUpdated \u0026#34;Jan 02, 2006 15:04 MST\u0026#34; ) }} \u0026lt;/span\u0026gt; \u0026lt;/section\u0026gt; {{- end -}} ","date":"2024-12-29T00:00:00Z","image":"https://serennan.github.io/post/hugo-config/blog1.jpg","permalink":"https://serennan.github.io/post/hugo-config/","title":"【Hugo】配置(stack主题)"},{"content":"基础命令 CSDN博主总结常用命令\n获得基础信息，输出Metadata 打开媒体文件，获取Meta信息，关闭媒体文件\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #include \u0026#34;libavutil/log.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; // 传入命令行参数个数 int main(int argc, char **argv) { // 设置日志级别 av_log_set_level(AV_LOG_DEBUG); // 设置日志输出函数 // 检查参数个数 if (argc \u0026lt; 2) { av_log(NULL, AV_LOG_DEBUG, \u0026#34;Usage:%s infileName.\\n\u0026#34;, argv[0]); return -1; } // 获取输入文件名 const char *infileName = argv[1]; // 初始化所有组件 AVFormatContext *pFormatCtx = NULL; // 打开媒体文件 int ret = avformat_open_input(\u0026amp;pFormatCtx, infileName, NULL, NULL); // av_err2str()函数返回错误信息 if (ret != 0) { // av_err2str()函数返回错误信息 av_log(NULL, AV_LOG_DEBUG, \u0026#34;open input file:%s failed: %s\\n\u0026#34;, infileName, av_err2str(ret)); return -1; } // 获取媒体文件信息 av_dump_format(pFormatCtx, 0, infileName, 0); // 关闭媒体文件 avformat_close_input(\u0026amp;pFormatCtx); return 0; } 容器/文件 (Container/File) 定义: 特定格式的多媒体文件，如 .mp4, .flv, .mov 等。 作用: 存储和组织多媒体数据，包括音频、视频、字幕等。 常见格式: MP4: 广泛用于视频存储和流媒体。 FLV: 主要用于Flash视频。 MOV: 苹果公司开发的视频格式。 媒体流 (Stream) 定义: 一段连续的数据，如一段声音数据、一段视频或者一段字幕数据。 特点: 由不同编码器编码。 类型: 音频流: 存储音频数据。 视频流: 存储视频数据。 字幕流: 存储字幕数据。 数据包 (Packet) 定义: 一个媒体流由大量的数据包组成，是压缩后的数据。 作用: 传输和存储媒体数据的基本单位。 特点: 数据包是压缩后的数据，便于传输和存储。 数据帧 (Frame) 定义: 一个数据包由一个或多个数据帧组成，是非压缩数据。 作用: 原始的、未压缩的媒体数据。 类型: I帧 (Intra Frame): 独立帧，不依赖其他帧。 P帧 (Predictive Frame): 依赖前一帧进行预测。 B帧 (Bidirectional Frame): 依赖前后帧进行预测。 编解码器 (Codec) 定义: 编解码器是以帧为单位实现压缩数据和原始数据之间相互转换的工具。 作用: 用于压缩和解压缩媒体数据。 常见编解码器: 视频编解码器: H.264, H.265, VP9 等。 音频编解码器: AAC, MP3, Vorbis 等。 重要结构体 AVFormatContext: 管理整个多媒体文件的格式和结构。 AVStream: 表示媒体文件中的一个单独的媒体流。 AVCodecContext 与 AVCodec: 管理媒体数据的编码和解码过程。 AVPacket: 表示压缩后的媒体数据。 AVFrame: 表示未压缩的原始媒体数据。 解封装-提取aac数据 AAC（Advanced Audio Coding）是一种高级音频编码技术，广泛用于数字音频压缩和传输。它是由MPEG（Moving Picture Experts Group）开发的，旨在提供比MP3更高的音质和更高的压缩效率。AAC通常用于各种音频应用，包括音乐、视频、广播和流媒体服务。\nAAC的主要特点：\n高音质：AAC能够在较低的比特率下提供比MP3更高的音质。 多通道支持：AAC支持多通道音频，包括立体声、5.1环绕声和7.1环绕声。 低延迟：AAC设计用于低延迟应用，适合实时音频传输。 灵活性：AAC支持多种比特率和采样率，适用于不同的应用场景。 1 2 ffmpeg -y -i out.mp4 -vn -acodec copy out.aac ffplay out.aac 流程 操作步骤 函数名 打开媒体文件 avformat_open_input 获取码流信息 avformat_find_stream_info 获取音频流 av_find_best_stream 初始化 packet av_packet_alloc 读取 packet 数据 av_read_frame 释放 packet 数据 av_packet_unref 关闭媒体文件 avformat_close_input 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; int main(int argc, char *argv[]) { // 设置日志级别 av_log_set_level(AV_LOG_DEBUG); // 如果参数小于3，输出使用方法 if (argc \u0026lt; 3) { // argv[0]是程序名 av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input file\u0026gt; \u0026lt;output file\u0026gt;\\n\u0026#34;, argv[0]); return -1; } // 获取命令行的输入音频 const char *inputName = argv[1]; // 获取命令行的输出音频 const char *outputName = argv[2]; av_sdp_create; // 打开输入音频文件 AVFormatContext *inFormatCtx = NULL; // 打开媒体文件，并获取流信息 int ret = avformat_open_input(\u0026amp;inFormatCtx, inputName, NULL, NULL); // 如果打开输入文件失败，返回错误信息 if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open input file \u0026#39;%s\u0026#39;\\n\u0026#34;, inputName); return -1; } // 获取码流信息 ret = avformat_find_stream_info(inFormatCtx, NULL); // 如果ret小于0，则打印错误信息 if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find stream info failed:%s\\n\u0026#34;, av_err2str(ret)); // 就算获取失败，也要关闭输入文件 avformat_close_input(\u0026amp;inFormatCtx); return -1; } // 如果获取成功，则打印信息 int audioIndex = av_find_best_stream(inFormatCtx, AVMEDIA_TYPE_AUDIO, -1, -1, NULL, 0); if (audioIndex \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find audio stream in the input file\\n\u0026#34;); avformat_close_input(\u0026amp;inFormatCtx); return -1; } if (audioIndex \u0026lt; 0) { // 输出错误信息，表示找不到最佳音频流 av_log(NULL, AV_LOG_ERROR, \u0026#34;find best stream failed, index is %d\\n\u0026#34;, audioIndex); avformat_close_input(\u0026amp;inFormatCtx); return -1; } // 打印音频信息 av_log(NULL, AV_LOG_INFO, \u0026#34;the audio index is %d\\n\u0026#34;, audioIndex); // 初始化AVPacket结构体 AVPacket *packet = av_packet_alloc(); if (!packet) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not allocate packet\\n\u0026#34;); avformat_close_input(\u0026amp;inFormatCtx); return -1; } // 存储音频流信息 输出文件 FILE *dest_fp = fopen(outputName, \u0026#34;wb\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open %s file failed\\n\u0026#34;, outputName); // 就算打不开文件也得关闭音频文件 avformat_close_input(\u0026amp;inFormatCtx); // 释放分配的AVPacket av_packet_free(\u0026amp;packet); return -1; } // 有许多PC数据，所以需要循环读取 while (av_read_frame(inFormatCtx, packet) == 0) { // 检查当前包是否属于音频流 if (packet-\u0026gt;stream_index == audioIndex) { // 将音频数据写入输出文件 fwrite(packet-\u0026gt;data, 1, packet-\u0026gt;size, dest_fp); // 检查写入是否成功 if (ret != packet-\u0026gt;size) { // 如果写入的数据大小不等于包的大小，则输出错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;write data failed\\n\u0026#34;); // 关闭输出文件 fclose(dest_fp); // 关闭输入文件 avformat_close_input(\u0026amp;inFormatCtx); // 释放整个结构体 av_packet_free(\u0026amp;packet); return -1; } } // 释放当前包的引用 av_packet_unref(packet); } // 检查输入格式上下文是否已初始化 if (inFormatCtx != NULL) { // 关闭输入文件 avformat_close_input(\u0026amp;inFormatCtx); } // 检查输出文件指针是否已初始化 if (dest_fp != NULL) { // 关闭输出文件 fclose(dest_fp); } if (packet != NULL) { // 释放AVPacket结构体 av_packet_free(\u0026amp;packet); } return 0; } aac音频格式分析 ADTS（Audio Data Transport Stream）和ADIF（Audio Data Interchange Format）是两种用于音频编码的容器格式，主要用于AAC（Advanced Audio Codec）音频编码。它们的主要区别在于数据流的组织方式和使用场景。\nADTS（Audio Data Transport Stream） 定义: ADTS是一种流式传输格式，适用于音频数据的实时传输，如广播、流媒体等。 结构: 每个ADTS帧都包含一个头信息，后面跟着音频数据。头信息中包含了帧的长度、采样率、声道数等信息。 特点: 自包含: 每个ADTS帧都是自包含的，可以独立解码。 流式传输: 适合流式传输，因为每个帧都可以独立处理。 头部信息: 每个帧的头部信息较大，可能会增加一些开销。 ADIF（Audio Data Interchange Format） 定义: ADIF是一种文件格式，适用于音频数据的存储和交换，如音频文件的存储。 结构: ADIF文件包含一个唯一的头信息，后面跟着所有的音频数据。头信息中包含了编码参数、采样率、声道数等信息。 特点: 单一头部: 整个文件只有一个头部信息，减少了冗余。 非流式: 不适合流式传输，因为需要整个文件的头信息才能开始解码。 存储和交换: 适合存储和交换音频数据，因为头部信息只出现一次，减少了文件大小。 总结 ADTS: 适用于流式传输，每个帧自包含，适合实时传输。 ADIF: 适用于文件存储和交换，整个文件只有一个头部信息，适合存储和交换音频数据。 选择哪种格式取决于具体的应用场景：如果需要实时传输音频数据，ADTS是更好的选择；如果需要存储或交换音频文件，ADIF更为合适。\n提取H264视频数据 流程 流程和提取aac文件一样\n操作步骤 函数名 打开媒体文件 avformat_open_input 获取码流信息 avformat_find_stream_info 获取音频流 av_find_best_stream 初始化 packet av_packet_alloc 读取 packet 数据 av_read_frame 释放 packet 数据 av_packet_unref 关闭媒体文件 avformat_close_input 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 #include \u0026lt;libavutil/avutil.h\u0026gt; #include \u0026lt;libavformat/avformat.h\u0026gt; int main(int argc, char **argv) { av_log_set_level(AV_LOG_DEBUG); if (argc \u0026lt; 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input\u0026gt; \u0026lt;output\u0026gt;\\n\u0026#34;, argv[0]); return -1; } const char *inFilename = argv[1]; const char *outFilename = argv[2]; AVFormatContext *inFmtCtx = NULL; int ret = avformat_open_input(\u0026amp;inFmtCtx, inFilename, NULL, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Open input format failed:%s\\n\u0026#34;, av_err2str(ret)); return -1; } ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Find stream info failed:%s\\n\u0026#34;, av_err2str(ret)); ret = -1; goto fail; } ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Find best stream failed:%s\\n\u0026#34;, av_err2str(ret)); ret = -1; goto fail; } int videoIndex = ret; FILE *dest_fp = fopen(outFilename, \u0026#34;wb\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Open output file failed:%s\\n\u0026#34;, outFilename); ret = -1; goto fail; } AVPacket *packet = av_packet_alloc(); while (av_read_frame(inFmtCtx, packet) == 0) { if (packet-\u0026gt;stream_index == videoIndex) { int writeSize = fwrite(packet-\u0026gt;data, 1, packet-\u0026gt;size, dest_fp); if (writeSize != packet-\u0026gt;size) { // 这里不能释放整个packet，只能释放packet中的data，因为循环之后还会用到packet av_packet_unref(packet); ret = -1; break; } } av_packet_free(\u0026amp;packet); } fclose(dest_fp); fail: if(inFmtCtx != NULL) { avformat_close_input(\u0026amp;inFmtCtx); } if(dest_fp != NULL) { fclose(dest_fp); } return ret; } 成功运行，要用avi格式的视频文件\n如果想提取mp4格式的文件，需要进行以下步骤\nmp4→h264 流程 函数名 描述 av_bsf_get_by_name 根据名称获取比特流过滤器 av_bsf_alloc 分配比特流过滤器上下文 avcodec_parameters_copy 复制编解码器参数 av_bsf_init 初始化比特流过滤器 av_bsf_send_packet 发送数据包到比特流过滤器 av_bsf_receive_packet 从比特流过滤器接收处理后的数据包 av_bsf_free 释放比特流过滤器上下文及相关资源 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 #include \u0026lt;libavutil/avutil.h\u0026gt; #include \u0026lt;libavformat/avformat.h\u0026gt; #include \u0026lt;libavcodec/bsf.h\u0026gt; int main(int argc, char **argv) { av_log_set_level(AV_LOG_DEBUG); if (argc \u0026lt; 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input\u0026gt; \u0026lt;output\u0026gt;\\n\u0026#34;, argv[0]); return -1; } const char *inFilename = argv[1]; const char *outFilename = argv[2]; AVFormatContext *inFmtCtx = NULL; int ret = avformat_open_input(\u0026amp;inFmtCtx, inFilename, NULL, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Open input format failed:%s\\n\u0026#34;, av_err2str(ret)); return -1; } ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Find stream info failed:%s\\n\u0026#34;, av_err2str(ret)); ret = -1; goto fail; } ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Find best stream failed:%s\\n\u0026#34;, av_err2str(ret)); ret = -1; goto fail; } int videoIndex = ret; FILE *dest_fp = fopen(outFilename, \u0026#34;wb+\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Open output file failed:%s\\n\u0026#34;, outFilename); ret = -1; goto fail; } AVPacket *packet = av_packet_alloc(); const AVBitStreamFilter *bsf = av_bsf_get_by_name(\u0026#34;h264_mp4toannexb\u0026#34;); if(bsf == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;get h264_mp4toannexb bsf failed\\n\u0026#34;); ret = -1; goto fail; } AVBSFContext *bsfCtx = NULL; av_bsf_alloc(bsf, \u0026amp;bsfCtx); avcodec_parameters_copy(bsfCtx-\u0026gt;par_in, inFmtCtx-\u0026gt;streams[videoIndex]-\u0026gt;codecpar); av_bsf_init(bsfCtx); while (av_read_frame(inFmtCtx, packet) == 0) { if (packet-\u0026gt;stream_index == videoIndex) { if(av_bsf_send_packet(bsfCtx, packet) == 0) { while(av_bsf_receive_packet(bsfCtx, packet) == 0) { int writeSize = fwrite(packet-\u0026gt;data, 1, packet-\u0026gt;size, dest_fp); if (writeSize != packet-\u0026gt;size) { // 这里不能释放整个packet，只能释放packet中的data，因为循环之后还会用到packet av_packet_unref(packet); ret = -1; break; } } } } av_packet_free(\u0026amp;packet); } fclose(dest_fp); fail: if(inFmtCtx != NULL) { avformat_close_input(\u0026amp;inFmtCtx); } if(bsfCtx != NULL) { av_bsf_free(\u0026amp;bsfCtx); } if(dest_fp != NULL) { fclose(dest_fp); } return ret; } 转封装-mp4转flv I帧，P帧，B帧 I帧：帧内编码帧（Intra picture），I帧通常是一个GOP的第一帧，经过轻度地压缩，作为随机访问的参考点，可以当成静态图像，I帧压缩可去掉视频的空间冗余信息。\nP帧：前向预测编码帧（predictive frame），通过将图像序列中前面已编码帧的时间冗余信息充分去除来压缩传输数据量的编码图像，也称为预测帧。\nB帧：双向预测内插编码帧，既考虑源图像序列前面的已编码帧，又顾及源图像序列后面的已编码帧之间的时间冗余信息，来压缩传输数据量的编码图像，也称为双向预测帧\nPTS-显示时间戳\nDTS-解码时间戳\n流程 步骤 对应函数 打开输入媒体文件 avformat_open_input 获取输入流信息 avformat_find_stream_info 创建输出流上下文 avformat_alloc_output_context2 创建输出码流的AVStream avformat_new_stream 拷贝编码参数 avcodec_parameters_copy 写入视频文件头 avformat_write_header 读取输入视频流 av_read_frame 计算pts/dts/duration av_rescale_q_rnd/av_rescale_q 写入视频流数据 av_interleaved_write_frame 写入视频文件末尾 av_write_trailer 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 #include \u0026lt;libavutil/avutil.h\u0026gt; #include \u0026lt;libavformat/avformat.h\u0026gt; int main(int argc, char **argv) { av_log_set_level(AV_LOG_DEBUG); if (argc \u0026lt; 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;infileName\u0026gt; \u0026lt;outfileName\u0026gt;\\n\u0026#34;, argv[0]); return -1; } const char *inFileName = argv[1]; const char *outFileName = argv[2]; AVFormatContext *inFmtCtx = NULL; int ret = avformat_open_input(\u0026amp;inFmtCtx, inFileName, NULL, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input format failed:%s\\n\u0026#34;, av_err2str(ret)); return -1; } ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find input stream failed:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } AVFormatContext *outFmtCtx = NULL; // 分配输出格式上下文 ret = avformat_alloc_output_context2(\u0026amp;outFmtCtx, NULL, NULL, outFileName); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;alloc output format failed:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } // 输入文件的流数量 int streamCount = inFmtCtx-\u0026gt;nb_streams; // 分配一个整数数组，用于存储输入流索引到输出流索引的映射关系，并将其初始化为零 int *handleStreamIndexArray = av_malloc_array(streamCount, sizeof(int)); if (handleStreamIndexArray == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;malloc handle stream index array failed\\n\u0026#34;); goto fail; } int streamIndex = 0; // 用于多媒体处理的循环，主要功能是将输入文件中的音视频流复制到输出文件中 for (int i = 0; i \u0026lt; streamCount; i++) { // 获取输入文件的流 AVStream *inStream = inFmtCtx-\u0026gt;streams[i]; // 判断流的类型（视频，音频或字幕） if (inStream-\u0026gt;codecpar-\u0026gt;codec_type != AVMEDIA_TYPE_VIDEO \u0026amp;\u0026amp; inStream-\u0026gt;codecpar-\u0026gt;codec_type != AVMEDIA_TYPE_AUDIO \u0026amp;\u0026amp; inStream-\u0026gt;codecpar-\u0026gt;codec_type != AVMEDIA_TYPE_SUBTITLE) { // 不处理该流 handleStreamIndexArray[i] = -1; continue; } handleStreamIndexArray[i] = streamIndex++; // 创建新的输出流 AVStream *outStream = NULL; // 在输出文件中创建一个新的流 outStream = avformat_new_stream(outFmtCtx, NULL); if (outStream == NULL) { ret = -1; av_log(NULL, AV_LOG_ERROR, \u0026#34;new output stream failed\\n\u0026#34;); goto fail; } // 复制编解码器参数 avcodec_parameters_copy(outStream-\u0026gt;codecpar, inStream-\u0026gt;codecpar); // 设置输出流的编解码器标签为0 outStream-\u0026gt;codecpar-\u0026gt;codec_tag = 0; } // 判断outFmtCtx-\u0026gt;oformat-\u0026gt;flags是否包含AVFMT_NOFILE标志 [\u0026amp;解释（点击跳转）](https://www.notion.so/if-outFmtCtx-oformat-flags-AVFMT_NOFILE-1187c25c79d08036bde1c286d0b3c943?pvs=21) if (!(outFmtCtx-\u0026gt;oformat-\u0026gt;flags \u0026amp; AVFMT_NOFILE)) { // 以写入模式打开 ret = avio_open(\u0026amp;outFmtCtx-\u0026gt;pb, outFileName, AVIO_FLAG_WRITE); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open output file failed:%s\\n\u0026#34;, outFileName); goto fail; } } // 将输出文件的头部信息写入到输出文件中 ret = avformat_write_header(outFmtCtx, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;write header failed:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } AVPacket *packet = av_packet_alloc(); // 读取输入文件的数据包 while (av_read_frame(inFmtCtx, packet) == 0) { if (packet-\u0026gt;stream_index \u0026gt;= streamCount || handleStreamIndexArray[packet-\u0026gt;stream_index == -1]) { av_packet_unref(packet); } // 获取输入输出文件中对应流索引的流 AVStream *inStream = inFmtCtx-\u0026gt;streams[packet-\u0026gt;stream_index]; AVStream *outStream = outFmtCtx-\u0026gt;streams[packet-\u0026gt;stream_index]; packet-\u0026gt;stream_index = handleStreamIndexArray[packet-\u0026gt;stream_index]; packet-\u0026gt;pts = av_rescale_q(packet-\u0026gt;pts, inStream-\u0026gt;time_base, outStream-\u0026gt;time_base); packet-\u0026gt;dts = av_rescale_q(packet-\u0026gt;dts, inStream-\u0026gt;time_base, outStream-\u0026gt;time_base); packet-\u0026gt;duration = av_rescale_q(packet-\u0026gt;duration, inStream-\u0026gt;time_base, outStream-\u0026gt;time_base); // 将数据包的位置设置为-1 packet-\u0026gt;pos = -1; ret = av_interleaved_write_frame(outFmtCtx, packet); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;write interleaved failed:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } av_packet_unref(packet); } ret = av_write_trailer(outFmtCtx); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;write trailer failed :%s\\n\u0026#34;, av_err2str(ret)); } fail: if (inFmtCtx) { avformat_close_input(\u0026amp;inFmtCtx); } if (outFmtCtx \u0026amp;\u0026amp; !(outFmtCtx-\u0026gt;oformat-\u0026gt;flags \u0026amp; AVFMT_NOFILE)) { avio_closep(\u0026amp;outFmtCtx-\u0026gt;pb); } if (outFmtCtx) { avformat_free_context(outFmtCtx); } if (handleStreamIndexArray) { av_freep(\u0026amp;handleStreamIndexArray); } return ret; } 截取封装文件 时间基与时间戳 时间基：时间刻度，表示每个刻度多少秒（就像一把尺子的刻度）\n时间戳：表示占多少个时间刻度，单位不是秒，而是时间刻度（多少多少cm）\n时间基和时间戳相乘就是时间\nPTS：显示时间戳，在什么时候开始显示这一帧数据，转成时间：PTS * 时间基\nDTS：解码时间戳，在什么时候开始解码这一帧数据，转成时间：DTS * 时间基\n流程 截取封装文件处理流程和转封装流程几乎一样，只是多了一个跳转指定时间戳的步骤。以下是详细流程：\n步骤 对应函数 1. 打开输入媒体文件 avformat_open_input 2. 获取输入流信息 avformat_find_stream_info 3. 创建输出流上下文 avformat_alloc_output_context2 4. 创建输出码流的AVStream avformat_new_stream 5. 拷贝编码参数 avcodec_parameters_copy 6. 写入视频文件头 avformat_write_header 7. 读取输入视频流 av_read_frame 8. 跳转指定时间戳 av_seek_frame 9. 计算pts/dts/duration av_rescale_q_rnd/av_rescale_q 10. 写入视频流数据 av_interleaved_write_frame 11. 写入视频文件末尾 av_write_trailer 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 #include \u0026lt;libavutil/avutil.h\u0026gt; #include \u0026lt;libavformat/avformat.h\u0026gt; #include \u0026lt;libavcodec/avcodec.h\u0026gt; int main(int argc, char **argv) { // 设置日志级别 av_log_set_level(AV_LOG_INFO); if (argc \u0026lt; 2) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage:%s \u0026lt;infileName\u0026gt;\\n\u0026#34;, argv[0]); } const char *inFileName = argv[1]; // 打开输入文件 AVFormatContext *inFmtCtx = NULL; // 用于存储输入文件的格式信息 avformat_open_input(\u0026amp;inFmtCtx, inFileName, NULL, NULL); // 打开输入文件inFileName，并将格式信息存储在inFmtCtx中 avformat_find_stream_info(inFmtCtx, NULL); // 查找输入文件的流信息，并将流信息存储在inFmtCtx中 av_dump_format(inFmtCtx, 0, inFileName, 0); // 打印输入文件inFileName的格式信息 av_log(NULL, AV_LOG_INFO, \u0026#34;input file duration:%ld us, %lf s \\n\u0026#34;, inFmtCtx-\u0026gt;duration, inFmtCtx-\u0026gt;duration * av_q2d(AV_TIME_BASE_Q)); // 打印输入文件的总时长，单位为微秒和秒 AV_TIME_BASE_Q是ffmpeg内部的时间基，值为{1, AV_TIME_BASE}，AV_TIME_BASE的值为1000000，即1秒 // AVRational是ffmpeg内部的时间基，值为{num, den}，num为分子，den为分母 AVRational videoTimeBase; AVRational audioTimeBase; for (int i = 0; i \u0026lt; inFmtCtx-\u0026gt;nb_streams; i++) // 遍历输入文件中的所有流 { AVStream *inStream = inFmtCtx-\u0026gt;streams[i]; // 获取输入文件中的第i个流 // 分别判断是否为音频或视频流 if (inStream-\u0026gt;codecpar-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO) { videoTimeBase = inStream-\u0026gt;time_base; av_log(NULL, AV_LOG_INFO, \u0026#34;video timebase:num = %d,den = %d\\n\u0026#34;, videoTimeBase.num, videoTimeBase.den); } else if (inStream-\u0026gt;codecpar-\u0026gt;codec_type == AVMEDIA_TYPE_AUDIO) { audioTimeBase = inStream-\u0026gt;time_base; av_log(NULL, AV_LOG_INFO, \u0026#34;audio timebase:num = %d,den = %d\\n\u0026#34;, audioTimeBase.num, audioTimeBase.den); } } AVPacket *packet = av_packet_alloc(); // 分配一个AVPacket结构体，用于存储解码后的数据 while (av_read_frame(inFmtCtx, packet) \u0026gt;= 0) // 循环读取输入文件中的每个数据包，并将数据包存储在packet中 { AVStream *inStream = inFmtCtx-\u0026gt;streams[packet-\u0026gt;stream_index]; // 获取当前数据包所属的流 av_log(NULL, AV_LOG_INFO, \u0026#34;streamIndex = %d,pts = %ld,ptsTime = %lf,dts = %ld,dtsTime = %lf\\n\u0026#34;, packet-\u0026gt;stream_index, packet-\u0026gt;pts, packet-\u0026gt;pts * av_q2d(inStream-\u0026gt;time_base), packet-\u0026gt;dts, packet-\u0026gt;dts * av_q2d(inStream-\u0026gt;time_base)); // 打印当前数据包的流索引、pts、pts时间、dts、dts时间 } return 0; } 视频解码 如何使用ffmpeg接口对视频解码\nRGB介绍 三原色：RGB色彩模式是工业界的一种颜色标准，是通过对红(R)、绿(G)、蓝(B)三个颜色通道的变化以及它们相互之间的叠加来得到各式各样的颜色的，RGB即是代表红、绿、蓝三个通道的颜色，这个标准几乎包括了人类视力所能感知的所有颜色，是目前运用最广的颜色系统之一。\n显示器：使用RGB三种颜色的发光体作为基本发光单元\n分辨率：手机屏幕分辨率是1280*720，表示屏幕上有1280*720个像素点，每个像素点由RGB三种颜色组成\nRGB格式 调色版：通过编号映射到颜色的一张二维表，如01索引，表示红色 索引格式： RGB1、RGB4、RGB8 是计算机图形学中常见的颜色编码格式，它们代表了不同的颜色深度和存储方式。以下是对这些格式的解释：\nRGB1：\n颜色深度：1位（bit）。 颜色数量：2种颜色（通常是黑色和白色）。 应用场景：常用于早期的单色显示器或简单的图形界面，如文本模式下的显示。 RGB4：\n颜色深度：4位（bit）。 颜色数量：16种颜色。 应用场景：常用于早期的彩色显示器或低分辨率图形界面，如早期的计算机游戏或简单的图形应用程序。 RGB8：\n颜色深度：8位（bit）。 颜色数量：256种颜色。 应用场景：常用于早期的彩色显示器或低分辨率图形界面，如早期的计算机游戏、网页设计中的调色板模式等。 这些格式在现代计算机图形处理中已经较少使用，但在某些特定的应用场景或历史研究中仍然具有参考价值。 像素格式：。。。（后续觉得有必要再补上）\n命令\nffmpeg命令将图片转RGB数据\n1 ffmpeg -i input.png -pix_fmt rgb24 output.rgb 注意输出信息中会输出图片大小，下面的ffplay需要用\n1 Stream #0:0: Video: png, rgba(pc, gbr/bt709/iec61966-2-1), 1920x1200 [SAR 5669:5669 DAR 8:5], 25 fps, 25 tbr, 25 tbn ffplay命令播放RGB数据\n1 ffplay -f output.rgb -pix_fmt rgb24 -s widthxheight output.rgb 其中，width 和 height 是图片的宽度和高度，是必要的信息。\n通过解码，会发现照片内存明显变大，因为RGB格式存储了更多的颜色信息，所以我们需要对照片进行编码\nYUV介绍 YUV 是一种颜色编码系统，常用于视频和图像处理中。Y 代表亮度（Luminance），U 和 V 代表色度（Chrominance）。YUV 格式有多种变体，如 YUV420、YUV422、YUV444 等。\n流程 函数名 描述 av_find_best_stream 在媒体文件中查找最佳流 avcodec_alloc_context3 分配一个编解码器上下文 avcodec_parameters_to_context 复制编解码器参数 avcodec_find_decoder 查找并获取视频解码器 avcodec_open2 打开解码器上下文，并与指定的解码器关联 av_read_frame 读取帧 avcodec_send_packet 发送数据包到解码器 avcodec_receive_frame 从解码器接收帧 输入指令\n1 2 ./demoBin ../video/test.mp4 test.yuv ffplay test.yuv -video_size 720x1280 -pixel_format yuv420p 如果播放的视频乱码，主要是由于width和linesize大小不一样 后续的更改视频格式的时候会解决这个问题\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; #include \u0026#34;libavcodec/avcodec.h\u0026#34; // 定义一个全局变量，用于记录解码的帧数 int frameCount = 0; // 解码视频帧的函数 int decodeVideo(AVCodecContext *codecCtx, AVPacket *packet, FILE *dest_fp) { // 将数据包发送到解码器 int ret = avcodec_send_packet(codecCtx, packet); if (ret != 0) { // 如果发送失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not send packet:%s\\n\u0026#34;, av_err2str(ret)); return -1; } // 分配一个AVFrame结构体，用于存储解码后的帧数据 AVFrame *frame = av_frame_alloc(); // 循环接收解码后的帧数据 while (avcodec_receive_frame(codecCtx, frame) == 0) { // 将帧数据写入输出文件 fwrite(frame-\u0026gt;data[0], 1, codecCtx-\u0026gt;width * codecCtx-\u0026gt;height, dest_fp); fwrite(frame-\u0026gt;data[1], 1, codecCtx-\u0026gt;width * codecCtx-\u0026gt;height / 4, dest_fp); fwrite(frame-\u0026gt;data[2], 1, codecCtx-\u0026gt;width * codecCtx-\u0026gt;height / 4, dest_fp); // 增加帧计数 frameCount++; // 记录当前帧数 av_log(NULL, AV_LOG_INFO, \u0026#34;frameCount:%d\\n\u0026#34;, frameCount); } // 如果帧数据不为空，释放帧内存 if (frame) { av_frame_free(\u0026amp;frame); } return 0; } int main(int argc, char **argv) { // 设置日志级别为调试模式 av_log_set_level(AV_LOG_DEBUG); // 检查命令行参数是否正确 if (argc \u0026lt; 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input\u0026gt; \u0026lt;output\u0026gt;\\n\u0026#34;, argv[0]); return -1; } // 获取输入和输出文件名 const char *inFileName = argv[1]; const char *outFileName = argv[2]; // 定义一个AVFormatContext结构体，用于存储输入文件的格式信息 AVFormatContext *inFmtCtx = NULL; // 打开输入文件 int ret = avformat_open_input(\u0026amp;inFmtCtx, inFileName, NULL, NULL); if (ret != 0) { // 如果打开失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open input file %s\\n\u0026#34;, inFileName); return -1; } // 获取输入文件的流信息 ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret \u0026lt; 0) { // 如果获取失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find stream information:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } // 查找最佳的视频流索引 ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { // 如果查找失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find best stream index:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } // 获取视频流的索引 int videoIndex = ret; // 分配一个AVCodecContext结构体，用于存储解码器上下文信息 AVCodecContext *codecCtx = avcodec_alloc_context3(NULL); if (codecCtx == NULL) { // 如果分配失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not allocate codec context\\n\u0026#34;); ret = -1; goto fail; } // 将流参数复制到解码器上下文 avcodec_parameters_to_context(codecCtx, inFmtCtx-\u0026gt;streams[videoIndex]-\u0026gt;codecpar); // 查找解码器 const AVCodec *decoder = avcodec_find_decoder(codecCtx-\u0026gt;codec_id); if (decoder == NULL) { // 如果查找失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find codec\\n\u0026#34;); ret = -1; goto fail; } // 打开解码器 ret = avcodec_open2(codecCtx, decoder, NULL); if (ret != 0) { // 如果打开失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open codec:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } // 打开输出文件 FILE *dest_fp = fopen(outFileName, \u0026#34;wb+\u0026#34;); if (dest_fp == NULL) { // 如果打开失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open output file %s\\n\u0026#34;, outFileName); ret = -1; goto fail; } // 分配一个AVPacket结构体，用于存储数据包 AVPacket *packet = av_packet_alloc(); // 分配一个AVFrame结构体，用于存储解码后的帧数据 AVFrame *frame = av_frame_alloc(); // 循环读取输入文件中的数据包 while (av_read_frame(inFmtCtx, packet) \u0026gt;= 0) { // 如果数据包属于视频流ff if (packet-\u0026gt;stream_index == videoIndex) { // 解码视频帧 if (decodeVideo(codecCtx, packet, dest_fp) == -1) { ret = -1; av_packet_unref(packet); goto fail; } // 释放数据包引用 av_packet_unref(packet); } } // 刷新解码器，确保所有帧都被解码 decodeVideo(codecCtx, NULL, dest_fp); fail: // 如果输入文件格式上下文不为空，关闭输入文件 if (inFmtCtx) { avformat_close_input(\u0026amp;inFmtCtx); } // 如果解码器上下文不为空，释放解码器上下文 if (codecCtx) { avcodec_free_context(\u0026amp;codecCtx); } // 如果输出文件指针不为空，关闭输出文件 if (dest_fp) { fclose(dest_fp); } return ret; } 更改视频格式 流程 函数名 描述 av_parse_video_size 解析视频尺寸字符串（如 \u0026ldquo;1920x1080\u0026rdquo;）并返回宽度和高度。 sws_getContext 创建一个 SwsContext，用于图像缩放和格式转换。 av_frame_alloc 分配一个 AVFrame 结构体，用于存储解码后的视频帧。 av_image_get_buffer_size 计算给定图像格式和尺寸所需的缓冲区大小。 av_malloc 分配内存，用于存储图像数据。 av_image_fill_arrays 将图像数据填充到 AVFrame 的缓冲区中，并设置相关的行大小和数据指针。 sws_scale 使用 SwsContext 对图像进行缩放或格式转换。 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libswscale/swscale.h\u0026#34; #include \u0026#34;libavutil/parseutils.h\u0026#34; #include \u0026#34;libavutil/imgutils.h\u0026#34; // 定义一个全局变量，用于记录解码的帧数 int frameCount = 0; // 解码视频帧的函数 int decodeVideo(AVCodecContext *codecCtx, AVPacket *packet, struct SwsContext *swsCtx, int destWidth, int destHeight, AVFrame *destFrame, FILE *dest_fp) { // 将数据包发送到解码器 int ret = avcodec_send_packet(codecCtx, packet); if (ret != 0) { // 如果发送失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not send packet:%s\\n\u0026#34;, av_err2str(ret)); return -1; } // 分配一个AVFrame结构体，用于存储解码后的帧数据 AVFrame *frame = av_frame_alloc(); // 循环接收解码后的帧数据 while (avcodec_receive_frame(codecCtx, frame) == 0) { sws_scale(swsCtx, (const uint8_t *const*)frame-\u0026gt;data, frame-\u0026gt;linesize, 0, codecCtx-\u0026gt;height, destFrame-\u0026gt;data, destFrame-\u0026gt;linesize); // 将帧数据写入输出文件 fwrite(destFrame-\u0026gt;data[0], 1, destWidth * destHeight, dest_fp); fwrite(destFrame-\u0026gt;data[1], 1, destWidth * destHeight / 4, dest_fp); fwrite(destFrame-\u0026gt;data[2], 1, destWidth * destHeight / 4, dest_fp); // 增加帧计数 frameCount++; // 记录当前帧数 av_log(NULL, AV_LOG_INFO, \u0026#34;frameCount:%d\\n\u0026#34;, frameCount); // 输出宽高信息,linesize0 1 2 av_log(NULL, AV_LOG_INFO, \u0026#34;width:%d,height:%d,linesize0:%d,linesize1:%d,linesize2:%d\\n\u0026#34;, destWidth, destHeight, destFrame-\u0026gt;linesize[0], destFrame-\u0026gt;linesize[1], destFrame-\u0026gt;linesize[2]); } // 如果帧数据不为空，释放帧内存 if (frame) { av_frame_free(\u0026amp;frame); } return 0; } int main(int argc, char **argv) { // 设置日志级别为调试模式 av_log_set_level(AV_LOG_DEBUG); // 检查命令行参数是否正确 if (argc \u0026lt; 4) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input\u0026gt; \u0026lt;output\u0026gt; \u0026lt;width*height\u0026gt;\\n\u0026#34;, argv[0]); return -1; } // 获取输入和输出文件名 const char *inFileName = argv[1]; const char *outFileName = argv[2]; const char *destVideoSizeString = argv[3]; int destWidth = 0, destHeight = 0; int ret = av_parse_video_size(\u0026amp;destWidth, \u0026amp;destHeight, destVideoSizeString); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;invalid video size:%s\\n\u0026#34;, destVideoSizeString); return -1; } av_log(NULL, AV_LOG_INFO, \u0026#34;destWith:%d,destHeight:%d\\n\u0026#34;, destWidth, destHeight); // 定义一个AVFormatContext结构体，用于存储输入文件的格式信息 AVFormatContext *inFmtCtx = NULL; // 打开输入文件 ret = avformat_open_input(\u0026amp;inFmtCtx, inFileName, NULL, NULL); if (ret != 0) { // 如果打开失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open input file %s\\n\u0026#34;, inFileName); return -1; } // 获取输入文件的流信息 ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret \u0026lt; 0) { // 如果获取失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find stream information:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } // 查找最佳的视频流索引 ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { // 如果查找失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find best stream index:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } // 获取视频流的索引 int videoIndex = ret; // 分配一个AVCodecContext结构体，用于存储解码器上下文信息 AVCodecContext *codecCtx = avcodec_alloc_context3(NULL); if (codecCtx == NULL) { // 如果分配失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not allocate codec context\\n\u0026#34;); ret = -1; goto fail; } // 将流参数复制到解码器上下文 avcodec_parameters_to_context(codecCtx, inFmtCtx-\u0026gt;streams[videoIndex]-\u0026gt;codecpar); // 查找解码器 const AVCodec *decoder = avcodec_find_decoder(codecCtx-\u0026gt;codec_id); if (decoder == NULL) { // 如果查找失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not find codec\\n\u0026#34;); ret = -1; goto fail; } // 打开解码器 ret = avcodec_open2(codecCtx, decoder, NULL); if (ret != 0) { // 如果打开失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open codec:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } enum AVPixelFormat destPixfmt = codecCtx-\u0026gt;pix_fmt; struct SwsContext *swsCtx = sws_getContext(codecCtx-\u0026gt;width, codecCtx-\u0026gt;height, codecCtx-\u0026gt;pix_fmt, destWidth, destHeight, destPixfmt, SWS_BICUBIC, NULL, NULL, NULL); if (swsCtx == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not create SwsContext\\n\u0026#34;); ret = -1; goto fail; } AVFrame *destFrame = av_frame_alloc(); uint8_t *outBuffer = av_malloc(av_image_get_buffer_size(destPixfmt, destWidth, destHeight, 1)); av_image_fill_arrays(destFrame-\u0026gt;data, destFrame-\u0026gt;linesize, outBuffer, destPixfmt, destWidth, destHeight, 1); // 打开输出文件 FILE *dest_fp = fopen(outFileName, \u0026#34;wb+\u0026#34;); if (dest_fp == NULL) { // 如果打开失败，记录错误信息 av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open output file %s\\n\u0026#34;, outFileName); ret = -1; goto fail; } // 分配一个AVPacket结构体，用于存储数据包 AVPacket *packet = av_packet_alloc(); // 分配一个AVFrame结构体，用于存储解码后的帧数据 AVFrame *frame = av_frame_alloc(); // 循环读取输入文件中的数据包 while (av_read_frame(inFmtCtx, packet) \u0026gt;= 0) { // 如果数据包属于视频流 if (packet-\u0026gt;stream_index == videoIndex) { // 解码视频帧 // if (decodeVideo(codecCtx, packet, dest_fp) == -1) if (decodeVideo(codecCtx, packet, swsCtx, destWidth, destHeight, destFrame, dest_fp) == -1) { ret = -1; av_packet_unref(packet); goto fail; } // 释放数据包引用 av_packet_unref(packet); } } // 刷新解码器，确保所有帧都被解码 // decodeVideo(codecCtx, NULL, dest_fp); decodeVideo(codecCtx, NULL, swsCtx, destWidth, destHeight, destFrame, dest_fp); fail: // 如果输入文件格式上下文不为空，关闭输入文件 if (inFmtCtx) { avformat_close_input(\u0026amp;inFmtCtx); } // 如果解码器上下文不为空，释放解码器上下文 if (codecCtx) { avcodec_free_context(\u0026amp;codecCtx); } // 如果输出文件指针不为空，关闭输出文件 if (dest_fp) { fclose(dest_fp); } if (destFrame) { av_frame_free(\u0026amp;destFrame); } if (outBuffer) { av_free(outBuffer); } return ret; } 解码后的数据存储 解码后的视频数据通常存储在 data[0]、data[1]、data[2] 等数组中。具体来说：\ndata[0]: 存储了 linesize[0] * height 个数据。 data[1] 和 data[2]: 存储了其他平面的数据（如YUV格式中的U和V平面）。 内存对齐和 linesize linesize[0]: 实际上并不等于图像的宽度 width，而是比宽度大。 这种差异是由于内存对齐的需求，以及解码器的CPU和其他优化原因导致的。 sws_scale 函数功能 sws_scale 函数是 FFmpeg 中用于图像缩放和格式转换的核心函数。它主要完成以下功能：\n图像色彩空间转换：\n将图像从一种色彩空间转换为另一种色彩空间，例如从 RGB 转换为 YUV，或者从 YUV420P 转换为 YUV444P。 分辨率缩放：\n调整图像的分辨率，例如将 1920x1080 的图像缩放到 1280x720。 前后图像滤波处理：\n在进行缩放和色彩空间转换时，应用滤波器以平滑图像，减少锯齿和伪影。 BMP文件格式 概念：BMP文件格式，又称为Bitmap（位图）或是DIB（Device-Independent Device，设备无光位图），是Windows操作系统中的标准图像文件格式。由于它可以不作任何变换地保存图像像素域的数据，因此成为我们取得RAW数据的好来源。\n扫描方式：从左到右，从下到上\n文件组成：\n位图文件头（Bitmap File Header）：提供文件的格式，大小等信息 位图信息头（Bitmap Information）：提供图像的尺寸，位平面数，压缩方式，颜色索引等信息。 调色板（Color Palette）：可选，有些位图需要调色板，有些位图，比如真彩色图（24位的BMP）就不需要调色板。 位图数据（Bitmap Data）：图像数据区 文件头结构体：\n1 2 3 4 5 6 7 typedef struct tagBITMAPFILEHEADER { WORD bfType; // 文件类型，必须是0x424D，即字符“BM” DWORD bfSize; // bmp文件大小 WORD bfReserved1; // 保留字 WORD bfReserved2; // 保留字 DWORD bfOffBits; // 实际位图数据的偏移字节数，即前三个部分长度之和 } BITMAPFILEHEADER; 信息头结构体：\n1 2 3 4 5 6 7 8 9 10 11 12 13 typedef struct tagBITMAPINFOHEADER { DWORD biSize; //表示struct tagBITMAPINFOHEADER的长度，设为40 LONG biWidth; //bmp图片宽度 LONG biHeight; //bmp图片高度 WORD biPlanes; //bmp图片平面树，设为1 WORD biBitCount; //bmp图片位数，即1位图，4位图，8位图，24位图等 DWORD biCompression; //bmp图片压缩类型，0表示不压缩 DWORD biSizeImage; //bmp图片数据大小，必须是4的整数倍 LONG biXPelsPerMeter; //bmp图片水平分辨率 LONG biYPelsPerMeter; //bmp图片垂直分辨率 DWORD biClrUsed; //bmp图片实际使用的颜色表中的颜色数 DWORD biClrImportant; //bmp图片对显示有重要影响的颜色索引的数目 } BITMAPINFOHEADER; 视频编码（yuv到h264） 流程 函数名 描述 avcodec_find_encoder 查找编码器 avcodec_alloc_context3 创建编码器上下文 avcodec_open2 打开编码器 av_frame_alloc 分配帧内存 av_image_get_buffer_size 获取图像缓冲区大小 av_image_fill_arrays 填充图像数据数组 avcodec_send_frame 发送帧到编码器 avcodec_receive_packet 从编码器接收数据包 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026#34;libavutil/parseutils.h\u0026#34; #include \u0026lt;libavcodec/codec.h\u0026gt; #include \u0026lt;libavcodec/packet.h\u0026gt; #include \u0026lt;libavutil/frame.h\u0026gt; #include \u0026lt;libavutil/imgutils.h\u0026gt; #include \u0026lt;libavutil/log.h\u0026gt; #include \u0026lt;libavutil/rational.h\u0026gt; #include \u0026lt;time.h\u0026gt; int writePacketCount = 0; int encodeVideo(AVCodecContext *encoderCtx, AVFrame *frame, AVPacket *packet, FILE *dest_fp) { int ret = avcodec_send_frame(encoderCtx, frame); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;send frame error:%s\\n\u0026#34;, av_err2str(ret)); return -1; } while (ret \u0026gt;= 0) { avcodec_receive_packet(encoderCtx, packet); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) { return 0; } else if (ret \u0026lt; 0) { av_log(NULL,AV_LOG_ERROR,\u0026#34;encoder frrame failed:%s\\n\u0026#34;,av_err2str(ret)); return -1; } fwrite(packet-\u0026gt;data, 1, packet-\u0026gt;size, dest_fp); writePacketCount++; av_log(NULL,AV_LOG_INFO,\u0026#34;writePacketCount : %d\\n\u0026#34;,writePacketCount); av_packet_unref(packet); } } int main(int argc, char **argv) { av_log_set_level(AV_LOG_INFO); if (argc \u0026lt; 5) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;inFile\u0026gt; \u0026lt;outFile\u0026gt; \u0026lt;encodeName\u0026gt; \u0026lt;width x height\u0026gt;\\n\u0026#34;, argv[0]); return -1; } const char *inFileName = argv[1]; const char *outFileName = argv[2]; const char *encoderName = argv[3]; int width = 0, height = 0; int ret = av_parse_video_size(\u0026amp;width, \u0026amp;height, argv[4]); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Invalid size \u0026#39;%s\u0026#39;, must be in the form WxH or a valid size abbreviation\\n\u0026#34;, argv[4]); return -1; } enum AVPixelFormat pixFmt = AV_PIX_FMT_YUV420P; int fps = 30; const AVCodec *encoder = avcodec_find_encoder_by_name(encoderName); if (encoder == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find encoder %s failed\\n\u0026#34;, encoderName); return -1; } AVCodecContext *encoderCtx = avcodec_alloc_context3(encoder); if (encoderCtx == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;alloc encoder context failed!\\n\u0026#34;); return -1; } encoderCtx-\u0026gt;codec_type = AVMEDIA_TYPE_VIDEO; encoderCtx-\u0026gt;pix_fmt = pixFmt; encoderCtx-\u0026gt;width = width; encoderCtx-\u0026gt;height = height; encoderCtx-\u0026gt;time_base = (AVRational){1, fps}; encoderCtx-\u0026gt;bit_rate = 4096000; encoderCtx-\u0026gt;max_b_frames = 0; encoderCtx-\u0026gt;gop_size = 10; ret = avcodec_open2(encoderCtx, encoder, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open encoder failed! %s\\n\u0026#34;, av_err2str(ret)); goto end; } FILE *src_fp = fopen(inFileName, \u0026#34;rb\u0026#34;); if (src_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open infilename error\u0026#34;); ret = -1; goto end; } FILE *dest_fp = fopen(outFileName, \u0026#34;wb\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open outfilename error\u0026#34;); ret = -1; goto end; } AVFrame *frame = av_frame_alloc(); int frameSize = av_image_get_buffer_size(pixFmt, width, height, 1); uint8_t *frameBuffer = av_malloc(frameSize); av_image_fill_arrays(frame-\u0026gt;data, frame-\u0026gt;linesize, frameBuffer, pixFmt, width, height, 1); int pictureSize = width * height; AVPacket *packet = av_packet_alloc(); int readFrameCount = 0; while (fread(frameBuffer, 1, pictureSize * 3 / 2, src_fp) == pictureSize * 3 / 2) { // Y 1 U 1/4 V 1/4 frame-\u0026gt;data[0] = frameBuffer; frame-\u0026gt;data[1] = frameBuffer + pictureSize; frame-\u0026gt;data[2] = frameBuffer + pictureSize + pictureSize / 4; readFrameCount++; av_log(NULL, AV_LOG_INFO, \u0026#34;readFrameCount: %d\\n\u0026#34;, readFrameCount); encodeVideo(encoderCtx, frame, packet, dest_fp); } end: if (encoderCtx) { avcodec_free_context(\u0026amp;encoderCtx); } if (src_fp) { fclose(src_fp); } if (dest_fp) { fclose(dest_fp); } if (frameBuffer) { av_freep(\u0026amp;frameBuffer); } return ret; } 音频解码 PCM介绍 PCM（Pulse Code Modulation）是一种用于数字音频的标准编码格式。它通过将模拟音频信号转换为数字信号来表示音频数据。PCM 编码的基本原理是将模拟音频信号在时间上进行采样，并将每个采样点的幅度值量化为离散的数字值。\n核心过程：采样-\u0026gt;量化-\u0026gt;编码\nPCM关键要素 采样率（Sample Rate）：每秒采样的次数，常见的采样率有 44.1 kHz、48 kHz 等。 量化格式（Sample Format）：每个采样点的位数，常见的量化格式有 16 位、24 位等。 声道数（Channels）：音频信号的声道数，如单声道、立体声等。 PCM数据格式 存储格式\n双声道：采样数据按LRLR方式存储，即左声道和右声道交替存储，存储的时候与字节序有关。 单声道：采样数据按时间顺序存储（有时也会采用LRLR方式，但另一个声道数据为0）。 存储格式分为Packed和Planner两种，对于双通道音频，Packed为两个声道的数据交错存储;Planner为两个声道的数据分开存储。\nPacked：LRLRLR Planner：LLLRRR ffmpeg音频解码后的数据存放在AVFrame结构体中：\nPacked格式下，frame.data[0]存放所有声道的数据。 Planner格式下，frame.data[i]存放第i个声道的数据。 左声道data[0]:LLLL\u0026hellip; 右声道data[1]:RRRR\u0026hellip; Planner模式是ffmpeg内部存储模式，实际使用的音频文件都是Packed模式。\nPCM计算 大小计算：以CD的音质为例：量化格式为16比特（2字节），采样率为44100，声道数为2。 比特率为：16 * 44100 * 2 = 1378.125 kbps 每秒存储空间：1378.125 * 60/8/1024 = 10.09MB ffmpeg提取pcm数据命令： 1 ffmpeg -i input.aac -ar 48000 -ac 2 -f s16le output.pcm ffplay播放pcm数据命令： 1 ffplay -ar 48000 -ac 2 -f s16le output.pcm 通过上述指令播放不成功的话，可以尝试转换PCM文件\n1 2 ffmpeg -f s16le -ar 48000 -ac 2 -i output.pcm output_stereo.wav ffplay output_stereo.wav 流程 函数名 描述 avformat_open_input() 打开输入文件或流并读取头部信息。 avformat_find_stream_info() 读取一些数据包以获取流信息。 av_find_best_stream() 查找最佳流（音频、视频或字幕）。 avcodec_alloc_context3() 分配解码器上下文。 avcodec_parameters_to_context() 将流参数复制到解码器上下文中。 avcodec_find_decoder() 查找合适的解码器。 avcodec_open2() 打开解码器。 av_frame_alloc() 分配AVFrame结构体。 av_samples_get_buffer_size() 计算音频缓冲区的大小。 avcodec_fill_audio_frame() 填充音频帧的缓冲区。 av_read_frame() 从输入文件或流中读取数据包。 avcodec_send_packet() 将数据包发送到解码器进行解码。 avcodec_receive_frame() 从解码器接收解码后的帧。 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026lt;libavcodec/codec.h\u0026gt; #include \u0026lt;libavcodec/packet.h\u0026gt; #include \u0026lt;time.h\u0026gt; int decodeAudio(AVCodecContext *decoderCtx, AVPacket *packet, AVFrame *frame, FILE *dest_fp) { int ret = avcodec_send_packet(decoderCtx, packet); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;send packet to decoder failed: %s\\n\u0026#34;, av_err2str(ret)); return -1; } int channel = 0; while (ret \u0026gt;= 0) { ret = avcodec_receive_frame(decoderCtx, frame); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) { return 0; } else if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;decode packet failed: %s\\n\u0026#34;, av_err2str(ret)); return -1; } int dataSize = av_get_bytes_per_sample(decoderCtx-\u0026gt;sample_fmt); if (dataSize \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;get bytes per sample failed\\n\u0026#34;); return -1; } // frame fltp 2 /* data[0] L L L L data[1] R R R R --\u0026gt; L R L R L R L R */ for (int i = 0; i \u0026lt; frame-\u0026gt;nb_samples; i++) { for (channel = 0; channel \u0026lt; decoderCtx-\u0026gt;ch_layout.nb_channels; channel++) { fwrite(frame-\u0026gt;data[channel] + dataSize * i, 1, dataSize, dest_fp); } } } return 0; } int main(int argc, char **argv) { av_log_set_level(AV_LOG_DEBUG); if (argc \u0026lt; 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input\u0026gt; \u0026lt;output\u0026gt;\\n\u0026#34;, argv[0]); } const char *inFileName = argv[1]; const char *outFileName = argv[2]; AVFormatContext *inFmtCtx = NULL; int ret = avformat_open_input(\u0026amp;inFmtCtx, inFileName, NULL, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open %s failed\\n\u0026#34;, inFileName); return -1; } ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find stream error:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_AUDIO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find best stream error:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } int audioStreamIndex = ret; AVCodecContext *decoderCtx = avcodec_alloc_context3(NULL); if (decoderCtx == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;alloc codec context failed\\n\u0026#34;); goto fail; } ret = avcodec_parameters_to_context(decoderCtx, inFmtCtx-\u0026gt;streams[audioStreamIndex]-\u0026gt;codecpar); const AVCodec *decoder = avcodec_find_decoder(decoderCtx-\u0026gt;codec_id); if (decoder == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find decoder %d failed\\n\u0026#34;, decoderCtx-\u0026gt;codec_id); ret = -1; goto fail; } ret = avcodec_open2(decoderCtx, decoder, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open decoder error:%s\\n\u0026#34;, av_err2str(ret)); goto fail; } FILE *dest_fp = fopen(outFileName, \u0026#34;wb\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open %s failed\\n\u0026#34;, outFileName); ret = -1; goto fail; } AVFrame *frame = av_frame_alloc(); int frameSize = av_samples_get_buffer_size(NULL, decoderCtx-\u0026gt;ch_layout.nb_channels, frame-\u0026gt;nb_samples, decoderCtx-\u0026gt;sample_fmt, 1); uint8_t *frameBuffer = av_malloc(frameSize); avcodec_fill_audio_frame(frame, decoderCtx-\u0026gt;ch_layout.nb_channels, decoderCtx-\u0026gt;sample_fmt, frameBuffer, frameSize, 1); AVPacket *packet = av_packet_alloc(); while (av_read_frame(inFmtCtx, packet) \u0026gt;= 0) { if (packet-\u0026gt;stream_index == audioStreamIndex) { decodeAudio(decoderCtx, packet, frame, dest_fp); } av_packet_unref(packet); } decodeAudio(decoderCtx, NULL, frame, dest_fp); fail: if (inFmtCtx) { avformat_close_input(\u0026amp;inFmtCtx); } if (decoderCtx) { avcodec_free_context(\u0026amp;decoderCtx); } if (frame) { av_frame_free(\u0026amp;frame); } if (frameBuffer) { av_freep(frameBuffer); } if (dest_fp) { fclose(dest_fp); } return ret; } 运行指令\n1 2 3 4 5 ./demoBin ../video/test.aac ../video/test_decode_by_code.pcm ffmpeg -f f32le -ar 44100 -ac 2 -i ../video/test_decode_by_code.pcm ../video/test_decode_by_code_stereo.wav ffplay ../video/test_decode_by_code_stereo.wav 音频编码 流程 函数名 描述 av_frame_alloc 分配一个AVFrame结构体 av_frame_get_buffer 为AVFrame分配缓冲区 avcodec_find_encoder_by_name 根据名称查找编码器 avcodec_alloc_context3 分配编码器上下文 avcodec_open2 打开编码器 avcodec_send_frame 发送帧到编码器 avcodec_receive_packet 从编码器接收编码后的数据包 运行指令\n1 2 3 ffmpeg -ac 2 -ar 44100 -f s16le -i test.pcm -acodec libfdk_aac test1.aac ffplay test1.aac 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026lt;libavcodec/codec.h\u0026gt; #include \u0026lt;libavcodec/packet.h\u0026gt; #include \u0026lt;libavutil/channel_layout.h\u0026gt; #include \u0026lt;libavutil/error.h\u0026gt; #include \u0026lt;libavutil/log.h\u0026gt; #include \u0026lt;libavutil/frame.h\u0026gt; #include \u0026lt;libavutil/samplefmt.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;time.h\u0026gt; int encodeAudio(AVCodecContext *encoderCtx, AVFrame *frame, AVPacket *packet, FILE *dest_fp) { int ret = avcodec_send_frame(encoderCtx, frame); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;send frame to encoder failed:%s\\n\u0026#34;, av_err2str(ret)); return -1; } while (ret \u0026gt;= 0) { ret = avcodec_receive_packet(encoderCtx, packet); if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) { return 0; } else if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;receive packet from encoder failed:%s\\n\u0026#34;, av_err2str(ret)); return -1; } fwrite(packet-\u0026gt;data, 1, packet-\u0026gt;size, dest_fp); av_packet_unref(packet); } return 0; } int main(int argc, char **argv) { av_log_set_level(AV_LOG_INFO); if (argc \u0026lt; 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input file\u0026gt; \u0026lt;output file\u0026gt;\\n\u0026#34;, argv[0]); return -1; } const char *inFileName = argv[1]; const char *outFileName = argv[2]; AVFrame *frame = av_frame_alloc(); if (!frame) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not allocate video frame\\n\u0026#34;); return -1; } frame-\u0026gt;sample_rate = 44100; // 这里代码有些不同 frame-\u0026gt;ch_layout.nb_channels = 2; av_channel_layout_from_mask(\u0026amp;frame-\u0026gt;ch_layout, AV_CH_LAYOUT_STEREO); frame-\u0026gt;format = AV_SAMPLE_FMT_S16; frame-\u0026gt;nb_samples = 1024; av_frame_get_buffer(frame, 0); int ret = 0; const AVCodec *encoder = avcodec_find_encoder_by_name(\u0026#34;libfdk_aac\u0026#34;); if (!encoder) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find encoder failed\\n\u0026#34;); ret = -1; goto end; } AVCodecContext *encoderCtx = avcodec_alloc_context3(encoder); if (!encoderCtx) { av_log(NULL, AV_LOG_ERROR, \u0026#34;alloc encoder context failed\\n\u0026#34;); ret = -1; goto end; } encoderCtx-\u0026gt;sample_fmt = frame-\u0026gt;format; encoderCtx-\u0026gt;sample_rate = frame-\u0026gt;sample_rate; encoderCtx-\u0026gt;ch_layout.nb_channels = frame-\u0026gt;ch_layout.nb_channels; encoderCtx-\u0026gt;ch_layout = frame-\u0026gt;ch_layout; ret = avcodec_open2(encoderCtx, encoder, NULL); if (ret \u0026lt; 0) { av_log(NULL,AV_LOG_ERROR,\u0026#34;open encoder failed:%s\\n\u0026#34;,av_err2str(ret)); ret = -1; goto end; } FILE *src_fp = fopen(inFileName, \u0026#34;rb\u0026#34;); if (src_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input file failed\\n\u0026#34;); ret = -1; goto end; } FILE *dest_fp = fopen(outFileName, \u0026#34;wb+\u0026#34;); if (src_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open output file failed\\n\u0026#34;); ret = -1; goto end; } AVPacket *packet = av_packet_alloc(); while (1) { int readSize = fread(frame-\u0026gt;data[0], 1, frame-\u0026gt;linesize[0], src_fp); if (readSize == 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;finish read infile\\n\u0026#34;); break; } encodeAudio(encoderCtx, frame, packet, dest_fp); } encodeAudio(encoderCtx, NULL, packet, dest_fp); end: if (frame) { av_frame_free(\u0026amp;frame); } if (encoderCtx) { avcodec_free_context(\u0026amp;encoderCtx); } if (src_fp) { fclose(src_fp); } if (dest_fp) { fclose(dest_fp); } return ret; } 指令\n1 2 3 ./demoBin test.pcm aac_by_code.aac ffplay aac_by_code.aac 视频采集 视频采集命令 查看设备列表： 1 ffmpeg -hide_banner -devices 查看dshow支持的参数： 1 ffmpeg -h demuxer=dshow 查看dshow支持的设备： 1 ffmpeg -f dshow -list_devices true -i dummy 一般是Integrated Camera，这是本地摄像头\n采集摄像头画面： 1 ffmpeg -f dshow -i video=\u0026#34;Integrated Camera\u0026#34; ./video/output.mp4 播放摄像头采集画面：\n1 ffplay output.mp4 流程 函数名 描述 avdevice_register_all 注册所有可用的设备 avformat_alloc_context 分配格式上下文 av_dict_set 设置字典选项 av_find_input_format 查找输入格式 avformat_open_input 打开输入文件 avformat_find_stream_info 查找流信息 av_find_best_stream 查找最佳流 avcodec_alloc_context3 分配编解码器上下文 avcode_parameters_to_context 将参数复制到上下文 avcodec_find_decoder 查找解码器 avcodec_open2 打开编解码器 av_read_frame 读取帧 avcode_send_packet 发送数据包 avcodec_receive_frame 接收帧 颜色空间格式转换：\n函数名 描述 sws_getContext 获取缩放上下文 av_frame_alloc 分配帧 av_image_get_buffer_size 获取图像缓冲区大小 av_malloc 分配内存 av_image_fill_arrays 填充图像数组 sws_scale 缩放图像 先用ffmpeg指令试一下视频采集格式，后续代码写的时候要用对应采集的格式。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libavdevice/avdevice.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026#34;libavutil/imgutils.h\u0026#34; #include \u0026#34;libswscale/swscale.h\u0026#34; #include \u0026lt;libavcodec/packet.h\u0026gt; #include \u0026lt;libavutil/dict.h\u0026gt; #include \u0026lt;libavutil/frame.h\u0026gt; #include \u0026lt;libavutil/log.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;time.h\u0026gt; // 显示可用的摄像头设备 // ffmpeg -f dshow -list_devices true -i dummy void dshowListDevices() { const AVInputFormat *inFmt = av_find_input_format(\u0026#34;dshow\u0026#34;); if (inFmt == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find dshow failed!\\n\u0026#34;); } // 设置参数 AVDictionary *options = NULL; av_dict_set(\u0026amp;options, \u0026#34;list_devices\u0026#34;, \u0026#34;true\u0026#34;, 0); AVFormatContext *inFmtCtx = avformat_alloc_context(); // 第二个参数是URL int ret = avformat_open_input(\u0026amp;inFmtCtx, \u0026#34;video=Integrated Camera\u0026#34;, inFmt, \u0026amp;options); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input format failed:%s\\n\u0026#34;, av_err2str(ret)); return; } if (inFmtCtx) { avformat_close_input(\u0026amp;inFmtCtx); avformat_free_context(inFmtCtx); } } void decodeVideo(struct SwsContext *swsCtx, AVCodecContext *decoderCtx, AVFrame *destFrame, AVPacket *packet, FILE *dest_fp) { if (avcodec_send_packet(decoderCtx, packet) == 0) { AVFrame *frame = av_frame_alloc(); while (avcodec_receive_frame(decoderCtx, frame) \u0026gt;= 0) { sws_scale(swsCtx, (const uint8_t *const *)frame-\u0026gt;data, frame-\u0026gt;linesize, 0, decoderCtx-\u0026gt;height, destFrame-\u0026gt;data, destFrame-\u0026gt;linesize); fwrite(destFrame-\u0026gt;data[0], 1, decoderCtx-\u0026gt;width * decoderCtx-\u0026gt;height, dest_fp); fwrite(destFrame-\u0026gt;data[1], 1, decoderCtx-\u0026gt;width * decoderCtx-\u0026gt;height / 4, dest_fp); fwrite(destFrame-\u0026gt;data[2], 1, decoderCtx-\u0026gt;width * decoderCtx-\u0026gt;height / 4, dest_fp); } av_frame_free(\u0026amp;frame); } } int main(int argc, char *argv[]) { av_log_set_level(AV_LOG_INFO); if (argc \u0026lt; 2) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage:%s \u0026lt;outFileName\u0026gt; \\n\u0026#34;, argv[0]); return -1; } const char *outFileName = argv[1]; avdevice_register_all(); dshowListDevices(); AVFormatContext *inFmtCtx = avformat_alloc_context(); const AVInputFormat *inFmt = av_find_input_format(\u0026#34;dshow\u0026#34;); if (inFmt == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input format failed!\\n\u0026#34;); goto end; } AVDictionary *options = NULL; av_dict_set(\u0026amp;options, \u0026#34;framerate\u0026#34;, \u0026#34;30\u0026#34;, 0); int ret = avformat_open_input(\u0026amp;inFmtCtx, \u0026#34;video=Integrated Camera\u0026#34;, inFmt, \u0026amp;options); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find stream info failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find best stream failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } int videoIndex = ret; // 创建解码器上下文 AVCodecContext *decoderCtx = avcodec_alloc_context3(NULL); ret = avcodec_parameters_to_context(decoderCtx, inFmtCtx-\u0026gt;streams[videoIndex]-\u0026gt;codecpar); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;copy parameters to context failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } const AVCodec *decoder = avcodec_find_decoder(decoderCtx-\u0026gt;codec_id); if (decoder == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find decoder failed!\\n\u0026#34;); ret = -1; goto end; } ret = avcodec_open2(decoderCtx, decoder, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open decoder failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } AVFrame *destFrame = av_frame_alloc(); enum AVPixelFormat destPixFmt = AV_PIX_FMT_YUV420P; uint8_t *outBuffer = av_malloc(av_image_get_buffer_size(destPixFmt, decoderCtx-\u0026gt;width, decoderCtx-\u0026gt;height, 1)); av_image_fill_arrays(destFrame-\u0026gt;data, destFrame-\u0026gt;linesize, outBuffer, destPixFmt, decoderCtx-\u0026gt;width, decoderCtx-\u0026gt;height, 1); struct SwsContext *swsCtx = sws_getContext(decoderCtx-\u0026gt;coded_width, decoderCtx-\u0026gt;coded_height, decoderCtx-\u0026gt;pix_fmt, decoderCtx-\u0026gt;width, decoderCtx-\u0026gt;height, destPixFmt, 0, NULL, NULL, NULL); if (swsCtx == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;create sws context failed!\\n\u0026#34;); ret = -1; goto end; } FILE *dest_fp = fopen(outFileName, \u0026#34;wb+\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open out put file %s failed!\\n\u0026#34;, outFileName); ret = -1; goto end; } AVPacket *packet = av_packet_alloc(); while (1) { if (av_read_frame(inFmtCtx, packet) == 0) { if (packet-\u0026gt;stream_index == videoIndex) { decodeVideo(swsCtx, decoderCtx, destFrame, packet, dest_fp); } } av_packet_unref(packet); } decodeVideo(swsCtx,decoderCtx, destFrame,NULL, dest_fp); end: if (inFmtCtx) { avformat_free_context(inFmtCtx); } if (decoderCtx) { avcodec_free_context(\u0026amp;decoderCtx); } if (dest_fp) { fclose(dest_fp); } if (outBuffer) { av_freep(\u0026amp;outBuffer); } return ret; } 音频采集 音频采集命令 采集麦克风声音：\n1 ffmpeg -f dshow -i audio=\u0026#34;阵列麦克风 (AMD Audio Device)\u0026#34; -ar 44100 -f f32le output.pcm 播放麦克风采集：\n1 ffplay -ar 44100 -f f32le output.pcm 流程 函数名 描述 avdevice_register_all 注册所有可用的设备 avformat_alloc_context 分配格式上下文 av_dict_set 设置字典选项 av_find_input_format 查找输入格式 avformat_open_input 打开输入文件 avformat_find_stream_info 查找流信息 av_find_best_stream 查找最佳流 avcodec_alloc_context3 分配编解码器上下文 avcode_parameters_to_context 将参数复制到上下文 avcodec_find_decoder 查找解码器 avcodec_open2 打开编解码器 av_read_frame 读取帧 avcode_send_packet 发送数据包 avcodec_receive_frame 接收帧 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 #include \u0026#34;libavcodec/avcodec.h\u0026#34; #include \u0026#34;libavdevice/avdevice.h\u0026#34; #include \u0026#34;libavformat/avformat.h\u0026#34; #include \u0026#34;libavutil/avutil.h\u0026#34; #include \u0026#34;libavutil/imgutils.h\u0026#34; #include \u0026#34;libswscale/swscale.h\u0026#34; #include \u0026lt;libavcodec/packet.h\u0026gt; #include \u0026lt;libavutil/dict.h\u0026gt; #include \u0026lt;libavutil/frame.h\u0026gt; #include \u0026lt;libavutil/log.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;time.h\u0026gt; // 显示可用的摄像头设备 // ffmpeg -f dshow -list_devices true -i dummy void dshowListDevices() { const AVInputFormat *inFmt = av_find_input_format(\u0026#34;dshow\u0026#34;); if (inFmt == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find dshow failed!\\n\u0026#34;); } // 设置参数 AVDictionary *options = NULL; av_dict_set(\u0026amp;options, \u0026#34;list_devices\u0026#34;, \u0026#34;true\u0026#34;, 0); AVFormatContext *inFmtCtx = avformat_alloc_context(); // 第二个参数是URL int ret = avformat_open_input(\u0026amp;inFmtCtx, \u0026#34;video=Integrated Camera\u0026#34;, inFmt, \u0026amp;options); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input format failed:%s\\n\u0026#34;, av_err2str(ret)); return; } if (inFmtCtx) { avformat_close_input(\u0026amp;inFmtCtx); avformat_free_context(inFmtCtx); } } void decodeAudio(AVCodecContext *decoderCtx, AVPacket *packet, FILE *dest_fp) { if (avcodec_send_packet(decoderCtx, packet) == 0) { AVFrame *frame = av_frame_alloc(); while (avcodec_receive_frame(decoderCtx, frame) \u0026gt;= 0) { fwrite(frame-\u0026gt;data[0], 1, frame-\u0026gt;linesize[0], dest_fp); } av_frame_free(\u0026amp;frame); } } int main(int argc, char *argv[]) { av_log_set_level(AV_LOG_INFO); if (argc \u0026lt; 2) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage:%s \u0026lt;outFileName\u0026gt; \\n\u0026#34;, argv[0]); return -1; } const char *outFileName = argv[1]; avdevice_register_all(); dshowListDevices(); AVFormatContext *inFmtCtx = avformat_alloc_context(); const AVInputFormat *inFmt = av_find_input_format(\u0026#34;dshow\u0026#34;); if (inFmt == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input format failed!\\n\u0026#34;); goto end; } AVDictionary *options = NULL; // av_dict_set(\u0026amp;options, \u0026#34;framerate\u0026#34;, \u0026#34;30\u0026#34;, 0); int ret = avformat_open_input(\u0026amp;inFmtCtx, \u0026#34;audio=阵列麦克风 (AMD Audio Device)\u0026#34;, inFmt, \u0026amp;options); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open input failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } ret = avformat_find_stream_info(inFmtCtx, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find stream info failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } ret = av_find_best_stream(inFmtCtx, AVMEDIA_TYPE_AUDIO, -1, -1, NULL, 0); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find best stream failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } int audioIndex = ret; // 创建解码器上下文 AVCodecContext *decoderCtx = avcodec_alloc_context3(NULL); ret = avcodec_parameters_to_context(decoderCtx, inFmtCtx-\u0026gt;streams[audioIndex]-\u0026gt;codecpar); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;copy parameters to context failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } const AVCodec *decoder = avcodec_find_decoder(decoderCtx-\u0026gt;codec_id); if (decoder == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;find decoder failed!\\n\u0026#34;); ret = -1; goto end; } ret = avcodec_open2(decoderCtx, decoder, NULL); if (ret != 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open decoder failed:%s\\n\u0026#34;, av_err2str(ret)); goto end; } #if 0 AVFrame *destFrame = av_frame_alloc(); enum AVPixelFormat destPixFmt = AV_PIX_FMT_YUV420P; uint8_t *outBuffer = av_malloc(av_image_get_buffer_size(destPixFmt, decoderCtx-\u0026gt;width, decoderCtx-\u0026gt;height, 1)); av_image_fill_arrays(destFrame-\u0026gt;data, destFrame-\u0026gt;linesize, outBuffer, destPixFmt, decoderCtx-\u0026gt;width, decoderCtx-\u0026gt;height, 1); struct SwsContext *swsCtx = sws_getContext(decoderCtx-\u0026gt;coded_width, decoderCtx-\u0026gt;coded_height, decoderCtx-\u0026gt;pix_fmt, decoderCtx-\u0026gt;width, decoderCtx-\u0026gt;height, destPixFmt, 0, NULL, NULL, NULL); if (swsCtx == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;create sws context failed!\\n\u0026#34;); ret = -1; goto end; } #endif FILE *dest_fp = fopen(outFileName, \u0026#34;wb+\u0026#34;); if (dest_fp == NULL) { av_log(NULL, AV_LOG_ERROR, \u0026#34;open out put file %s failed!\\n\u0026#34;, outFileName); ret = -1; goto end; } AVPacket *packet = av_packet_alloc(); while (1) { if (av_read_frame(inFmtCtx, packet) == 0) { if (packet-\u0026gt;stream_index == audioIndex) { // decodeVideo(swsCtx, decoderCtx, destFrame, packet, dest_fp); decodeAudio(decoderCtx, packet, dest_fp); } } av_packet_unref(packet); } // decodeVideo(swsCtx, decoderCtx, destFrame, NULL, dest_fp); decodeAudio(decoderCtx, NULL, dest_fp); end: if (inFmtCtx) { avformat_free_context(inFmtCtx); } if (decoderCtx) { avcodec_free_context(\u0026amp;decoderCtx); } if (dest_fp) { fclose(dest_fp); } return ret; } 采集完后要用指令\n1 ffplay -f s16le -ar 44100 code.pcm 才可以播放，可能是参数的不同\n","date":"2024-12-29T00:00:00Z","image":"https://serennan.github.io/post/video_base/player1.jpg","permalink":"https://serennan.github.io/post/video_base/","title":"音视频基础"}]